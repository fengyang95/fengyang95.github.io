<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="https://wwdguu.github.io">
  <title>Fengyang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="CV  python  C++  Java  Machine Learning">
<meta name="keywords" content="CV  python  C++  Java  Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Fengyang">
<meta property="og:url" content="https://wwdguu.github.io/index.html">
<meta property="og:site_name" content="Fengyang">
<meta property="og:description" content="CV  python  C++  Java  Machine Learning">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fengyang">
<meta name="twitter:description" content="CV  python  C++  Java  Machine Learning">
  
    <link rel="alternative" href="/atom.xml" title="Fengyang" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.507b3a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" 
style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="" class="profilepic">
			 <img src="/img/head.JPG" class="js-avatar show">
        	 <img src="/img/head.JPG" class="js-avatar show" style="width: 100%;height: 100%;opacity: 1;">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="">Fengyang</a></h1>
		</hgroup>
		
		<p class="header-subtitle">关注计算机视觉 机器学习</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/tags/随笔/">随笔</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/wwdguu/activities" title="zhihu"><i class="icon-zhihu"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/head.JPG" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Fengyang</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>关注计算机视觉 机器学习<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/wwdguu/activities" title="zhihu"><i class="icon-zhihu"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/tags/随笔/">随笔</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-dehaze" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/18/dehaze/">Implement of &#34;Single Image Haze Removal Using Dark Channel Prior&#34;</a>
    </h1>
  

        
        <a href="/2018/11/18/dehaze/" class="archive-article-date">
  	<time datetime="2018-11-18T02:59:12.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-11-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#compute-dark-channel"><span class="toc-text">compute dark channel</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#compute-atmosphere"><span class="toc-text">compute atmosphere</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Estimate-the-Transmission-and-Soft-Matting"><span class="toc-text">Estimate the Transmission and Soft Matting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recovering-the-Scene-Radiance"><span class="toc-text">Recovering the Scene Radiance</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-text">Reference</span></a></li></ol>
</div>

        <h2 id="compute-dark-channel"><a href="#compute-dark-channel" class="headerlink" title="compute dark channel"></a>compute dark channel</h2><script type="math/tex; mode=display">
J^{dark}(x)=min_{c\in{\{r,g,b\}}}(min_{y\in{\Omega (x)}}(J^c(y)))</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">%matplotlib inline</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">src=cv2.imread(<span class="string">'haze_img/9.jpg'</span>)</div><div class="line">plt.title(<span class="string">'src'</span>)</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.imshow(src[:,:,::<span class="number">-1</span>])</div></pre></td></tr></table></figure>
<p><img src="output_3_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_dark_channel</span><span class="params">(img,patch_size=<span class="number">15</span>)</span>:</span></div><div class="line">    h,w=img.shape[:<span class="number">2</span>]</div><div class="line">    b, g, r = cv2.split(img)</div><div class="line">    bgr_min_img = cv2.min(cv2.min(b, g), r)</div><div class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (patch_size,patch_size))</div><div class="line">    dark_channel_img = cv2.erode(bgr_min_img, kernel)</div><div class="line">    <span class="keyword">return</span> dark_channel_img</div><div class="line"></div><div class="line">dark_channel_img=compute_dark_channel(src,patch_size=<span class="number">15</span>)</div><div class="line">plt.title(<span class="string">'dark_channel_img'</span>)</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.imshow(dark_channel_img,cmap=<span class="string">'gray'</span>)</div></pre></td></tr></table></figure>
<p><img src="output_4_1.png" alt="png"></p>
<h2 id="compute-atmosphere"><a href="#compute-atmosphere" class="headerlink" title="compute atmosphere"></a>compute atmosphere</h2><p>We first pick the top 0.1% brightest pixels in the dark channel. Among these pixels, the pixels with highest intensity in the input image I is selected as the atmospheric light.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_atmosphere_light</span><span class="params">(img,dark_channel_img)</span>:</span></div><div class="line">    h,w=dark_channel_img.shape[:<span class="number">2</span>]</div><div class="line">    num_of_candiate=int(<span class="number">0.001</span>*h*w)</div><div class="line">    dark_channel=dark_channel_img.reshape(<span class="number">-1</span>,<span class="number">1</span>)[:,<span class="number">0</span>]</div><div class="line">    arg_sorted=np.argsort(dark_channel)[::<span class="number">-1</span>]</div><div class="line">    img=img.astype(np.float32)</div><div class="line">    atmosphere_light=np.zeros((<span class="number">3</span>,))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_of_candiate):</div><div class="line">        index=arg_sorted[i]</div><div class="line">        row_index=index//w</div><div class="line">        col_index=index%w</div><div class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">            atmosphere_light[c]=max(atmosphere_light[c],img[row_index,col_index][c])</div><div class="line">    <span class="keyword">return</span> atmosphere_light</div><div class="line"></div><div class="line">atmosphere_light=compute_atmosphere_light(src,dark_channel_img)</div><div class="line">print(atmosphere_light)</div></pre></td></tr></table></figure>
<pre><code>[255. 252. 249.]
</code></pre><h2 id="Estimate-the-Transmission-and-Soft-Matting"><a href="#Estimate-the-Transmission-and-Soft-Matting" class="headerlink" title="Estimate the Transmission and Soft Matting"></a>Estimate the Transmission and Soft Matting</h2><script type="math/tex; mode=display">
t(x)=1-\omega min_c(min_{y\in\Omega(x)} \frac{I^c(y)}{A^c})</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">guied_filter</span><span class="params">(I,P,radius,epsilon)</span>:</span></div><div class="line">    window_size=<span class="number">2</span>*radius+<span class="number">1</span></div><div class="line">    meanI=cv2.blur(I,(window_size,window_size))</div><div class="line">    meanP=cv2.blur(P,(window_size,window_size))</div><div class="line">    II=I**<span class="number">2</span></div><div class="line">    IP=I*P</div><div class="line">    corrI=cv2.blur(II,(window_size,window_size))</div><div class="line">    corrIP=cv2.blur(IP,(window_size,window_size))</div><div class="line">    varI=corrI-meanI**<span class="number">2</span></div><div class="line">    covIP=corrIP-meanI*meanP</div><div class="line">    a=covIP/(varI+epsilon)</div><div class="line">    b=meanP-a*meanI</div><div class="line">    meanA=cv2.blur(a,(window_size,window_size))</div><div class="line">    meanB=cv2.blur(b,(window_size,window_size))</div><div class="line">    transmission_rate=meanA*I+meanB</div><div class="line">    <span class="keyword">return</span> transmission_rate</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_transmission_rate</span><span class="params">(img,atmosphere_light_max,dark_channel_img,omega=<span class="number">0.95</span>,guided_filter_radius=<span class="number">50</span>,epsilon=<span class="number">0.0001</span>)</span>:</span></div><div class="line">    h,w=img.shape[:<span class="number">2</span>]</div><div class="line">    img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</div><div class="line">    zero_mat=np.zeros((h,w))</div><div class="line">    transmition_rate_est=cv2.max(zero_mat,np.ones_like(zero_mat)-omega*dark_channel_img/atmosphere_light_max)</div><div class="line">    <span class="comment">#transmission_rate = guied_filter(img_gray,transmition_rate_est, guided_filter_radius, epsilon)</span></div><div class="line">    transmission_rate=cv2.ximgproc.guidedFilter(img_gray.astype(np.float32),transmition_rate_est.astype(np.float32),guided_filter_radius,epsilon)</div><div class="line">    <span class="keyword">return</span> transmission_rate</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">transmission_rate=compute_transmission_rate(src,np.max(atmosphere_light),dark_channel_img)</div><div class="line">plt.title(<span class="string">'transmission_rate'</span>)</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.imshow(transmission_rate,cmap=<span class="string">'gray'</span>)</div></pre></td></tr></table></figure>
<p><img src="output_10_1.png" alt="png"></p>
<h2 id="Recovering-the-Scene-Radiance"><a href="#Recovering-the-Scene-Radiance" class="headerlink" title="Recovering the Scene Radiance"></a>Recovering the Scene Radiance</h2><script type="math/tex; mode=display">
J(x)=\frac{I(x)-A}{max(t(x),t_0)}+A</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">min_transmission=<span class="number">0.1</span></div><div class="line">transmission_rate[transmission_rate&lt;min_transmission]=min_transmission</div><div class="line">dehaze_img=np.zeros_like(src,dtype=np.uint8)</div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">    dehaze_img[:,:,c]=(src[:,:,c]-atmosphere_light[c])/transmission_rate+atmosphere_light[c]</div><div class="line">dehaze_img[dehaze_img&gt;<span class="number">255</span>]=<span class="number">255</span></div><div class="line">dehaze_img[dehaze_img&lt;<span class="number">0</span>]=<span class="number">0</span></div><div class="line">plt.title(<span class="string">'dehaze'</span>)</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.imshow(dehaze_img[:,:,::<span class="number">-1</span>])</div></pre></td></tr></table></figure>
<p><img src="output_12_1.png" alt="png"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] He K, Sun J, Tang X. Single image haze removal using dark channel prior[C]// Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009:1956-1963.<br>[2] He K, Sun J, Tang X. Guided Image Filtering[M]// Computer Vision – ECCV 2010. Springer Berlin Heidelberg, 2010:1397-1409.</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cv//" class="article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/11/18/dehaze/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-GeoMAN" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/16/GeoMAN/">GeoMAN</a>
    </h1>
  

        
        <a href="/2018/09/16/GeoMAN/" class="archive-article-date">
  	<time datetime="2018-09-16T15:00:18.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-09-16</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#GeoMAN-Multi-level-Attention-Networks-for-Geo-sensory-Time-Series-Predicti-on-论文笔记"><span class="toc-text">GeoMAN:Multi-level Attention Networks for Geo-sensory Time Series Predicti on 论文笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#论文亮点"><span class="toc-text">论文亮点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Attention细节"><span class="toc-text">Attention细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spatio-Attention"><span class="toc-text">Spatio Attention</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Local-Attention"><span class="toc-text">Local Attention</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Global-Attention"><span class="toc-text">Global Attention</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tempral-Attention"><span class="toc-text">Tempral Attention</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#External-Attention"><span class="toc-text">External Attention</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Encoder-Decoder结构"><span class="toc-text">Encoder-Decoder结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Encoder阶段"><span class="toc-text">Encoder阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoder阶段"><span class="toc-text">Decoder阶段</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验结果"><span class="toc-text">实验结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#源码阅读及实现"><span class="toc-text">源码阅读及实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#官方tensorflow-实现学习"><span class="toc-text">官方tensorflow 实现学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch-实现"><span class="toc-text">pytorch 实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-text">参考资料</span></a></li></ol></li></ol>
</div>

        <h1 id="GeoMAN-Multi-level-Attention-Networks-for-Geo-sensory-Time-Series-Predicti-on-论文笔记"><a href="#GeoMAN-Multi-level-Attention-Networks-for-Geo-sensory-Time-Series-Predicti-on-论文笔记" class="headerlink" title="GeoMAN:Multi-level Attention Networks for Geo-sensory Time Series Predicti on 论文笔记"></a>GeoMAN:Multi-level Attention Networks for Geo-sensory Time Series Predicti on 论文笔记</h1><h2 id="论文亮点"><a href="#论文亮点" class="headerlink" title="论文亮点"></a>论文亮点</h2><p>在encoder阶段加入两种类型的attention机制，包括local attention和global attention，分别学到同一sensor内各个特征之间的关系，以及不同sensor之间的关系。Decoder阶段的temporal attention机制学习到序列时序之间的关系。加入外部因子融合模块。<br>总的来说：GeoMAN的网络结构以Encoder-Decoder作为基础结构，Encoder阶段加入了spatio attention（包括local attention和global attention),Decoder阶段加入了tempral attention和external attention。</p>
<h2 id="Attention细节"><a href="#Attention细节" class="headerlink" title="Attention细节"></a>Attention细节</h2><p>文中用到的符号：$Y=(y^1,y^2,…,y^{N_g})\in R^{N_g \times  T}$表示所有sensor测量到的在T时间序列内的数据。其中$y^i\in R^T$表示sensor i的测量值。使用$X^i=(x^{i,1},x^{i,2},…,x^{i,N_l})^{T}=(x_1^i,x_2^i,…,x_T^i)\in R^{N_l\times T}$表示sensor i的local features。将所有sensor的local feature组合在一起，得到global feature,$\chi={X^1,X^2,…,X^{N_g}}$以此作为sensor i的global 特征。</p>
<h3 id="Spatio-Attention"><a href="#Spatio-Attention" class="headerlink" title="Spatio Attention"></a>Spatio Attention</h3><h4 id="Local-Attention"><a href="#Local-Attention" class="headerlink" title="Local Attention"></a><strong>Local Attention</strong></h4><p>Local Attention的目的是找出同一个sensor之间不同特征的权重关系，遵循以下方法来进行：<br>$e_t^k=v_l^T tanh(W_l[h_{t-1};s_{t-1}]+U_lx^{i,k}+b_l)$<br>根据$\alpha_t^k=\frac{exp(e_t^k)}{\sum_{j=1}^{N_l}exp(e_t^j)}$计算特征k的权重，这里其实就是一个softmax函数。<br>最后得到：<br>$x_t^{local}=(\alpha_t^1x_t^{i,1},\alpha_t^2x_t^{i,2},…,\alpha_t^{N_l}x_t^{i,N_l})^T$<br>上述公式中，$v_l,b_l\in R^T$,$W_l\in R^{T\times 2m}$,$U_l\in R^{T\times T}$</p>
<h4 id="Global-Attention"><a href="#Global-Attention" class="headerlink" title="Global Attention"></a><strong>Global Attention</strong></h4><p>主要目的是找到不同sensor测量的特征之间的关系。<br>对于目标sensor i和另一个sensor l,通过以下式子计算attention的权重。<br>$g_t^l=v_g^T tanh(W_g[h_{t-1};s_{t-1}]+U_gy^l+W_g’X^lu_g+b_g)$<br>其中，$v_g,u_g,b_g \in R^T$,$W_g \in R^{T\times 2m}$,$U_g\in R^{T\times T}$,$W_g’\in R^{T\times N_l}$都是需要学习的参数。<br>另外还加入一个矩阵$P\in R^{N_g\times N_g}$来表征地理空间的相似性。<br>最后，和local attention机制类似，将权重用softmax整合起来。<br>$\beta _t^l=\frac{exp((1-\lambda)g_t^l+\lambda P_{i,l})}{\sum _{j=1}^{N_g}exp((1-\lambda)g_t^j+\lambda P_{i,j})}$<br>然后$x_t^{global}=(\beta_t^1y_t^1,\beta_t^2y_t^2,…,\beta_t^{N_g}y_t^{N_g})^T$</p>
<h3 id="Tempral-Attention"><a href="#Tempral-Attention" class="headerlink" title="Tempral Attention"></a><strong>Tempral Attention</strong></h3><p>解决时序过长时，Encoder-Decoder性能下降的问题。<br>$u_{t’}^o=v_d^Ttanh(W_d’[d_{t’-1};s_{t’-1}’]+W_dh_o+b_d)$<br>$\gamma_{t’}^o=\frac{exp(u_{t’}^o)}{\sum_{j=1}^{T}exp(u_{t’}^j)}$<br>$c_{t’}=\sum_{o=1}^{T}\gamma_{t’}^oh_o$<br>其中$W_d\in R^{m\times m}$,$W_d’\in R^{m\times 2n}$,$v_d,b_d\in R_m$是可以学习的参数。</p>
<h3 id="External-Attention"><a href="#External-Attention" class="headerlink" title="External Attention"></a><strong>External Attention</strong></h3><p>将各种外界的影响因素，embedding起来。<br>$ex_{t’}\in R^{N_e}$,其中t’是decoder中的未来时间点。</p>
<h2 id="Encoder-Decoder结构"><a href="#Encoder-Decoder结构" class="headerlink" title="Encoder-Decoder结构"></a>Encoder-Decoder结构</h2><h3 id="Encoder阶段"><a href="#Encoder阶段" class="headerlink" title="Encoder阶段"></a><strong>Encoder阶段</strong></h3><p>将local attention和global attention的结果concat起来作为Encoder的输入。<br>$x_t=[x_t^{local};x_t^{global}]$,其中$x_t\in R^{N_l+N_g}$,然后根据$h_t=f_e(h_{t-1},x_t)$更新hiddent state，其中$f_e$是LSTM单元。</p>
<h3 id="Decoder阶段"><a href="#Decoder阶段" class="headerlink" title="Decoder阶段"></a><strong>Decoder阶段</strong></h3><p>在Decoder阶段，根据t’时刻的加权求和的上下文向量$c_{t’}$，加上$ex_{t’}$和$y_{t’-1}^i$来更新decoder的hidden state，$d_{t’}=f_d(d_{t’-1},[y_{t’-1}^i;ex_{t’};c_{t’}])$,其中$f_d$是decoder中使用的LSTM单元。然后使用下式得到$y_{t’}^i$,$y_{t’}^i=v_y^T(W_m[c_{t’};d_{t’}]+b_m)+b_y$其中$W_m\in R^{n\times (              m+n)}$,$b_m\in{R^n}$将$[c_{t’};d_{t’}]\in R^{m+n}$映射到hidden state的尺度。最后用线性变换产生最后的预测输出。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>使用MSE作为损失函数，最后的实验结果详见原论文。在其所用数据集上达到了state-of-the-art。</p>
<h2 id="源码阅读及实现"><a href="#源码阅读及实现" class="headerlink" title="源码阅读及实现"></a>源码阅读及实现</h2><h3 id="官方tensorflow-实现学习"><a href="#官方tensorflow-实现学习" class="headerlink" title="官方tensorflow 实现学习"></a>官方tensorflow 实现学习</h3><h3 id="pytorch-实现"><a href="#pytorch-实现" class="headerlink" title="pytorch 实现"></a>pytorch 实现</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1、<a href="http://yuxuanliang.com/assets/pdf/ijcai-18/paper.pdf" target="_blank" rel="external">原论文 GeoMAN: Multi-level Attention Networks for Geo-sensory Time Series Prediction</a><br>2、<a href="https://github.com/yoshall/GeoMAN" target="_blank" rel="external">官方Tensorflow实现</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">RNN</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/RNN//" class="article-tag-list-link color4">RNN</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/09/16/GeoMAN/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-seq2seq-for-time-series-prediction" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/08/seq2seq-for-time-series-prediction/">用Seq2Seq做时间序列预测</a>
    </h1>
  

        
        <a href="/2018/09/08/seq2seq-for-time-series-prediction/" class="archive-article-date">
  	<time datetime="2018-09-08T04:08:32.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-09-08</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Useful-Blogs"><span class="toc-text">Useful Blogs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tips"><span class="toc-text">Tips</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-challenge-2018-天气预报赛题"><span class="toc-text">AI challenge 2018 天气预报赛题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#一些尝试"><span class="toc-text">一些尝试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Baseline"><span class="toc-text">Baseline</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Seq2Seq的思路"><span class="toc-text">Seq2Seq的思路</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#数据分析"><span class="toc-text">数据分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#特征选择"><span class="toc-text">特征选择</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#模型建立"><span class="toc-text">模型建立</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#尝试改进措施"><span class="toc-text">尝试改进措施</span></a></li></ol></li></ol></li></ol></li></ol>
</div>

        <h2 id="Useful-Blogs"><a href="#Useful-Blogs" class="headerlink" title="Useful Blogs"></a>Useful Blogs</h2><p>1、<a href="https://github.com/LukeTonin/keras-seq-2-seq-signal-prediction" target="_blank" rel="external">keras-seq-2-seq-signal-prediction</a><br>2、<a href="https://github.com/guillaume-chevalier/seq2seq-signal-prediction" target="_blank" rel="external">seq2seq-signal-prediction</a><br>3、<a href="https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/" target="_blank" rel="external">ts_seq2seq_intro/</a><br>4、<a href="https://github.com/Arturus/kaggle-web-traffic" target="_blank" rel="external">https://github.com/Arturus/kaggle-web-traffic</a><br>5、<a href="https://arxiv.org/pdf/1409.3215.pdf" target="_blank" rel="external">Sequence to Sequence Learning with Neural Networks Paper</a><br>6、<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="external">Attention is All You Need paper</a><br>7、<a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="external">https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html</a><br>8、<a href="https://github.com/Arturus/kaggle-web-traffic/blob/master/how_it_works.md" target="_blank" rel="external">https://github.com/Arturus/kaggle-web-traffic/blob/master/how_it_works.md</a><br>9、<a href="https://github.com/skyhuang1208/kaggle-web-traffic-time-series-forecasting" target="_blank" rel="external">https://github.com/skyhuang1208/kaggle-web-traffic-time-series-forecasting</a><br>10、<a href="https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/" target="_blank" rel="external">https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/</a><br>11、<a href="https://www.analyticsvidhya.com/blog/2018/08/auto-arima-time-series-modeling-python-r/" target="_blank" rel="external">https://www.analyticsvidhya.com/blog/2018/08/auto-arima-time-series-modeling-python-r/</a><br>12、<a href="http://chandlerzuo.github.io/blog/2017/11/darnn" target="_blank" rel="external">http://chandlerzuo.github.io/blog/2017/11/darnn</a><br>13、<a href="https://arxiv.org/pdf/1704.02971.pdf" target="_blank" rel="external">A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction</a><br>14、<a href="https://github.com/yoshall/GeoMAN" target="_blank" rel="external">https://github.com/yoshall/GeoMAN</a></p>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>1、注意RNN中Many-to-Many 和 Encoder-Decoder模型的区别。Many-to-Many是一个整体的模型，而Encoder-Decoder是将模型分为不同的Encoder-Decoder两个部分。<br>2、尝试将Encoder和Decoder的结构设为不同，如将hidden_size以及layers设为不同，如果hidden_size设为不同，需要在Encoder最后加一个全连接层，将输出维度与Decoder的输入维度匹配。<br>3、尝试使用attention模块。<br>4、</p>
<h2 id="AI-challenge-2018-天气预报赛题"><a href="#AI-challenge-2018-天气预报赛题" class="headerlink" title="AI challenge 2018 天气预报赛题"></a>AI challenge 2018 天气预报赛题</h2><h3 id="一些尝试"><a href="#一些尝试" class="headerlink" title="一些尝试"></a>一些尝试</h3><h4 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h4><p>使用fbprophet根据年、日变化特征预测</p>
<h4 id="Seq2Seq的思路"><a href="#Seq2Seq的思路" class="headerlink" title="Seq2Seq的思路"></a>Seq2Seq的思路</h4><h5 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h5><p>分析t2m_obs,rh2m_obs,w10m_obs三个特征的变化趋势，以及与其他特征之间的一些关系</p>
<h5 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h5><p>初步：9个obs特征+时刻特征+月份特征+31个M特征<br>其中时刻特征和月份特征因为涉及到循环，如23时和0时应该在数值上相邻，于是使用cos，sin来编码。<br>如下面这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hour_period = <span class="number">24</span> / (<span class="number">2</span> * np.pi)</div><div class="line">validation_data[<span class="string">'hour_cos'</span>] = np.cos(validation_data.index.hour / hour_period)</div><div class="line">validation_data[<span class="string">'hour_sin'</span>] = np.sin(validation_data.index.hour / hour_period)</div></pre></td></tr></table></figure></p>
<h5 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h5><p>使用Encoder-Decoder组成的Seq2Seq结构，以前108个时间段的所有特征作为输入，以待预测的推移36个时间段的3个目标特征作为输出。<br>Encoder阶段使用LSTM 第一步：将输入维度变化到与LSTM的隐藏层相同，一种思路是使用全连接层，一种是使用LSTM input_size=输入维度，hidden_size=LSTM。第二步：使用多层LSTM stack。尝试过3层，5层。<br>Decoder阶段：以Encoder阶段的最后一个隐藏层输入作为隐藏层，Input目前选择初始化为全零。也是多层LSTM,最后使用Decoder阶段的output作为输入的一部分。<br><strong>Attention Module</strong>：加入attention module，将Encoder阶段的outputs，与Decoder中的LSTM的outputs作为attention模块输入，输出最后的output。<br>加上一层全连接层将维度进行转换。</p>
<p>目前的测试结果来看：效果不理想，存在过拟合的现象，训练loss降低的情况下，验证的loss反而升高了。尝试dropout，似乎对结果没有提升。</p>
<h5 id="尝试改进措施"><a href="#尝试改进措施" class="headerlink" title="尝试改进措施"></a>尝试改进措施</h5><p>1、尝试Decoder阶段的Input不为零，改用其它有意义的信息，需要再看资料解决。（Decoder inputs in Seq2Seq Model）（input特征已经加入，正在尝试效果）应该实现位移一位？<br>2、参数初始化问题<br>3、一个可能的思路：最后输出之前，加入待预测特征的前一年同一时刻(24<em>365-1h到24</em>365+1h)前后共3小时的观测数据值、前一天（23-25h前）前后3小时的观测数据值、用fbprophet预测的该时刻的观测值。这些特征与输出拼接起来，再加入一个全连接层，作为最后的输出。（相当于手动加入历史数据及变化趋势数据并线性组合起来）：已经加入了前一天的观测数据作为辅助，fbprophet预测的数据尚未加入。</p>
<p>最新模型想法：<br>以fbprophet预测的t2m,rh2m,w10m数据作为Decoder的inputs。<br>最后一层融合的数据包括 前一天（23-25h之前）的观测数据，以及fbprophet预测的观测值。<br>即把fbprophet预测的值用在了两个地方，一是作为Decoder部分的输入，一是作为最后融合特征的一部分。<br>先尝试这个模型的效果。</p>
<p>然后考虑进一步的优化方向：<br>1、加入更多的数据特征，（即将M类信息也作为特征输入）<br>2、考虑更鲁棒的填充缺失值算法。如使用prophet辅助填充缺失值。<br>3、考虑取出outliners，将太过明显的噪声滤掉，替换为更平滑的数据。</p>
<p>最新模型的特点：Encoder-Decoder作为基础结构，以input sequence作为decoder的input输入<br>新的想法：分析各个因素之间的相关性，添加相关性较强的特征作为因素</p>
<p>Decoder Inputs选用当前 input的 t2m_obs,rh2m_obs,w10m_obs,t2m_M,rh2m_M,w10m_M,t2m_prophet,rh2m_prophet,w10m_prophet,hour_sin,hour_cos,month_sin,month_sin作为输入。<br>Decoder output之后，将等待预测时刻的t2m_M,rh2m_M,w10m_M,t2m_prophet,rh2m_prophet,w10m_prophet与output融合，作为最后输出。（使用depth_wise 1D conv实现融合）<br>融合策略如何改进？</p>
<p>改进措施：<br>比较MinMaxScaler和StandardScaler</p>
<p>分析数据，去掉outlines</p>
<p>尝试GeoMAN中的attention方法</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">rnn</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/rnn//" class="article-tag-list-link color4">rnn</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/09/08/seq2seq-for-time-series-prediction/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-use-pandas" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/02/use-pandas/">pandas的一些操作记录</a>
    </h1>
  

        
        <a href="/2018/09/02/use-pandas/" class="archive-article-date">
  	<time datetime="2018-09-02T02:12:39.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-09-02</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  
</div>

        <p>1、<strong>修改DataFrame列名</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 方法1 直接修改columns属性</span></div><div class="line">df.columns = [<span class="string">'A'</span>,<span class="string">'B'</span>] </div><div class="line"><span class="comment"># 方法2 使用rename方法</span></div><div class="line">df.rename(columns=&#123;<span class="string">'a'</span>:<span class="string">'A'</span>,<span class="string">'b'</span>:<span class="string">'B'</span>&#125;)</div></pre></td></tr></table></figure></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">pandas</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/pandas//" class="article-tag-list-link color2">pandas</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/09/02/use-pandas/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-HOMLWSLATF-ch4" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/01/HOMLWSLATF-ch4/">Chapter 4. Training Models</a>
    </h1>
  

        
        <a href="/2018/09/01/HOMLWSLATF-ch4/" class="archive-article-date">
  	<time datetime="2018-09-01T05:21:24.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-09-01</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Linear-Regression"><span class="toc-text">1 Linear Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-The-Normal-Equation"><span class="toc-text">1.1 The Normal Equation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Computational-Complexity"><span class="toc-text">1.2 Computational Complexity</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Gradient-Descent"><span class="toc-text">2 Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Batch-Gradient-Descent"><span class="toc-text">2.1 Batch Gradient Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Stochastic-Gradient-Descent"><span class="toc-text">2.2 Stochastic Gradient Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Mini-batch-Gradient-Descent"><span class="toc-text">2.3 Mini-batch Gradient Descent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Polynomial-Regression"><span class="toc-text">3 Polynomial Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Learning-Curves"><span class="toc-text">4 Learning Curves</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Regularized-Linear-Models"><span class="toc-text">5 Regularized Linear Models</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Ridge-Regression"><span class="toc-text">5.1 Ridge Regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Lasso-Regression"><span class="toc-text">5.2 Lasso Regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Elastic-Net"><span class="toc-text">5.3 Elastic Net</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-Early-Stopping"><span class="toc-text">5.4 Early Stopping</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Logistic-Regression"><span class="toc-text">6 Logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-Estimating-Probabilities"><span class="toc-text">6.1 Estimating Probabilities</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-Training-and-Cost-Funtion"><span class="toc-text">6.2 Training and Cost Funtion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-Decision-Boundaries"><span class="toc-text">6.3 Decision Boundaries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-Softmax-Regression"><span class="toc-text">6.4 Softmax Regression</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>前面几章在不知道具体原理的情况下，我们已经使用sklearn搭建模型并解决了一些实际问题，这章介绍一些原理，以便我们更好地选择算法模型。</p>
<h2 id="1-Linear-Regression"><a href="#1-Linear-Regression" class="headerlink" title="1 Linear Regression"></a>1 Linear Regression</h2><p>线性回归的基本形式：</p>
<script type="math/tex; mode=display">y=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n</script><p>它的向量化的形式是：</p>
<script type="math/tex; mode=display">y=h_\theta(x)=\theta^T\cdot x</script><p>MSE损失函数：</p>
<script type="math/tex; mode=display">MSE(X,h_\theta)=\frac{1}{m}\sum_{i=1}^m(\theta^T\cdot x^{(i)}-y^{(i)})^2</script><h3 id="1-1-The-Normal-Equation"><a href="#1-1-The-Normal-Equation" class="headerlink" title="1.1 The Normal Equation"></a>1.1 The Normal Equation</h3><p>线性回归是有闭式解使得损失函数的值最小的，它的形式如下： </p>
<script type="math/tex; mode=display">\theta=(X^T\cdot X)^{-1}\cdot X^T \cdot y</script><p><strong>使用numpy测试</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">X = <span class="number">2</span> * np.random.rand(<span class="number">100</span>, <span class="number">1</span>)</div><div class="line">y = <span class="number">4</span> + <span class="number">3</span> * X + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</div><div class="line"></div><div class="line">X_b = np.c_[np.ones((<span class="number">100</span>,<span class="number">1</span>)), X] <span class="comment"># add x0 = 1 to each instance</span></div><div class="line">theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>theta_best</div><div class="line">array([[<span class="number">4.21509616</span>],</div><div class="line">        [<span class="number">2.77011339</span>]])</div></pre></td></tr></table></figure></p>
<p><strong>用sklearn测试</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line">lin_reg = LinearRegression()</div><div class="line">lin_reg.fit(X, y)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>lin_reg.intercept_, lin_reg.coef_</div><div class="line">(array([<span class="number">4.21509616</span>]), array([[<span class="number">2.77011339</span>]]))</div></pre></td></tr></table></figure></p>
<h3 id="1-2-Computational-Complexity"><a href="#1-2-Computational-Complexity" class="headerlink" title="1.2 Computational Complexity"></a>1.2 Computational Complexity</h3><p>闭式解的计算需要对矩阵求逆，其复杂度是和实例的数量以及特征的数量成正比的。</p>
<h2 id="2-Gradient-Descent"><a href="#2-Gradient-Descent" class="headerlink" title="2 Gradient Descent"></a>2 Gradient Descent</h2><p>梯度下降是寻找局部最优的一种常见方法，其思想就是迭代参数使得loss下降。关于梯度下降，因为已经了解，不做过多笔记。使用梯度下降的时候，需要保证所有的特征都有相似的尺度。</p>
<h3 id="2-1-Batch-Gradient-Descent"><a href="#2-1-Batch-Gradient-Descent" class="headerlink" title="2.1 Batch Gradient Descent"></a>2.1 Batch Gradient Descent</h3><p>对线性回归的MSE求梯度，</p>
<script type="math/tex; mode=display">\Delta_\theta MSE(\theta)=\frac{2}{m}X^T \cdot (X \cdot \theta - y)</script><p>这是一个向量化的操作，它对整个训练集X求梯度，所以称为<strong>Batch Gradient Descent</strong>。<br>参数更新如下：</p>
<script type="math/tex; mode=display">\theta^{(next)}=\theta - \eta\Delta_\theta MSE(\theta)</script><p><strong>算法实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">eta = <span class="number">0.1</span> </div><div class="line">n_iterations = <span class="number">1000</span></div><div class="line">m = <span class="number">100</span></div><div class="line"></div><div class="line">theta = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</div><div class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</div><div class="line">    gradients = <span class="number">2</span>/m*X_b.T.dot(X_b.dot(theta)-y)</div><div class="line">    theta = theta - eta * gradients</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>theta</div><div class="line">array([<span class="number">4.21509616</span>],</div><div class="line">    [<span class="number">2.77011339</span>])</div></pre></td></tr></table></figure></p>
<p>可见针对线性回归问题，使用梯度下降的方法和闭式解相同。值得注意的是，学习率需要合理设置，过高容易越过最优解，而过低则收敛太慢。合理设置迭代次数也极为重要，通常的好做法是设置比较大的iterations，当参数变化极微弱时即可中断操作，可以认为此时达到了局部最优解。</p>
<h3 id="2-2-Stochastic-Gradient-Descent"><a href="#2-2-Stochastic-Gradient-Descent" class="headerlink" title="2.2 Stochastic Gradient Descent"></a>2.2 Stochastic Gradient Descent</h3><p>Batch Gradient Descent的一个缺点就是它将训练集作为整体进行训练，当训练集太大时，速度会很慢。随机梯度下降则在训练时随机选择一个实例对其计算梯度，然后进行优化，这样速度很快，当然，由于其每次只用一个实例进行训练，它并不能做到每次迭代都使loss减小，并且即便函数到达全局最优，它还是可以继续运算下去，所以它只能得到一个近似的最优解。它的特点就是可以跳过局部最优，但是同时这也就意味着它也能跳过全局最优。一种解决方案是逐渐减小学习率，叫做<strong>simulated annealing</strong><br><strong>实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">n_epochs = <span class="number">50</span></div><div class="line">t0, t1 = <span class="number">5</span>, <span class="number">50</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">learning_schedule</span><span class="params">(t)</span>:</span></div><div class="line">    <span class="keyword">return</span> t0 / (t + t1)</div><div class="line"></div><div class="line">theta = np.random.randn(<span class="number">2</span>,<span class="number">1</span>)</div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        random_index = np.random.randint(m)</div><div class="line">        xi = X_b[random_index:random_index+<span class="number">1</span>]</div><div class="line">        yi = y[random_index:random_index+<span class="number">1</span>]</div><div class="line">        gradients = <span class="number">2</span> * xi.T.dot(xi.dot(theta) - yi)</div><div class="line">        eta = learning_schedule(epoch * m + i)</div><div class="line">        theta = theta - eta * gradients</div></pre></td></tr></table></figure></p>
<p>最后计算得到<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>theta</div><div class="line">array([[<span class="number">4.21076011</span>],</div><div class="line">    [<span class="number">2.74856079</span>]])</div></pre></td></tr></table></figure></p>
<p>使用sklearn实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</div><div class="line">sgd_reg = SGDRegressor(n_iter=<span class="number">50</span>, penalty=<span class="keyword">None</span>, eta0=<span class="number">0.1</span>)</div><div class="line">sgd_reg.fit(X,y.ravel())</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_reg.inercept_,sgd_reg.coef_</div><div class="line">(array([<span class="number">4.18380366</span>]), array([<span class="number">2.74285299</span>]))</div></pre></td></tr></table></figure></p>
<h3 id="2-3-Mini-batch-Gradient-Descent"><a href="#2-3-Mini-batch-Gradient-Descent" class="headerlink" title="2.3 Mini-batch Gradient Descent"></a>2.3 Mini-batch Gradient Descent</h3><p>Mini-batch是前两种方式的折中，不过多笔记了。<br><strong>几种训练方法比较</strong></p>
<script type="math/tex; mode=display">\begin{array}{c|lcr}
\text{Algorithm} & \text{Large m} & \text{Out-of-core support} & \text{Large n} & \text{Hyperparams} &\text{Scaling required} &\text{Scikit-Learn} \\\\
Normal &Equation &Fast &No &Slow &0 &No &LinearRegression \\\\
Batch GD & Slow & No & Fast & 2 & Yes & n/a \\\\
SGD & Fast & Yes & Fast & >=2 & Yes & SGDRegressor \\\\
Mini-batch GD & Fast & Yes & Fast & >=2 & Yes & n/a \\\\
\end{array}</script><h2 id="3-Polynomial-Regression"><a href="#3-Polynomial-Regression" class="headerlink" title="3 Polynomial Regression"></a>3 Polynomial Regression</h2><p>多项式回归<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">m = <span class="number">100</span></div><div class="line">X = <span class="number">6</span> * np.random.rand(m,<span class="number">1</span>) - <span class="number">3</span></div><div class="line">y = <span class="number">0.5</span> * X**<span class="number">2</span> + X + <span class="number">2</span> + np.random.randn(m,<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment">#使用sklearn包进行拟合</span></div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</div><div class="line">poly_features = PolynomialFeatures(degree=<span class="number">2</span>, include_bias=<span class="keyword">False</span>)</div><div class="line">X_poly = poly_features.fit_transform(X)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>X[<span class="number">0</span>]</div><div class="line">array([<span class="number">-0.75275929</span>])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>X_poly[<span class="number">0</span>]</div><div class="line">array([<span class="number">-0.75275929</span>, <span class="number">0.56664654</span>])</div><div class="line"></div><div class="line"><span class="comment"># 下面进行线性回归</span></div><div class="line">lin_reg = LinearRegression()</div><div class="line">lin_reg.fit(X_poly, y)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>lin_reg.intercept_,lin_reg.coef_</div><div class="line">(array([<span class="number">1.78134581</span>]),array([[<span class="number">0.93366893</span>, <span class="number">0.56456263</span>]]))</div></pre></td></tr></table></figure></p>
<h2 id="4-Learning-Curves"><a href="#4-Learning-Curves" class="headerlink" title="4 Learning Curves"></a>4 Learning Curves</h2><p>可以通过绘制训练集和验证集的学习曲线来判断模型的拟合情况。<br><strong>some tricks</strong><br><strong>1</strong> 如果模型在训练集上是欠拟合的，添加更多训练数据并没有用，我们需要做的是使用更复杂的模型或者是利用更多的features。<br><strong>2</strong> 提升一个过拟合模型的性能的一种有效方法是添加更多的训练数据，直到训练误差接近验证误差。<br><strong>The Bias/Variance Tradeoff</strong><br>泛化误差的三个主要组成部分：<br><strong>Bias</strong>：来源于错误的假设，比如数据是线性的，假设为二次多项式造成的泛化误差。<br><strong>Variance</strong>：来源于训练过程中，模型对数据中微小变化的敏感性。<br><strong>Irreducible error</strong>：来源于数据的噪声。解决方法只能是数据清洗，如去除outliners等。</p>
<h2 id="5-Regularized-Linear-Models"><a href="#5-Regularized-Linear-Models" class="headerlink" title="5 Regularized Linear Models"></a>5 Regularized Linear Models</h2><p>介绍线性模型中的一些正则化方法，来抑制过拟合。</p>
<h3 id="5-1-Ridge-Regression"><a href="#5-1-Ridge-Regression" class="headerlink" title="5.1 Ridge Regression"></a>5.1 Ridge Regression</h3><p>在损失函数中添加正则项：</p>
<script type="math/tex; mode=display">J(\theta)=MSE(\theta)+\alpha \frac{1}{2} \sum _{i=1}^{n} \theta_i ^2</script><p><strong>Trick</strong>：使用Ridge Regression之前先对数据进行scale是很有必要的，因为该模型对输入数据尺度敏感。对于大多数正则化模型来说都是这样。</p>
<p><strong>Ridge Regression的闭式解</strong></p>
<script type="math/tex; mode=display">\theta=(X^T \cdot X+\alpha A)^{-1}\cdot X^T\cdot y</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</div><div class="line"><span class="comment"># 使用闭式解</span></div><div class="line">ridge_reg = Ridge(alpha=<span class="number">1</span>,  solver=<span class="string">'cholesky'</span>)</div><div class="line">ridge_reg.fit(X,y)</div><div class="line"></div><div class="line"><span class="comment"># 使用SGD</span></div><div class="line">sgd_reg = SGDRegressor(penalty=<span class="string">'l2'</span>)</div><div class="line">sgd_reg.fit(X,y.ravel())</div></pre></td></tr></table></figure>
<h3 id="5-2-Lasso-Regression"><a href="#5-2-Lasso-Regression" class="headerlink" title="5.2 Lasso Regression"></a>5.2 Lasso Regression</h3><p>Least Absolute Shrinkage and Selection Operator Regression<br>同样是在loss function添加正则项。</p>
<script type="math/tex; mode=display">J(\theta)=MSE(\theta)+\alpha \sum _{i=1}^n |\theta_i|</script><p>Lasso倾向于使得不重要的特征的权重接近0，也就是说，它能够自动进行特征选择，并且输出为稀疏矩阵。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</div><div class="line">lasso_reg = Lasso(alpha=<span class="number">0.1</span>)</div></pre></td></tr></table></figure></p>
<h3 id="5-3-Elastic-Net"><a href="#5-3-Elastic-Net" class="headerlink" title="5.3 Elastic Net"></a>5.3 Elastic Net</h3><p>对Ridge和Lasso的折中，既惩罚一次项，也惩罚二次项。</p>
<script type="math/tex; mode=display">J(\theta)= MSE(\theta)+ra\sum _{i=1}^n|\theta _i|+\frac{1-r}{2}\alpha \sum _{i=1} ^n \theta_i^2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</div><div class="line">elastic_net = ElasticNet(alpha=<span class="number">0.1</span>, l1_ratio=<span class="number">0.5</span>)</div></pre></td></tr></table></figure>
<h3 id="5-4-Early-Stopping"><a href="#5-4-Early-Stopping" class="headerlink" title="5.4 Early Stopping"></a>5.4 Early Stopping</h3><p>训练过程中，验证误差达到某个阈值时停止训练。</p>
<h2 id="6-Logistic-Regression"><a href="#6-Logistic-Regression" class="headerlink" title="6 Logistic Regression"></a>6 Logistic Regression</h2><p>Logistic Regression的作用就是不直接输出预测分数，而是加上一个logistic函数使得输出在0到1之间，作为概率的度量。</p>
<h3 id="6-1-Estimating-Probabilities"><a href="#6-1-Estimating-Probabilities" class="headerlink" title="6.1 Estimating Probabilities"></a>6.1 Estimating Probabilities</h3><script type="math/tex; mode=display">p=h_\theta (x) = \sigma (\theta ^T \cdot x)</script><script type="math/tex; mode=display">\sigma (t)=\frac{1}{1+exp(-t)}</script><h3 id="6-2-Training-and-Cost-Funtion"><a href="#6-2-Training-and-Cost-Funtion" class="headerlink" title="6.2 Training and Cost Funtion"></a>6.2 Training and Cost Funtion</h3><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\sum _{i=1}^m[y^{(i)}log(p^{(i)})+(1-y^{(i)})log(1-p^{(i)})]</script><p>这个式子没有闭式解， 但是其是凸函数，所以可以用梯度下降求出解。<br>其偏导数如下：</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \theta _j}J(\theta)=\frac{1}{m}\sum _{i=1}^m(\sigma(\theta ^T \cdot x^{(i)})-y^{(i)})x_j^{(i)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">log_reg = LogisticRegression()</div><div class="line"><span class="comment"># 也可对Logistic Regression添加正则项</span></div></pre></td></tr></table></figure>
<h3 id="6-3-Decision-Boundaries"><a href="#6-3-Decision-Boundaries" class="headerlink" title="6.3 Decision Boundaries"></a>6.3 Decision Boundaries</h3><h3 id="6-4-Softmax-Regression"><a href="#6-4-Softmax-Regression" class="headerlink" title="6.4 Softmax Regression"></a>6.4 Softmax Regression</h3><p>使得Logistic Regression支持多分类，也叫作Multinomial Logistic Regression。<br><strong>算法思路</strong><br>首先对每类计算score</p>
<script type="math/tex; mode=display">s_k(x)=\theta_k ^T \cdot x</script><p>然后计算每类的概率：</p>
<script type="math/tex; mode=display">p_k=\sigma (s(x))_k=\frac{exp(s_k(x))}{\sum _{j=1}^{K}exp(s_j(x))}</script><p>其类别预测方法：</p>
<script type="math/tex; mode=display">y=argmax_k\sigma(s(x))_k=argmax_k s_k(x)=argmax_k(\theta_k^T\cdot x)</script><p>使用Cross Entropy 作为损失函数：</p>
<script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\sum _{i=1}^m \sum _{k=1}^K y_k^{(i)}log(p_k^{(i)})</script><p>偏导数如下计算：</p>
<script type="math/tex; mode=display">\Delta_{\theta_k}J(\Theta)=\frac{1}{m}\sum_{i=1}^m(p_k^{(i)}-y_k^{(i)})x^{(i)}</script><p><strong>调包</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">softmax_reg = LogisticRegression(multi_class=<span class="string">'multinomial'</span>, solver=<span class="string">'lbfgs'</span>,C=<span class="number">10</span>)</div><div class="line">softmax_reg.fit(X,y)</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1、Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurélien Géron (O’Reilly). Copyright 2017 Aurélien Géron, 978-1-491-96229-9</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">sklearn</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/sklearn//" class="article-tag-list-link color3">sklearn</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/09/01/HOMLWSLATF-ch4/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-install-netcdf4-python" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/30/install-netcdf4-python/">Linux下安装netCDF4过程记录</a>
    </h1>
  

        
        <a href="/2018/08/30/install-netcdf4-python/" class="archive-article-date">
  	<time datetime="2018-08-30T14:01:59.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDF5安装"><span class="toc-text">HDF5安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#netCDF-4-C-library-安装"><span class="toc-text">netCDF-4 C library 安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装netCDF4-python包"><span class="toc-text">安装netCDF4 python包</span></a></li></ol>
</div>

        <p><a href="http://unidata.github.io/netcdf4-python/" target="_blank" rel="external">netCDF4官方指南</a></p>
<h2 id="HDF5安装"><a href="#HDF5安装" class="headerlink" title="HDF5安装"></a>HDF5安装</h2><p><a href="https://www.hdfgroup.org/downloads/hdf5/source-code/" target="_blank" rel="external">HDF5网站</a><br><a href="https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.10/hdf5-1.10.3/src/unpacked/hdf5-1.10.3/release_docs/INSTALL" target="_blank" rel="external">INSTALL FILE</a><br><strong>1、在HDF5网站上下载hdf5-1.10.3.tar.gz源码</strong><br><strong>2、在Ubuntu16.04上安装HDF5</strong><br>使用以下安装脚本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">tar zxf hdf5-1.10.3.tar.gz</div><div class="line"><span class="built_in">cd</span> hdf5-1.10.3</div><div class="line">./configure --prefix=/usr/<span class="built_in">local</span>/hdf5  --<span class="built_in">enable</span>-hl --<span class="built_in">enable</span>-shared</div><div class="line">make</div><div class="line">make check                <span class="comment"># run test suite.</span></div><div class="line">make install</div><div class="line">make check-install        <span class="comment"># verify installation.</span></div></pre></td></tr></table></figure></p>
<p>如果遇到安装失败，可能需要sudo make</p>
<h2 id="netCDF-4-C-library-安装"><a href="#netCDF-4-C-library-安装" class="headerlink" title="netCDF-4 C library 安装"></a>netCDF-4 C library 安装</h2><p><a href="https://github.com/Unidata/netcdf-c" target="_blank" rel="external">netCDF-4 C github repo</a><br><a href="https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html" target="_blank" rel="external">Build Instruction</a><br>1、下载netcdf-c-4.6.1.tar.gz<br>2、安装<br>使用以下脚本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Build and install netCDF-4</span></div><div class="line">tar zxf netcdf-c-4.6.1.tar.gz</div><div class="line"><span class="built_in">cd</span> netcdf-c-4.6.1</div><div class="line">NCDIR=/usr/<span class="built_in">local</span></div><div class="line">H5DIR=/usr/<span class="built_in">local</span>/hdf5</div><div class="line">CPPFLAGS=-I<span class="variable">$&#123;H5DIR&#125;</span>/include LDFLAGS=-L<span class="variable">$&#123;H5DIR&#125;</span>/lib ./configure --prefix=<span class="variable">$&#123;NCDIR&#125;</span> --<span class="built_in">enable</span>-netcdf-4 --<span class="built_in">enable</span>-shared</div><div class="line">sudo make check</div><div class="line">sudo make install  <span class="comment"># or sudo make install</span></div></pre></td></tr></table></figure></p>
<p>3、遇到问题：使用git clone下来的源码，没有configure，无法build。</p>
<h2 id="安装netCDF4-python包"><a href="#安装netCDF4-python包" class="headerlink" title="安装netCDF4 python包"></a>安装netCDF4 python包</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">USE_SETUPCFG=0 HDF5_INCDIR=/usr/include/hdf5/serial HDF5_LIBDIR=/usr/lib/x86_64-linux-gnu/hdf5/serial pip3 install netCDF4</div></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/linux//" class="article-tag-list-link color1">linux</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/30/install-netcdf4-python/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-HOMLWSLATF-ch3" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/30/HOMLWSLATF-ch3/">Chapter 3. Classification</a>
    </h1>
  

        
        <a href="/2018/08/30/HOMLWSLATF-ch3/" class="archive-article-date">
  	<time datetime="2018-08-30T13:41:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#MNIST"><span class="toc-text">MNIST</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-a-Binary-Classifier"><span class="toc-text">Training a Binary Classifier</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Performance-Measures"><span class="toc-text">Performance Measures</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-利用交叉验证-Cross-Validation-来验证模型"><span class="toc-text">3.1 利用交叉验证(Cross-Validation)来验证模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-混淆矩阵-Confusion-Matrix"><span class="toc-text">3.2 混淆矩阵(Confusion Matrix)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-准确率和召回率"><span class="toc-text">3.3 准确率和召回率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Precision-Recall-Tradeoff"><span class="toc-text">3.4 Precision/Recall Tradeoff</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-The-ROC-Curve"><span class="toc-text">3.5 The ROC Curve</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-总结"><span class="toc-text">3.5 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multiclass-classification"><span class="toc-text">Multiclass classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Error-Analysis"><span class="toc-text">Error Analysis</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multilabel-Classification"><span class="toc-text">Multilabel Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multioutput-Classiffication"><span class="toc-text">Multioutput Classiffication</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>《 Hands-On Machine Learning with Scikit-Learn and TensorFlow》笔记</p>
<h2 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h2><p>MNIST数据集介绍及载入</p>
<h2 id="Training-a-Binary-Classifier"><a href="#Training-a-Binary-Classifier" class="headerlink" title="Training a Binary Classifier"></a>Training a Binary Classifier</h2><p>使用sklearn包训练二分类器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">y_train_5 = (y_train == <span class="number">5</span>)</div><div class="line">y_test_5 = (y_test == <span class="number">5</span>)</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</div><div class="line">sgd_clf = SGDClassifier(random_state=<span class="number">42</span>)</div><div class="line">sgd_clf.fit(X_train, y_train_5)</div><div class="line"></div><div class="line">&gt;&gt; sgd_clf.predict([some_digit])</div><div class="line">array([<span class="keyword">True</span>], dtype=bool)</div></pre></td></tr></table></figure></p>
<h2 id="Performance-Measures"><a href="#Performance-Measures" class="headerlink" title="Performance Measures"></a>Performance Measures</h2><h3 id="3-1-利用交叉验证-Cross-Validation-来验证模型"><a href="#3-1-利用交叉验证-Cross-Validation-来验证模型" class="headerlink" title="3.1 利用交叉验证(Cross-Validation)来验证模型"></a>3.1 利用<strong>交叉验证</strong>(Cross-Validation)来验证模型</h3><p>有用函数: sklearn包中的<strong>cross_val_score</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</div><div class="line">cross_val_score(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">'accuracy'</span>)</div></pre></td></tr></table></figure></p>
<h3 id="3-2-混淆矩阵-Confusion-Matrix"><a href="#3-2-混淆矩阵-Confusion-Matrix" class="headerlink" title="3.2 混淆矩阵(Confusion Matrix)"></a>3.2 混淆矩阵(Confusion Matrix)</h3><p>使用函数 <strong>cross_val_predict</strong>和<strong>confusion_matrix</strong>计算混淆矩阵<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</div><div class="line">y_train_pred=cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>)</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</div><div class="line">cm=confusion_matrix(y_train_5,y_train_pred)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>cm</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>array([[<span class="number">53272</span>, <span class="number">1307</span>],</div><div class="line">    [<span class="number">1077</span>, <span class="number">4344</span>]])</div></pre></td></tr></table></figure></p>
<h3 id="3-3-准确率和召回率"><a href="#3-3-准确率和召回率" class="headerlink" title="3.3 准确率和召回率"></a>3.3 准确率和召回率</h3><p><strong>准确率(Precision)</strong> <script type="math/tex">precision=\frac{TP}{TP + FP}</script><br><strong>召回率(Recall)</strong> <script type="math/tex">recall=\frac{TP}{TP + FN}</script><br><strong>F1分数(F1 score)</strong><script type="math/tex">F_1=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}=2 \times \frac{precision \cdot recall}{precision + recall} =  \frac {TP}{TP+\frac{FN + FP}{2}}</script><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score,f1_score</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>precision_score(y_train_5, y_pred)</div><div class="line"><span class="number">0.768</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>recall_score(y_train_5,y_train_pred)</div><div class="line"><span class="number">0.791</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train_5, y_pred)</div><div class="line"><span class="number">0.784</span></div></pre></td></tr></table></figure></p>
<p>F1 score favors classifiers that have similar precision and recall.</p>
<h3 id="3-4-Precision-Recall-Tradeoff"><a href="#3-4-Precision-Recall-Tradeoff" class="headerlink" title="3.4 Precision/Recall Tradeoff"></a>3.4 Precision/Recall Tradeoff</h3><p>分类器在做预测时根据预测的分数来决定时属于正类还是反类,我们需要设定一个分数<strong>阈值(threshold)</strong>来作为划分,低阈值的选取对应高的recall和低的precision,而高阈值的选取对应了高的precision和低的recall。<br>实践中我们可以使用sklearn中的<strong>decsion_function</strong>获得分数，并指定分类阈值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>y_scores = sgd_clf.decision_function([some_digit])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>y_scores</div><div class="line">array([<span class="number">161855.555</span>])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>threshold = <span class="number">0</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>y_some_digit_pred = (y_scores &gt; threshold)</div><div class="line">array([ <span class="keyword">True</span>], dtype=bool)</div></pre></td></tr></table></figure></p>
<p>还可以使用<strong>precision_recall_curve</strong>计算recall、precision曲线。<br>根据recall、precision曲线，我们就可以按照特定的场景需求来合理选择阈值。</p>
<h3 id="3-5-The-ROC-Curve"><a href="#3-5-The-ROC-Curve" class="headerlink" title="3.5 The ROC Curve"></a>3.5 The ROC Curve</h3><p>和准确率/召回率曲线类似，其是衡量 <em>true positive rate</em>(TPR) 和<em>false negative rate</em>的关系.<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</div><div class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)</div></pre></td></tr></table></figure></p>
<p> 该曲线包围的面积(<em>area under the curve(AUC)</em>)越大,说明分类器越好.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores)</div><div class="line"><span class="number">0.9706</span></div></pre></td></tr></table></figure></p>
<h3 id="3-5-总结"><a href="#3-5-总结" class="headerlink" title="3.5 总结"></a>3.5 总结</h3><p>训练二分类器的一般流程如下:<br>1、选择合适的metrics作为评价指标<br>2、 使用交叉验证训练模型<br>3、取得precision/recall的平衡来满足需求<br>4、利用ROC curves和ROC AUC scores来比较不同模型的性能</p>
<h2 id="Multiclass-classification"><a href="#Multiclass-classification" class="headerlink" title="Multiclass classification"></a>Multiclass classification</h2><p>一些算法可以直接进行多分类，如随机森林、朴素贝叶斯等，而另外一些算法只能进行二分类，如支持向量机、线性分类器等。<br>有很多策略可以将二分类算法推广到多分类任务中：<br><em>one-versus-all</em>(<strong>OvA</strong>): 训练N个二分类器，每个二分类器负责预测一个label。<br><em>one-versus-one</em>(<strong>OvO</strong>):训练N*(N-1)个二分类器，每个二分类器负责预测一对label。<br>对于SVM来说，使用OvO策略更好，对于绝大多数算法，更推荐使用OvA策略。<br>sklearn包针对多分类任务自动选择OvA策略(SVM例外)。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.fit(X_train, y_train)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.predict([some_digit])</div><div class="line">array([<span class="number">5.</span>])</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>some_digit_scores = sgd_clf.decision_function([some_digit])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>some_digit_scores</div><div class="line">array([[...</div><div class="line">]])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(some_digit_scores)</div><div class="line"><span class="number">5</span></div></pre></td></tr></table></figure></p>
<p>也可以使用<strong>OneVsOneClassifier</strong>或者<strong>OneVsRestClassifier</strong>类自定义策略。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsOneClassifier</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=<span class="number">42</span>))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf.fit(X_train,y_train)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>onv_clf.predict([some_digit])</div><div class="line">array([<span class="number">5.</span>])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>len(ovo_clf.estimators_)</div><div class="line"><span class="number">45</span></div></pre></td></tr></table></figure></p>
<p>对于随机森林等可以直接进行多分类，不需要使用OvO或者OvA策略。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.fit(X_train, y_train)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.predict([some_digit])</div><div class="line">array([<span class="number">5.</span>])</div><div class="line"><span class="comment"># 可以使用predict_proba方法得到预测各类的概率</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.predict_proba([some_digit])</div><div class="line">array([[<span class="number">0.1</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.1</span>, <span class="number">0.</span>, <span class="number">0.8</span>, ...]])</div></pre></td></tr></table></figure></p>
<h2 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h2><p>找到合适的模型之后，我们想要更进一步的提升，对错误的分析就很有必要。<br><strong>分析混淆矩阵</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=<span class="number">3</span> )</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>conf_mx = confusion_matrix(y_train, y_train_pred)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>conf_mx</div><div class="line">array([[<span class="number">5725</span>, <span class="number">3</span>, <span class="number">24</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">49</span>, <span class="number">50</span>, <span class="number">10</span>, <span class="number">39</span>, <span class="number">4</span>],</div><div class="line">        [<span class="number">2</span>, <span class="number">6493</span>, <span class="number">43</span>, ...],</div><div class="line">        ...])</div></pre></td></tr></table></figure></p>
<p>对混淆矩阵进行一些可视化的操作之后，我们可以方便看出一些错误原因，并针对这些错误原因做进一步的优化。具体的分析方法根据实际情况而异。</p>
<h2 id="Multilabel-Classification"><a href="#Multilabel-Classification" class="headerlink" title="Multilabel Classification"></a>Multilabel Classification</h2><p>有时我们需要为一个实例输出多个标签，这就需要用到<strong>Multilabel Classification</strong>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 简单例子</span></div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line">y_train_large = (y_train &gt;= <span class="number">7</span>)</div><div class="line">y_train_odd = (y_train % <span class="number">2</span> == <span class="number">1</span>)</div><div class="line">y_multilabel = np.c_[y_train_large, y_train_odd]</div><div class="line"></div><div class="line">knn_clf = KNeighborsClassifier()</div><div class="line">knn_clf.fit(X_train, y_multilabel)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>knn_clf.predict([some_digit])</div><div class="line">array([[<span class="keyword">False</span>, <span class="keyword">True</span>]], dtype=bool)</div></pre></td></tr></table></figure></p>
<p>有多种方法可以验证多标签的分类器，一种方法是对于每个标签计算它的F1分数，然后取平均来评价。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=<span class="number">3</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train, y_train_knn_pred, average=<span class="string">'macro'</span>)</div><div class="line"><span class="number">0.9684</span></div></pre></td></tr></table></figure></p>
<p>以上这种方法是建立在每个标签重要性相同的前提下的，然而实际情况可能并非如此。可以改变average参数来设置各个标签的权重。具体参考sklearn的文档。</p>
<h2 id="Multioutput-Classiffication"><a href="#Multioutput-Classiffication" class="headerlink" title="Multioutput Classiffication"></a>Multioutput Classiffication</h2><p><strong>举例</strong><br>图片去噪问题，输入是一张含有噪声的图像，输出是去噪了的图像，这算是一个<strong>Multioutput Classification</strong>问题。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">noise_train = rnd.randint(<span class="number">0</span>,<span class="number">100</span>,(len(X_train), <span class="number">784</span>))</div><div class="line">noise_test = rnd.randint(<span class="number">0</span>,<span class="number">100</span>,(len(X_test), <span class="number">784</span>))</div><div class="line">X_train_mod = X_train + noise_train</div><div class="line">X_test_mod = X_test + noise_test</div><div class="line">y_train_mod = X_train</div><div class="line">y_test_mod = X_test</div><div class="line"></div><div class="line">knn_clf.fit(X_train_mod, y_train_mod)</div><div class="line">clean_digit=knn_clf.predict([X_test_mod[some_index]])</div><div class="line">plot_digit(clean_digit)</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1、Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurélien Géron (O’Reilly). Copyright 2017 Aurélien Géron, 978-1-491-96229-9</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">sklearn</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/sklearn//" class="article-tag-list-link color3">sklearn</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/30/HOMLWSLATF-ch3/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-titanic-dl" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/23/titanic-dl/">用神经网络解决Titanic问题</a>
    </h1>
  

        
        <a href="/2018/08/23/titanic-dl/" class="archive-article-date">
  	<time datetime="2018-08-23T05:21:36.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#使用Pytorch搭建模型"><span class="toc-text">使用Pytorch搭建模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据载入和处理"><span class="toc-text">数据载入和处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用skorch搭建模型"><span class="toc-text">使用skorch搭建模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>使用神经网络解决Titanic问题，主要用两种实现，一种是纯pytorch实现神经网络的搭建，另一种是使用skorch包装好的以pytorch为后端的API实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> copy</div><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div><div class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</div><div class="line"><span class="keyword">import</span> torch.nn.functional</div><div class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</div><div class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">import</span> torch</div><div class="line">torch.manual_seed(<span class="number">0</span>)</div><div class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</div><div class="line">print(torch.__version__)</div></pre></td></tr></table></figure>
<pre><code>0.4.1
</code></pre><p>读入数据文件，这里省去了特征工程的部分，特征采用之前特征工程提取出的特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">train=pd.read_csv(<span class="string">'train_features.csv'</span>)</div><div class="line">test=pd.read_csv(<span class="string">'test_features.csv'</span>)</div><div class="line">train.head()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.info()</div></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 13 columns):
PassengerId        891 non-null int64
Pclass             891 non-null int64
Sex                891 non-null int64
Title              891 non-null int64
Family_size        891 non-null int64
Family_Survival    891 non-null float64
FareBin_Code       891 non-null int64
AgeBin_Code        891 non-null int64
Embarked_C         891 non-null int64
Embarked_None      891 non-null int64
Embarked_Q         891 non-null int64
Embarked_S         891 non-null int64
Survived           891 non-null float64
dtypes: float64(2), int64(11)
memory usage: 90.6 KB
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.describe()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">X_train=train.drop([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>],axis=<span class="number">1</span>).as_matrix()</div><div class="line">Y_train=train[<span class="string">'Survived'</span>].astype(int).as_matrix()</div><div class="line"></div><div class="line">X_test=test.drop([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>],axis=<span class="number">1</span>).as_matrix()</div><div class="line">IDtest=test[<span class="string">'PassengerId'</span>]</div><div class="line"></div><div class="line"><span class="comment"># scalar</span></div><div class="line">scaler=MinMaxScaler()</div><div class="line">X_train=scaler.fit_transform(X_train)</div><div class="line">X_test=scaler.transform(X_test)</div></pre></td></tr></table></figure>
<h1 id="使用Pytorch搭建模型"><a href="#使用Pytorch搭建模型" class="headerlink" title="使用Pytorch搭建模型"></a>使用Pytorch搭建模型</h1><h2 id="数据载入和处理"><a href="#数据载入和处理" class="headerlink" title="数据载入和处理"></a>数据载入和处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TitanicFeaturesDataset</span><span class="params">(Dataset)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,X,y=None,transform=None)</span>:</span></div><div class="line">        self.X=X</div><div class="line">        self.y=y</div><div class="line">        self.transform=transform</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.X.shape[<span class="number">0</span>]</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,idx)</span>:</span></div><div class="line">        <span class="keyword">if</span> self.y <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            sample=&#123;<span class="string">'X'</span>:self.X[idx],<span class="string">'y'</span>:self.y[idx]&#125;</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            sample=&#123;<span class="string">'X'</span>:self.X[idx]&#125;</div><div class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            sample=self.transform(sample)</div><div class="line">        <span class="keyword">return</span> sample</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># transform class</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToTensor</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self,sample)</span>:</span></div><div class="line">        <span class="keyword">if</span> <span class="string">'y'</span> <span class="keyword">in</span> sample.keys():</div><div class="line">            X,y=sample[<span class="string">'X'</span>],sample[<span class="string">'y'</span>]</div><div class="line">            <span class="keyword">return</span> &#123;</div><div class="line">                <span class="string">'X'</span>:torch.from_numpy(X.astype(np.float32)),</div><div class="line">                <span class="string">'y'</span>:torch.squeeze(torch.from_numpy(np.array([y.astype(np.int64)])))</div><div class="line">            &#125;</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            X=sample[<span class="string">'X'</span>]</div><div class="line">            <span class="keyword">return</span> &#123;</div><div class="line">                <span class="string">'X'</span>:torch.from_numpy(X.astype(np.float32))</div><div class="line">            &#125;</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Model class</span></div><div class="line"><span class="comment"># 自定义Model需要继承nn.Module</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassifierModule</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,D_in=<span class="number">11</span>,D_out=<span class="number">2</span>,num_units=<span class="number">20</span>,nonlin=F.relu,dropout=<span class="number">0.5</span>)</span>:</span></div><div class="line">        super(ClassifierModule,self).__init__()</div><div class="line">        self.num_units=num_units</div><div class="line">        self.nonlin=nonlin</div><div class="line">        self.dropout=nn.Dropout(dropout)</div><div class="line">        </div><div class="line">        self.linear1=nn.Linear(D_in,num_units)</div><div class="line">        self.linear2=nn.Linear(num_units,<span class="number">10</span>)</div><div class="line">        self.output=nn.Linear(<span class="number">10</span>,<span class="number">2</span>)</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,X)</span>:</span></div><div class="line">        X=self.nonlin(self.linear1(X))</div><div class="line">        X=self.dropout(X)</div><div class="line">        X=self.nonlin(self.linear2(X))</div><div class="line">        X=self.dropout(X)</div><div class="line">        X=self.output(X)</div><div class="line">        <span class="keyword">return</span> X</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># train model</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model,criterion,optimiizer,scheduler,dataset_sizes,num_epochs=<span class="number">100</span>,device=<span class="string">'cpu'</span>)</span>:</span></div><div class="line">    start=time.time()</div><div class="line">    best_model_wts=copy.deepcopy(model.state_dict())</div><div class="line">    best_acc=<span class="number">0.0</span></div><div class="line">    </div><div class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</div><div class="line">        print(<span class="string">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch,num_epochs<span class="number">-1</span>))</div><div class="line">        print(<span class="string">'-'</span>*<span class="number">10</span>)</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">'train'</span>,<span class="string">'val'</span>]:</div><div class="line">            <span class="keyword">if</span> phase == <span class="string">'train'</span>:</div><div class="line">                scheduler.step()</div><div class="line">                model.train()</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                model.eval()</div><div class="line">            running_loss=<span class="number">0.0</span></div><div class="line">            running_corrects=<span class="number">0</span></div><div class="line">            <span class="keyword">for</span> sample_batches <span class="keyword">in</span> dataloaders[phase]:</div><div class="line">                inputs=sample_batches[<span class="string">'X'</span>].to(device)</div><div class="line">                labels=sample_batches[<span class="string">'y'</span>].to(device)</div><div class="line">                </div><div class="line">                optimizer.zero_grad()</div><div class="line">                </div><div class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase==<span class="string">'train'</span>):</div><div class="line">                    outputs=model(inputs)</div><div class="line">                    _,preds=torch.max(outputs,<span class="number">1</span>)</div><div class="line">                    loss=criterion(outputs,labels)</div><div class="line">                    </div><div class="line">                    <span class="keyword">if</span> phase==<span class="string">'train'</span>:</div><div class="line">                        loss.backward()</div><div class="line">                        optimizer.step()</div><div class="line">                    running_loss+=loss.item()*inputs.size(<span class="number">0</span>)</div><div class="line">                    running_corrects+=torch.sum(preds==labels.data)</div><div class="line">            epoch_loss=running_loss/dataset_sizes[phase]</div><div class="line">            epoch_acc=running_corrects.double()/dataset_sizes[phase]</div><div class="line">            print(<span class="string">'&#123;&#125; loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;'</span>.format(phase,epoch_loss,epoch_acc))</div><div class="line">            </div><div class="line">            <span class="keyword">if</span> phase==<span class="string">'val'</span> <span class="keyword">and</span> epoch_acc&gt;best_acc:</div><div class="line">                best_acc=epoch_acc</div><div class="line">                best_model_wts=copy.deepcopy(model.state_dict())</div><div class="line">    time_elapsed=time.time()-start</div><div class="line">    print(<span class="string">'Trainning complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(</div><div class="line">            time_elapsed//<span class="number">60</span>,time_elapsed%<span class="number">60</span>))</div><div class="line">    print(<span class="string">'Best val Acc: &#123;:4f&#125;'</span>.format(best_acc))</div><div class="line">    model.load_state_dict(best_model_wts)</div><div class="line">    <span class="keyword">return</span> model</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># load data and train</span></div><div class="line">train_dataset_len=X_train.shape[<span class="number">0</span>]</div><div class="line">train_len=train_dataset_len*<span class="number">4</span>//<span class="number">5</span></div><div class="line"></div><div class="line">transformed_datasets = &#123;</div><div class="line">        <span class="string">'train'</span>: TitanicFeaturesDataset(X_train[:train_len],Y_train[:train_len], transform=transforms.Compose([ToTensor()])),</div><div class="line">        <span class="string">'val'</span>: TitanicFeaturesDataset(X_train[train_len:], Y_train[train_len:], transform=transforms.Compose([ToTensor()])),</div><div class="line">        <span class="string">'test'</span>:TitanicFeaturesDataset(X_test,transform=transforms.Compose([ToTensor()]))</div><div class="line">        &#125;</div><div class="line"></div><div class="line">dataloaders = &#123;x: DataLoader(transformed_datasets[x], batch_size=<span class="number">16</span>,</div><div class="line">                                 shuffle=<span class="keyword">True</span>, num_workers=<span class="number">0</span>)</div><div class="line">                   <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>]&#125;</div><div class="line">dataloaders[<span class="string">'test'</span>]=DataLoader(transformed_datasets[<span class="string">'test'</span>],batch_size=<span class="number">16</span>,shuffle=<span class="keyword">False</span>,num_workers=<span class="number">0</span>)</div><div class="line"></div><div class="line">dataset_sizes = &#123;x: len(transformed_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>,<span class="string">'test'</span>]&#125;</div><div class="line">device = torch.device(<span class="string">'cuda:0'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">model=ClassifierModule()</div><div class="line"><span class="comment"># 这里就包含了softmax</span></div><div class="line">criterion=nn.CrossEntropyLoss()</div><div class="line">optimizer=optim.SGD(model.parameters(),lr=<span class="number">2e-2</span>,momentum=<span class="number">0.9</span>)</div><div class="line">exp_lr_scheduler=lr_scheduler.StepLR(optimizer,step_size=<span class="number">7</span>,gamma=<span class="number">0.1</span>)</div><div class="line"></div><div class="line">model=train_model(model,criterion,optimizer,exp_lr_scheduler,dataset_sizes,num_epochs=<span class="number">100</span>,device=device)</div></pre></td></tr></table></figure>
<pre><code>Epoch 0/99
----------
train loss: 0.6819 Acc: 0.5674
val loss: 0.6576 Acc: 0.6425
Epoch 1/99
----------
train loss: 0.6624 Acc: 0.6096
val loss: 0.6418 Acc: 0.6425
Epoch 2/99
----------
...
Epoch 97/99
----------
train loss: 0.4965 Acc: 0.7598
val loss: 0.3836 Acc: 0.8603
Epoch 98/99
----------
train loss: 0.4819 Acc: 0.7556
val loss: 0.3836 Acc: 0.8603
Epoch 99/99
----------
train loss: 0.4981 Acc: 0.7626
val loss: 0.3836 Acc: 0.8603
Trainning complete in 0m 9s
Best val Acc: 0.877095
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># save model and reload it</span></div><div class="line">torch.save(model.state_dict(),<span class="string">'pytorch_model.pth'</span>)</div><div class="line">reloaded_model=ClassifierModule()</div><div class="line">reloaded_model.load_state_dict(torch.load(<span class="string">'pytorch_model.pth'</span>))</div><div class="line"><span class="comment"># predicts on  test dataset</span></div><div class="line"></div><div class="line">reloaded_model.eval()</div><div class="line">final_predicts=[]</div><div class="line"><span class="keyword">with</span> torch.no_grad():</div><div class="line">    <span class="keyword">for</span> samples <span class="keyword">in</span> dataloaders[<span class="string">'test'</span>]:</div><div class="line">        inputs=samples[<span class="string">'X'</span>].to(device)</div><div class="line">        outputs=reloaded_model(inputs)</div><div class="line">        _,preds=torch.max(outputs,<span class="number">1</span>)</div><div class="line">        <span class="keyword">for</span> y_predict <span class="keyword">in</span> list(preds.numpy()):</div><div class="line">            final_predicts.append(y_predict)</div><div class="line">final_predicts=np.array(final_predicts).reshape(<span class="number">-1</span>,)</div><div class="line">predict_survived_pytorch=pd.Series(final_predicts,name=<span class="string">'Survived'</span>)</div><div class="line">pytorch_result=pd.concat([IDtest,predict_survived_pytorch],axis=<span class="number">1</span>)</div><div class="line">pytorch_result.to_csv(<span class="string">'pytorch_result.csv'</span>,index=<span class="keyword">False</span>)</div><div class="line">pytorch_result.head()</div></pre></td></tr></table></figure>
<h1 id="使用skorch搭建模型"><a href="#使用skorch搭建模型" class="headerlink" title="使用skorch搭建模型"></a>使用skorch搭建模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> skorch <span class="keyword">import</span> NeuralNetClassifier</div><div class="line"><span class="keyword">from</span> skorch.dataset <span class="keyword">import</span> CVSplit</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">import</span> skorch</div><div class="line">print(skorch.__version__)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">skorchModule</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_units=<span class="number">20</span>)</span>:</span></div><div class="line">        super(skorchModule,self).__init__()</div><div class="line">        self.net=ClassifierModule(num_units=num_units)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,X)</span>:</span></div><div class="line">        X=self.net(X)</div><div class="line">        X=F.softmax(X,dim=<span class="number">-1</span>)</div><div class="line">        <span class="keyword">return</span> X</div><div class="line">        </div><div class="line">        </div><div class="line">model = NeuralNetClassifier(</div><div class="line">        skorchModule,</div><div class="line">        max_epochs=<span class="number">200</span>,</div><div class="line">        lr=<span class="number">0.02</span>,</div><div class="line">        train_split=CVSplit(<span class="number">5</span>),</div><div class="line">        <span class="comment">#     device='cuda',  # uncomment this to train with CUDA</span></div><div class="line">    )</div><div class="line">   </div><div class="line"></div><div class="line">X = X_train.astype(np.float32)</div><div class="line">Y = Y_train.astype(np.int64)</div><div class="line"></div><div class="line">params = &#123;</div><div class="line">        <span class="string">'lr'</span>: [<span class="number">0.02</span>],</div><div class="line">        <span class="string">'max_epochs'</span>: [<span class="number">200</span>],</div><div class="line">        <span class="string">'module__num_units'</span>: [<span class="number">20</span>],</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># 用scoring='neg_log_loss'训练不正确？不知道为啥，只好在Module层加入softmax</span></div><div class="line">gs = GridSearchCV(model, params, refit=<span class="keyword">True</span>, cv=<span class="number">2</span>, scoring=<span class="string">'accuracy'</span>)</div><div class="line"></div><div class="line">gs.fit(X, Y)</div><div class="line">print(gs.best_score_, gs.best_params_)</div><div class="line">gs.estimator.set_params(**gs.best_params_).fit(X, Y)</div><div class="line"></div><div class="line">predict_Survived_skorch = pd.Series(gs.predict(X_test.astype(np.float32)), name=<span class="string">'Survived'</span>)</div><div class="line">skorch_result = pd.concat([IDtest, predict_Survived_skorch], axis=<span class="number">1</span>)</div><div class="line">skorch_result.to_csv(<span class="string">'skorch_result.csv'</span>, index=<span class="keyword">False</span>)</div><div class="line">skorch_result.head()</div></pre></td></tr></table></figure>
<pre><code>0.3.0
  epoch    train_loss    valid_acc    valid_loss     dur
-------  ------------  -----------  ------------  ------
      1        0.7777       0.3596        0.7712  0.0215
      ...

  epoch    train_loss    valid_acc    valid_loss     dur
-------  ------------  -----------  ------------  ------
      1        0.6797       0.6704        0.6408  0.0250
      2        0.6756       0.6704        0.6409  0.0250
      3        0.6767       0.6704        0.6409  0.0250
      ...
    200        0.5370       0.7709        0.4915  0.0200
0.7845117845117845 {&#39;lr&#39;: 0.02, &#39;max_epochs&#39;: 200, &#39;module__num_units&#39;: 20}
  epoch    train_loss    valid_acc    valid_loss     dur
-------  ------------  -----------  ------------  ------
      1        0.7113       0.6704        0.6715  0.0190
      2        0.7007       0.6704        0.6704  0.0264
    ...
    199        0.5825       0.7989        0.5358  0.0220
    200        0.5838       0.7989        0.5350  0.0240
</code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、<a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#" target="_blank" rel="external">Pytorch data_loading tutorial</a></p>
<p>2、<a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" target="_blank" rel="external">Pytorch_transfer_learning_tutorial</a></p>
<p>3、<a href="https://nbviewer.jupyter.org/github/dnouri/skorch/blob/master/notebooks/Basic_Usage.ipynb" target="_blank" rel="external">skorch basic usage</a></p>
<p>4、<a href="https://github.com/wwdguu/wwdguu.github.io/tree/master/2018/08/23/titanic-dl/titanic_dl.ipynb" target="_blank" rel="external">notebook</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/23/titanic-dl/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-titanic" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/11/titanic/">Kaggle入门赛之Titanic</a>
    </h1>
  

        
        <a href="/2018/08/11/titanic/" class="archive-article-date">
  	<time datetime="2018-08-11T09:44:33.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-11</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#数据分析"><span class="toc-text">数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#填充缺失值"><span class="toc-text">填充缺失值</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scale以及模型选择"><span class="toc-text">Scale以及模型选择</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>本文是初次参加Kaggle入门赛Titanic生还预测的一个过程记录，通过这个比赛，主要熟悉了pandas以及sklearn包的使用，对于常见的分类问题有了一定的了解。现将数据分析的过程记录如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> xgboost</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder, LabelEncoder,StandardScaler,MinMaxScaler</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier,RandomForestRegressor</div><div class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</div><div class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, cross_val_score, StratifiedKFold, learning_curve</div><div class="line"><span class="keyword">from</span> mlxtend.classifier <span class="keyword">import</span> StackingClassifier</div></pre></td></tr></table></figure>
<h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">train_df=pd.read_csv(<span class="string">'data/train.csv'</span>)</div><div class="line">test_df=pd.read_csv(<span class="string">'data/test.csv'</span>)</div><div class="line">data_all=pd.concat([train_df,test_df],ignore_index=<span class="keyword">True</span>)</div><div class="line">train_len=train_df.shape[<span class="number">0</span>]</div><div class="line">print(train_df.shape)</div><div class="line">print(test_df.shape)</div></pre></td></tr></table></figure>
<pre><code>(891, 12)
(418, 11)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data_all.info()</div></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1309 entries, 0 to 1308
Data columns (total 12 columns):
Age            1046 non-null float64
Cabin          295 non-null object
Embarked       1307 non-null object
Fare           1308 non-null float64
Name           1309 non-null object
Parch          1309 non-null int64
PassengerId    1309 non-null int64
Pclass         1309 non-null int64
Sex            1309 non-null object
SibSp          1309 non-null int64
Survived       891 non-null float64
Ticket         1309 non-null object
dtypes: float64(3), int64(4), object(5)
memory usage: 122.8+ KB
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">n = data_all.drop([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>], axis=<span class="number">1</span>).loc[:, data_all.isnull().any()].isnull().sum()</div><div class="line">print(<span class="string">'ALL:'</span>, data_all.shape[<span class="number">0</span>])</div><div class="line">print(<span class="string">'-'</span> * <span class="number">30</span>)</div><div class="line">print(n.sort_values(ascending=<span class="keyword">False</span>))</div></pre></td></tr></table></figure>
<pre><code>ALL: 1309
------------------------------
Cabin       1014
Age          263
Embarked       2
Fare           1
dtype: int64
</code></pre><h2 id="填充缺失值"><a href="#填充缺失值" class="headerlink" title="填充缺失值"></a>填充缺失值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## Cabin缺失较多 考虑将其分为 有值和无值两类 或者直接弃用</span></div><div class="line"><span class="comment"># 这里直接弃用</span></div><div class="line"></div><div class="line"><span class="comment">## Fare只缺1个值，用均值或中值填充，这里采用中值填充</span></div><div class="line">data_all[<span class="string">'Fare'</span>].fillna(data_all[<span class="string">'Fare'</span>].median(),inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">## Embarked缺失2个值，为object类型，这里考虑添加一组新值，以"None"填充</span></div><div class="line">data_all[<span class="string">'Embarked'</span>].fillna(<span class="string">'None'</span>,inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">## Age对于预测很重要，这里考虑用机器学习的方法对其进行预测填充，考虑到Age和SibSp,Parch以及Pclass，Fare等因素有关</span></div><div class="line"><span class="comment"># 分析Age的影响因素</span></div><div class="line"></div><div class="line"><span class="comment"># 性别可能对age有影响，先将sex转化为数值类型</span></div><div class="line"><span class="comment"># convert Sex into categorical value 0 for male and 1 for female</span></div><div class="line">data_all[<span class="string">"Sex"</span>] = data_all[<span class="string">"Sex"</span>].map(&#123;<span class="string">"male"</span>: <span class="number">0</span>, <span class="string">"female"</span>:<span class="number">1</span>&#125;)</div><div class="line"></div><div class="line">g = sns.heatmap(data_all[[<span class="string">"Age"</span>,<span class="string">"Sex"</span>,<span class="string">"SibSp"</span>,<span class="string">"Parch"</span>,<span class="string">"Pclass"</span>,<span class="string">"Fare"</span>]].corr(),cmap=<span class="string">"BrBG"</span>,annot=<span class="keyword">True</span>)</div><div class="line"><span class="comment"># 分析出Age与Sex关系较小，而与其它几个属性都有一定关系</span></div><div class="line"><span class="comment"># 考虑使用RF模型结合其它几个属性对Age进行预测填充</span></div><div class="line"></div><div class="line"><span class="comment"># 把已有的数值型特征取出来丢进Random Forest Regressor中</span></div><div class="line">age_df = data_all[[<span class="string">'Age'</span>, <span class="string">'Fare'</span>, <span class="string">'Parch'</span>, <span class="string">'SibSp'</span>, <span class="string">'Pclass'</span>]]</div><div class="line"><span class="comment"># 乘客分成已知年龄和未知年龄两部分</span></div><div class="line">known_age = age_df[age_df.Age.notnull()].as_matrix()</div><div class="line">unknown_age = age_df[age_df.Age.isnull()].as_matrix()</div><div class="line"><span class="comment"># y即目标年龄</span></div><div class="line">y = known_age[:, <span class="number">0</span>]</div><div class="line"><span class="comment"># X即特征属性值</span></div><div class="line">X = known_age[:, <span class="number">1</span>:]</div><div class="line"></div><div class="line"><span class="comment"># fit到RandomForestRegressor之中</span></div><div class="line">rfr = RandomForestRegressor(random_state=<span class="number">0</span>, n_estimators=<span class="number">2000</span>, n_jobs=<span class="number">-1</span>)</div><div class="line">rfr.fit(X, y)</div><div class="line"><span class="comment"># 用得到的模型进行未知年龄结果预测</span></div><div class="line">predictedAges = rfr.predict(unknown_age[:, <span class="number">1</span>::])</div><div class="line"><span class="comment"># 用得到的预测结果填补原缺失数据</span></div><div class="line">data_all.loc[(data_all.Age.isnull()), <span class="string">'Age'</span>] = predictedAges</div></pre></td></tr></table></figure>
<p><img src="output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 显示数值类型的统计结果</span></div><div class="line">print(<span class="string">'number describe:\n'</span>,data_all.drop([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>],axis=<span class="number">1</span>).describe(include=[<span class="string">'number'</span>]).loc[[<span class="string">'min'</span>, <span class="string">'max'</span>, <span class="string">'mean'</span>,<span class="string">'std'</span>,<span class="string">'count'</span>]].T.sort_values(<span class="string">'max'</span>))</div><div class="line"></div><div class="line"><span class="comment"># 看出Age的缺失值已经被填充</span></div></pre></td></tr></table></figure>
<pre><code>number describe:
          min       max       mean        std   count
Sex     0.00    1.0000   0.355997   0.478997  1309.0
Pclass  1.00    3.0000   2.294882   0.837836  1309.0
SibSp   0.00    8.0000   0.498854   1.041658  1309.0
Parch   0.00    9.0000   0.385027   0.865560  1309.0
Age     0.17   80.0000  29.876751  13.447012  1309.0
Fare    0.00  512.3292  33.281086  51.741500  1309.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 显示object类型的取值</span></div><div class="line">print(<span class="string">'object describe:\n'</span>)</div><div class="line">n = data_all.select_dtypes(include=object)</div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> n.columns:</div><div class="line">    print(<span class="string">'&#123;:&lt;14&#125;'</span>.format(c),<span class="string">':'</span>,len(data_all[c].unique()),<span class="string">'\n'</span>,data_all[c].unique())</div></pre></td></tr></table></figure>
<pre><code>object describe:

Cabin          : 187 
 [nan &#39;C85&#39; &#39;C123&#39; &#39;E46&#39; &#39;G6&#39; &#39;C103&#39; &#39;D56&#39; &#39;A6&#39; &#39;C23 C25 C27&#39; &#39;B78&#39; &#39;D33&#39;
 &#39;B30&#39; &#39;C52&#39; &#39;B28&#39; &#39;C83&#39; &#39;F33&#39; &#39;F G73&#39; &#39;E31&#39; &#39;A5&#39; &#39;D10 D12&#39; &#39;D26&#39; &#39;C110&#39;
 &#39;B58 B60&#39; &#39;E101&#39; &#39;F E69&#39; &#39;D47&#39; &#39;B86&#39; &#39;F2&#39; &#39;C2&#39; &#39;E33&#39; &#39;B19&#39; &#39;A7&#39; &#39;C49&#39;
 &#39;F4&#39; &#39;A32&#39; &#39;B4&#39; &#39;B80&#39; &#39;A31&#39; &#39;D36&#39; &#39;D15&#39; &#39;C93&#39; &#39;C78&#39; &#39;D35&#39; &#39;C87&#39; &#39;B77&#39;
 &#39;E67&#39; &#39;B94&#39; &#39;C125&#39; &#39;C99&#39; &#39;C118&#39; &#39;D7&#39; &#39;A19&#39; &#39;B49&#39; &#39;D&#39; &#39;C22 C26&#39; &#39;C106&#39;
 &#39;C65&#39; &#39;E36&#39; &#39;C54&#39; &#39;B57 B59 B63 B66&#39; &#39;C7&#39; &#39;E34&#39; &#39;C32&#39; &#39;B18&#39; &#39;C124&#39; &#39;C91&#39;
 &#39;E40&#39; &#39;T&#39; &#39;C128&#39; &#39;D37&#39; &#39;B35&#39; &#39;E50&#39; &#39;C82&#39; &#39;B96 B98&#39; &#39;E10&#39; &#39;E44&#39; &#39;A34&#39;
 &#39;C104&#39; &#39;C111&#39; &#39;C92&#39; &#39;E38&#39; &#39;D21&#39; &#39;E12&#39; &#39;E63&#39; &#39;A14&#39; &#39;B37&#39; &#39;C30&#39; &#39;D20&#39; &#39;B79&#39;
 &#39;E25&#39; &#39;D46&#39; &#39;B73&#39; &#39;C95&#39; &#39;B38&#39; &#39;B39&#39; &#39;B22&#39; &#39;C86&#39; &#39;C70&#39; &#39;A16&#39; &#39;C101&#39; &#39;C68&#39;
 &#39;A10&#39; &#39;E68&#39; &#39;B41&#39; &#39;A20&#39; &#39;D19&#39; &#39;D50&#39; &#39;D9&#39; &#39;A23&#39; &#39;B50&#39; &#39;A26&#39; &#39;D48&#39; &#39;E58&#39;
 &#39;C126&#39; &#39;B71&#39; &#39;B51 B53 B55&#39; &#39;D49&#39; &#39;B5&#39; &#39;B20&#39; &#39;F G63&#39; &#39;C62 C64&#39; &#39;E24&#39; &#39;C90&#39;
 &#39;C45&#39; &#39;E8&#39; &#39;B101&#39; &#39;D45&#39; &#39;C46&#39; &#39;D30&#39; &#39;E121&#39; &#39;D11&#39; &#39;E77&#39; &#39;F38&#39; &#39;B3&#39; &#39;D6&#39;
 &#39;B82 B84&#39; &#39;D17&#39; &#39;A36&#39; &#39;B102&#39; &#39;B69&#39; &#39;E49&#39; &#39;C47&#39; &#39;D28&#39; &#39;E17&#39; &#39;A24&#39; &#39;C50&#39;
 &#39;B42&#39; &#39;C148&#39; &#39;B45&#39; &#39;B36&#39; &#39;A21&#39; &#39;D34&#39; &#39;A9&#39; &#39;C31&#39; &#39;B61&#39; &#39;C53&#39; &#39;D43&#39; &#39;C130&#39;
 &#39;C132&#39; &#39;C55 C57&#39; &#39;C116&#39; &#39;F&#39; &#39;A29&#39; &#39;C6&#39; &#39;C28&#39; &#39;C51&#39; &#39;C97&#39; &#39;D22&#39; &#39;B10&#39;
 &#39;E45&#39; &#39;E52&#39; &#39;A11&#39; &#39;B11&#39; &#39;C80&#39; &#39;C89&#39; &#39;F E46&#39; &#39;B26&#39; &#39;F E57&#39; &#39;A18&#39; &#39;E60&#39;
 &#39;E39 E41&#39; &#39;B52 B54 B56&#39; &#39;C39&#39; &#39;B24&#39; &#39;D40&#39; &#39;D38&#39; &#39;C105&#39;]
Embarked       : 4 
 [&#39;S&#39; &#39;C&#39; &#39;Q&#39; &#39;None&#39;]
Name           : 1307 
 [&#39;Braund, Mr. Owen Harris&#39;
 &#39;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&#39;
 &#39;Heikkinen, Miss. Laina&#39; ... &#39;Saether, Mr. Simon Sivertsen&#39;
 &#39;Ware, Mr. Frederick&#39; &#39;Peter, Master. Michael J&#39;]
Ticket         : 929 
 [&#39;A/5 21171&#39; &#39;PC 17599&#39; &#39;STON/O2. 3101282&#39; &#39;113803&#39; &#39;373450&#39; &#39;330877&#39;
 &#39;17463&#39; &#39;349909&#39; &#39;347742&#39; &#39;237736&#39; &#39;PP 9549&#39; &#39;113783&#39; &#39;A/5. 2151&#39;
    ...
 &#39;A.5. 3236&#39; &#39;SOTON/O.Q. 3101262&#39; &#39;359309&#39;]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#对object特征分组</span></div><div class="line"><span class="comment">#处理Name属性</span></div><div class="line">data_all[<span class="string">'Title'</span>] = data_all[<span class="string">'Name'</span>]</div><div class="line"><span class="comment"># Cleaning name and extracting Title</span></div><div class="line"><span class="keyword">for</span> name_string <span class="keyword">in</span> data_all[<span class="string">'Name'</span>]:</div><div class="line">    data_all[<span class="string">'Title'</span>] = data_all[<span class="string">'Name'</span>].str.extract(<span class="string">'([A-Za-z]+)\.'</span>, expand=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment"># Replacing rare titles with more common ones</span></div><div class="line">mapping = &#123;<span class="string">'Mlle'</span>: <span class="string">'Miss'</span>, <span class="string">'Major'</span>: <span class="string">'Mr'</span>, <span class="string">'Col'</span>: <span class="string">'Mr'</span>, <span class="string">'Sir'</span>: <span class="string">'Mr'</span>, <span class="string">'Don'</span>: <span class="string">'Mr'</span>, <span class="string">'Mme'</span>: <span class="string">'Miss'</span>,</div><div class="line">               <span class="string">'Jonkheer'</span>: <span class="string">'Mr'</span>, <span class="string">'Lady'</span>: <span class="string">'Mrs'</span>, <span class="string">'Capt'</span>: <span class="string">'Mr'</span>, <span class="string">'Countess'</span>: <span class="string">'Mrs'</span>, <span class="string">'Ms'</span>: <span class="string">'Miss'</span>, <span class="string">'Dona'</span>: <span class="string">'Mrs'</span>&#125;</div><div class="line">data_all.replace(&#123;<span class="string">'Title'</span>: mapping&#125;, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">g = sns.factorplot(x=<span class="string">"Title"</span>, y=<span class="string">"Survived"</span>,  data=data_all.iloc[:train_len,:],</div><div class="line">                   size=<span class="number">6</span>, kind=<span class="string">"bar"</span>, palette=<span class="string">"muted"</span>)</div><div class="line">g.despine(left=<span class="keyword">True</span>)</div><div class="line">g = g.set_ylabels(<span class="string">"survival probability"</span>)</div><div class="line"><span class="comment"># 分析得出女人小孩确实生存率更高</span></div></pre></td></tr></table></figure>
<p><img src="output_10_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对Title进行编码</span></div><div class="line">data_all[<span class="string">'Title'</span>].replace([<span class="string">'Mr'</span>,<span class="string">'Miss'</span>,<span class="string">'Mrs'</span>,<span class="string">'Master'</span>,<span class="string">'Rev'</span>,<span class="string">'Dr'</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>],inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 家族属性特征提取</span></div><div class="line"></div><div class="line"><span class="comment"># 合并Parch属性和SibSp属性，添加Family_size属性</span></div><div class="line">data_all[<span class="string">'Family_size'</span>]=data_all[<span class="string">'Parch'</span>]+data_all[<span class="string">'SibSp'</span>]+<span class="number">1</span></div><div class="line"></div><div class="line">g = sns.factorplot(x=<span class="string">"Parch"</span>, y=<span class="string">"Survived"</span>,  data=data_all.iloc[:train_len,:],</div><div class="line">                   size=<span class="number">6</span>, kind=<span class="string">"bar"</span>, palette=<span class="string">"muted"</span>)</div><div class="line">g.despine(left=<span class="keyword">True</span>)</div><div class="line">g = g.set_ylabels(<span class="string">"survival probability"</span>)</div><div class="line"></div><div class="line">g = sns.factorplot(x=<span class="string">"SibSp"</span>, y=<span class="string">"Survived"</span>,  data=data_all.iloc[:train_len,:],</div><div class="line">                   size=<span class="number">6</span>, kind=<span class="string">"bar"</span>, palette=<span class="string">"muted"</span>)</div><div class="line">g.despine(left=<span class="keyword">True</span>)</div><div class="line">g = g.set_ylabels(<span class="string">"survival probability"</span>)</div><div class="line"></div><div class="line"></div><div class="line">g = sns.factorplot(x=<span class="string">"Family_size"</span>, y=<span class="string">"Survived"</span>,  data=data_all.iloc[:train_len,:],</div><div class="line">                   size=<span class="number">6</span>, kind=<span class="string">"bar"</span>, palette=<span class="string">"muted"</span>)</div><div class="line">g.despine(left=<span class="keyword">True</span>)</div><div class="line">g = g.set_ylabels(<span class="string">"survival probability"</span>)</div><div class="line"></div><div class="line">g = sns.countplot(x=<span class="string">"Family_size"</span>, hue=<span class="string">"Survived"</span>, data=data_all.iloc[:train_len,:])</div></pre></td></tr></table></figure>
<p><img src="output_12_0.png" alt="png"></p>
<p><img src="output_12_1.png" alt="png"></p>
<p><img src="output_12_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 家族属性深挖</span></div><div class="line">data_all[<span class="string">'Last_Name'</span>] = data_all[<span class="string">'Name'</span>].apply(<span class="keyword">lambda</span> x: str.split(x, <span class="string">","</span>)[<span class="number">0</span>])</div><div class="line"></div><div class="line">DEFAULT_SURVIVAL_VALUE = <span class="number">0.5</span></div><div class="line">data_all[<span class="string">'Family_Survival'</span>] = DEFAULT_SURVIVAL_VALUE</div><div class="line"></div><div class="line"><span class="keyword">for</span> grp, grp_df <span class="keyword">in</span> data_all[[<span class="string">'Survived'</span>, <span class="string">'Name'</span>, <span class="string">'Last_Name'</span>, <span class="string">'Fare'</span>, <span class="string">'Ticket'</span>, <span class="string">'PassengerId'</span>,</div><div class="line">                                <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Age'</span>, <span class="string">'Cabin'</span>]].groupby([<span class="string">'Last_Name'</span>, <span class="string">'Fare'</span>]):</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (len(grp_df) != <span class="number">1</span>):</div><div class="line">        <span class="comment"># A Family group is found.</span></div><div class="line">        <span class="keyword">for</span> ind, row <span class="keyword">in</span> grp_df.iterrows():</div><div class="line">            smax = grp_df.drop(ind)[<span class="string">'Survived'</span>].max()</div><div class="line">            smin = grp_df.drop(ind)[<span class="string">'Survived'</span>].min()</div><div class="line">            passID = row[<span class="string">'PassengerId'</span>]</div><div class="line">            <span class="keyword">if</span> (smax == <span class="number">1.0</span>):</div><div class="line">                data_all.loc[data_all[<span class="string">'PassengerId'</span>] == passID, <span class="string">'Family_Survival'</span>] = <span class="number">1</span></div><div class="line">            <span class="keyword">elif</span> (smin == <span class="number">0.0</span>):</div><div class="line">                data_all.loc[data_all[<span class="string">'PassengerId'</span>] == passID, <span class="string">'Family_Survival'</span>] = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> _, grp_df <span class="keyword">in</span> data_all.groupby(<span class="string">'Ticket'</span>):</div><div class="line">    <span class="keyword">if</span> (len(grp_df) != <span class="number">1</span>):</div><div class="line">        <span class="keyword">for</span> ind, row <span class="keyword">in</span> grp_df.iterrows():</div><div class="line">            <span class="keyword">if</span> (row[<span class="string">'Family_Survival'</span>] == <span class="number">0</span>) | (row[<span class="string">'Family_Survival'</span>] == <span class="number">0.5</span>):</div><div class="line">                smax = grp_df.drop(ind)[<span class="string">'Survived'</span>].max()</div><div class="line">                smin = grp_df.drop(ind)[<span class="string">'Survived'</span>].min()</div><div class="line">                passID = row[<span class="string">'PassengerId'</span>]</div><div class="line">                <span class="keyword">if</span> (smax == <span class="number">1.0</span>):</div><div class="line">                    data_all.loc[data_all[<span class="string">'PassengerId'</span>] == passID, <span class="string">'Family_Survival'</span>] = <span class="number">1</span></div><div class="line">                <span class="keyword">elif</span> (smin == <span class="number">0.0</span>):</div><div class="line">                    data_all.loc[data_all[<span class="string">'PassengerId'</span>] == passID, <span class="string">'Family_Survival'</span>] = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># 查看Family_Survival分布</span></div><div class="line">g = sns.countplot(x=<span class="string">"Family_Survival"</span>, hue=<span class="string">"Survived"</span>, data=data_all.iloc[:train_len,:])</div></pre></td></tr></table></figure>
<p><img src="output_13_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将连续数值分成bins</span></div><div class="line"><span class="comment"># 处理Fare</span></div><div class="line"><span class="comment"># 显示Fare的分布 </span></div><div class="line">g = sns.distplot(data_all[<span class="string">"Fare"</span>], color=<span class="string">"m"</span>, label=<span class="string">"Skewness : %.2f"</span>%(data_all[<span class="string">"Fare"</span>].skew()))</div><div class="line">g = g.legend(loc=<span class="string">"best"</span>)</div></pre></td></tr></table></figure>
<p><img src="output_14_0.png" alt="png"></p>
<p>从上面可以看出Fare的分布比较不均匀，对其通过log尺度变换进行处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Apply log to Fare to reduce skewness distribution</span></div><div class="line">data_all[<span class="string">"Fare"</span>] = data_all[<span class="string">"Fare"</span>].map(<span class="keyword">lambda</span> i: np.log(i) <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</div><div class="line">g = sns.distplot(data_all[<span class="string">"Fare"</span>], color=<span class="string">"b"</span>, label=<span class="string">"Skewness : %.2f"</span>%(data_all[<span class="string">"Fare"</span>].skew()))</div><div class="line">g = g.legend(loc=<span class="string">"best"</span>)</div></pre></td></tr></table></figure>
<p><img src="output_16_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 现在对Fare分成bins</span></div><div class="line"><span class="comment"># 这里选择qcut方法，对频率进行等距分箱</span></div><div class="line">n_bins=<span class="number">5</span></div><div class="line">data_all[<span class="string">'FareBin'</span>] = pd.qcut(data_all[<span class="string">'Fare'</span>], n_bins)</div><div class="line">label = LabelEncoder()</div><div class="line">data_all[<span class="string">'FareBin_Code'</span>] = label.fit_transform(data_all[<span class="string">'FareBin'</span>])</div><div class="line"></div><div class="line">g = sns.countplot(x=<span class="string">"FareBin_Code"</span>,hue=<span class="string">'Survived'</span>,data=data_all.iloc[:train_len,:])</div></pre></td></tr></table></figure>
<p><img src="output_17_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 同样对年龄进行处理</span></div><div class="line">g = sns.distplot(data_all[<span class="string">"Age"</span>], color=<span class="string">"m"</span>, label=<span class="string">"Skewness : %.2f"</span>%(data_all[<span class="string">"Age"</span>].skew()))</div><div class="line">g = g.legend(loc=<span class="string">"best"</span>)</div></pre></td></tr></table></figure>
<p><img src="output_18_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 年龄的分布就比较均匀，不需要做任何预处理</span></div><div class="line"><span class="comment"># 这里用cut方法，对年龄选择等距分箱，分成n_bins_age个年龄段</span></div><div class="line">n_bins_age=<span class="number">8</span></div><div class="line">data_all[<span class="string">'AgeBin'</span>] = pd.cut(data_all[<span class="string">'Age'</span>], n_bins_age)</div><div class="line">label = LabelEncoder()</div><div class="line">data_all[<span class="string">'AgeBin_Code'</span>] = label.fit_transform(data_all[<span class="string">'AgeBin'</span>])</div><div class="line"></div><div class="line">g = sns.countplot(x=<span class="string">"AgeBin"</span>,hue=<span class="string">'Survived'</span>,data=data_all.iloc[:train_len,:])</div></pre></td></tr></table></figure>
<p><img src="output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 处理Embarked属性</span></div><div class="line">g = sns.countplot(x=<span class="string">"Embarked"</span>,data=data_all)</div></pre></td></tr></table></figure>
<p><img src="output_20_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g = sns.countplot(x=<span class="string">"Embarked"</span>,hue=<span class="string">'Survived'</span>,data=data_all.iloc[:train_len,:])</div></pre></td></tr></table></figure>
<p><img src="output_21_0.png" alt="png"></p>
<p>对Embarked属性进行dummy操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data_all=pd.get_dummies(data_all,columns=[<span class="string">'Embarked'</span>],prefix=<span class="string">'Embarked'</span>)</div></pre></td></tr></table></figure>
<p>剩下Ticket属性看起来比较复杂，先不做任何提取。</p>
<p>下面再继续看目前的data_all的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data_all.info()</div></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1309 entries, 0 to 1308
Data columns (total 23 columns):
Age                1309 non-null float64
Cabin              295 non-null object
Fare               1309 non-null float64
Name               1309 non-null object
Parch              1309 non-null int64
PassengerId        1309 non-null int64
Pclass             1309 non-null int64
Sex                1309 non-null int64
SibSp              1309 non-null int64
Survived           891 non-null float64
Ticket             1309 non-null object
Title              1309 non-null int64
Family_size        1309 non-null int64
Last_Name          1309 non-null object
Family_Survival    1309 non-null float64
FareBin            1309 non-null category
FareBin_Code       1309 non-null int64
AgeBin             1309 non-null category
AgeBin_Code        1309 non-null int64
Embarked_C         1309 non-null uint8
Embarked_None      1309 non-null uint8
Embarked_Q         1309 non-null uint8
Embarked_S         1309 non-null uint8
dtypes: category(2), float64(4), int64(9), object(4), uint8(4)
memory usage: 181.8+ KB
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 选用部分特征做为最终特征</span></div><div class="line">data_all=data_all[[<span class="string">'PassengerId'</span>,<span class="string">'Pclass'</span>,<span class="string">'Sex'</span>,<span class="string">'Title'</span>,<span class="string">'Family_size'</span>,<span class="string">'Family_Survival'</span>,<span class="string">'FareBin_Code'</span>,<span class="string">'AgeBin_Code'</span>,</div><div class="line">                  <span class="string">'Embarked_C'</span>,<span class="string">'Embarked_None'</span>,<span class="string">'Embarked_Q'</span>,<span class="string">'Embarked_S'</span>,<span class="string">'Survived'</span>]]</div><div class="line"></div><div class="line">g = sns.heatmap(data_all.iloc[:train_len,:].drop([<span class="string">'PassengerId'</span>],axis=<span class="number">1</span>).corr(),cmap=<span class="string">"BrBG"</span>,annot=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p><img src="output_27_0.png" alt="png"></p>
<h1 id="Scale以及模型选择"><a href="#Scale以及模型选择" class="headerlink" title="Scale以及模型选择"></a>Scale以及模型选择</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">X_train_original=data_all.iloc[:train_len,:].drop([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</div><div class="line">Y_train=data_all.iloc[:train_len,:][<span class="string">'Survived'</span>].astype(int)</div><div class="line">test_original=data_all.iloc[train_len:,:].drop([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</div><div class="line">testID=data_all.iloc[train_len:,:][<span class="string">'PassengerId'</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># nn using skorch </span></div><div class="line"><span class="comment"># 神经网络模型</span></div><div class="line"><span class="keyword">import</span> torch</div><div class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line">torch.manual_seed(<span class="number">0</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassifierModule</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></div><div class="line"><span class="function"><span class="params">            self,</span></span></div><div class="line"><span class="function"><span class="params">            num_units=<span class="number">20</span>,</span></span></div><div class="line"><span class="function"><span class="params">            nonlin=F.relu,</span></span></div><div class="line"><span class="function"><span class="params">            dropout=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">    )</span>:</span></div><div class="line">        super(ClassifierModule, self).__init__()</div><div class="line">        self.num_units = num_units</div><div class="line">        self.nonlin = nonlin</div><div class="line">        self.dropout = dropout</div><div class="line"></div><div class="line">        self.dense0 = nn.Linear(<span class="number">11</span>, num_units)</div><div class="line">        self.nonlin = nonlin</div><div class="line">        self.dropout = nn.Dropout(dropout)</div><div class="line">        self.dense1 = nn.Linear(num_units, <span class="number">10</span>)</div><div class="line">        self.output = nn.Linear(<span class="number">10</span>, <span class="number">2</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, **kwargs)</span>:</span></div><div class="line">        X = self.nonlin(self.dense0(X))</div><div class="line">        X = self.dropout(X)</div><div class="line">        X = F.relu(self.dense1(X))</div><div class="line">        X = F.softmax(self.output(X), dim=<span class="number">-1</span>)</div><div class="line">        <span class="keyword">return</span> X</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> skorch <span class="keyword">import</span> NeuralNetClassifier</div><div class="line"><span class="keyword">from</span> skorch.dataset <span class="keyword">import</span> CVSplit</div><div class="line">net = NeuralNetClassifier(</div><div class="line">    ClassifierModule,</div><div class="line">    max_epochs=<span class="number">500</span>,</div><div class="line">    lr=<span class="number">0.02</span>,</div><div class="line">    train_split=CVSplit(<span class="number">5</span>),</div><div class="line"><span class="comment">#     device='cuda',  # uncomment this to train with CUDA</span></div><div class="line">)</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"></div><div class="line">X=X_train.astype(np.float32)</div><div class="line">Y=Y_train.astype(np.int64)</div><div class="line"></div><div class="line">params = &#123;</div><div class="line">    <span class="string">'lr'</span>: [<span class="number">0.02</span>],</div><div class="line">    <span class="string">'max_epochs'</span>: [<span class="number">500</span>],</div><div class="line">    <span class="string">'module__num_units'</span>: [<span class="number">20</span>],</div><div class="line">&#125;</div><div class="line">gs = GridSearchCV(net, params, refit=<span class="keyword">True</span>,cv=<span class="number">2</span>, scoring=<span class="string">'accuracy'</span>)</div><div class="line">gs.fit(X, Y)</div><div class="line">print(gs.best_score_, gs.best_params_)</div><div class="line">gs.estimator.set_params(**gs.best_params_).fit(X,Y)</div><div class="line">IDtest=pd.read_csv(<span class="string">'data/test.csv'</span>)[<span class="string">'PassengerId'</span>]</div><div class="line">test_Survived_nn=pd.Series(gs.predict(test.astype(np.float32)),name=<span class="string">'Survived'</span>)</div><div class="line">nn_results=pd.concat([IDtest,test_Survived_nn],axis=<span class="number">1</span>)</div><div class="line">nn_results.to_csv(<span class="string">'nn_results.csv'</span>,index=<span class="keyword">False</span>)</div><div class="line">nn_results.head()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># scalar</span></div><div class="line">scaler=MinMaxScaler()</div><div class="line">X_train= scaler.fit_transform(X_train_original)</div><div class="line">test= scaler.transform(test_original)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">kfold = StratifiedKFold(n_splits=<span class="number">5</span>)</div><div class="line"></div><div class="line"><span class="comment"># Modeling step Test differents algorithms</span></div><div class="line">random_state = <span class="number">2</span></div><div class="line">classifiers = []</div><div class="line"></div><div class="line"></div><div class="line">classifiers.append(SVC(random_state=random_state))</div><div class="line">classifiers.append(DecisionTreeClassifier(random_state=random_state))</div><div class="line">classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state), random_state=random_state,</div><div class="line">                                          learning_rate=<span class="number">0.1</span>))</div><div class="line">classifiers.append(RandomForestClassifier(random_state=random_state))</div><div class="line">classifiers.append(ExtraTreesClassifier(random_state=random_state))</div><div class="line">classifiers.append(GradientBoostingClassifier(random_state=random_state))</div><div class="line">classifiers.append(MLPClassifier(random_state=random_state))</div><div class="line">classifiers.append(KNeighborsClassifier())</div><div class="line">classifiers.append(LogisticRegression(random_state=random_state))</div><div class="line">classifiers.append(LinearDiscriminantAnalysis())</div><div class="line"></div><div class="line">cv_results = []</div><div class="line"><span class="keyword">for</span> classifier <span class="keyword">in</span> classifiers:</div><div class="line">    cv_results.append(cross_val_score(classifier, X_train, y=Y_train, scoring=<span class="string">"accuracy"</span>, cv=kfold))</div><div class="line"></div><div class="line">cv_means = []</div><div class="line">cv_std = []</div><div class="line"><span class="keyword">for</span> cv_result <span class="keyword">in</span> cv_results:</div><div class="line">    cv_means.append(cv_result.mean())</div><div class="line">    cv_std.append(cv_result.std())</div><div class="line"></div><div class="line">cv_res = pd.DataFrame(</div><div class="line">        &#123;<span class="string">"CrossValMeans"</span>: cv_means, <span class="string">"CrossValerrors"</span>: cv_std, <span class="string">"Algorithm"</span>: [<span class="string">"SVC"</span>, <span class="string">"DecisionTree"</span>, <span class="string">"AdaBoost"</span>,<span class="string">"RandomForest"</span>, <span class="string">"ExtraTrees"</span>,<span class="string">"GradientBoosting"</span>,<span class="string">"MultipleLayerPerceptron"</span>, <span class="string">"KNeighboors"</span>,<span class="string">"LogisticRegression"</span>,<span class="string">"LinearDiscriminantAnalysis"</span>]&#125;)</div><div class="line"></div><div class="line">g = sns.barplot(<span class="string">"CrossValMeans"</span>, <span class="string">"Algorithm"</span>, data=cv_res, palette=<span class="string">"Set3"</span>, orient=<span class="string">"h"</span>, **&#123;<span class="string">'xerr'</span>: cv_std&#125;)</div><div class="line">g.set_xlabel(<span class="string">"Mean Accuracy"</span>)</div><div class="line">g = g.set_title(<span class="string">"Cross validation scores"</span>)</div></pre></td></tr></table></figure>
<p><img src="output_31_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Adaboost</span></div><div class="line">DTC = DecisionTreeClassifier()</div><div class="line"></div><div class="line">adaDTC = AdaBoostClassifier(DTC, random_state=<span class="number">7</span>)</div><div class="line"></div><div class="line">ada_param_grid = &#123;<span class="string">"base_estimator__criterion"</span>: [<span class="string">"entropy"</span>],</div><div class="line">                      <span class="string">"base_estimator__splitter"</span>: [ <span class="string">"random"</span>],</div><div class="line">                      <span class="string">"algorithm"</span>: [<span class="string">"SAMME"</span>],</div><div class="line">                      <span class="string">"n_estimators"</span>: [<span class="number">100</span>],</div><div class="line">                      <span class="string">"learning_rate"</span>: [<span class="number">0.0001</span>]&#125;</div><div class="line"></div><div class="line">gsadaDTC = GridSearchCV(adaDTC, param_grid=ada_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line"></div><div class="line">gsadaDTC.fit(X_train, Y_train)</div><div class="line"></div><div class="line">ada_best = gsadaDTC.best_estimator_</div><div class="line">print(<span class="string">'AdaBoost:'</span>)</div><div class="line">print(gsadaDTC.best_params_)</div><div class="line">print(gsadaDTC.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 1 candidates, totalling 5 fits


[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    3.0s finished


AdaBoost:
{&#39;algorithm&#39;: &#39;SAMME&#39;, &#39;base_estimator__criterion&#39;: &#39;entropy&#39;, &#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;learning_rate&#39;: 0.0001, &#39;n_estimators&#39;: 100}
0.8294051627384961
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># ExtraTrees</span></div><div class="line">ExtC = ExtraTreesClassifier()</div><div class="line"></div><div class="line"><span class="comment">## Search grid for optimal parameters</span></div><div class="line">ex_param_grid = &#123;<span class="string">"max_depth"</span>: [<span class="keyword">None</span>],</div><div class="line">                     <span class="string">"max_features"</span>: [<span class="number">0.2</span>,<span class="number">0.3</span>],</div><div class="line">                     <span class="string">"min_samples_split"</span>: [<span class="number">3</span>,<span class="number">5</span>],</div><div class="line">                     <span class="string">"min_samples_leaf"</span>: [<span class="number">5</span>,],</div><div class="line">                     <span class="string">"bootstrap"</span>: [<span class="keyword">False</span>],</div><div class="line">                     <span class="string">"n_estimators"</span>: [<span class="number">500</span>],</div><div class="line">                     <span class="string">"criterion"</span>: [<span class="string">"gini"</span>]&#125;</div><div class="line"></div><div class="line">gsExtC = GridSearchCV(ExtC, param_grid=ex_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line"></div><div class="line">gsExtC.fit(X_train, Y_train)</div><div class="line"></div><div class="line">print(<span class="string">'Extra Tree:'</span>)</div><div class="line">ExtC_best = gsExtC.best_estimator_</div><div class="line">print(gsExtC.best_params_)</div><div class="line"><span class="comment"># Best score</span></div><div class="line">print(gsExtC.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 4 candidates, totalling 20 fits


[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    8.1s finished


Extra Tree:
{&#39;bootstrap&#39;: False, &#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: None, &#39;max_features&#39;: 0.3, &#39;min_samples_leaf&#39;: 5, &#39;min_samples_split&#39;: 5, &#39;n_estimators&#39;: 500}
0.8462401795735129
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#xgboost</span></div><div class="line">XGBC = xgboost.sklearn.XGBClassifier()</div><div class="line">xgbc_param_grid = &#123;</div><div class="line">                     <span class="string">"n_estimators"</span>: [<span class="number">500</span>],</div><div class="line">                    <span class="string">'learning_rate'</span>:[<span class="number">0.001</span>],</div><div class="line">                    <span class="string">'max_depth'</span>:[<span class="number">3</span>],</div><div class="line">                    <span class="string">'booster'</span>:[<span class="string">'gbtree'</span>]&#125;</div><div class="line"></div><div class="line">gsXGBC= GridSearchCV(XGBC, param_grid=xgbc_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line">gsXGBC.fit(X_train, Y_train)</div><div class="line">print(<span class="string">'xgboost:'</span>)</div><div class="line">XGBC_best = gsXGBC.best_estimator_</div><div class="line">print(gsXGBC.best_params_)</div><div class="line">print(gsXGBC.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 1 candidates, totalling 5 fits


[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.5s finished


xgboost:
{&#39;booster&#39;: &#39;gbtree&#39;, &#39;learning_rate&#39;: 0.001, &#39;max_depth&#39;: 3, &#39;n_estimators&#39;: 500}
0.8518518518518519
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">LR=LogisticRegression()</div><div class="line">lr_param_grid = &#123;</div><div class="line">       <span class="string">'penalty'</span>:[<span class="string">'l1'</span>],</div><div class="line">        <span class="string">'tol'</span>:[<span class="number">1e-4</span>],</div><div class="line">        <span class="string">'C'</span>:[<span class="number">10</span>]&#125;</div><div class="line">gsLR = GridSearchCV(LR, param_grid=lr_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line">gsLR.fit(X_train, Y_train)</div><div class="line">print(<span class="string">'Logistic Regression:'</span>)</div><div class="line">LR_best = gsLR.best_estimator_</div><div class="line">print(gsLR.best_params_)</div><div class="line">print(gsLR.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 1 candidates, totalling 5 fits
Logistic Regression:
{&#39;C&#39;: 10, &#39;penalty&#39;: &#39;l1&#39;, &#39;tol&#39;: 0.0001}
0.8361391694725028


[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.3s finished
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># RFC Parameters tunning</span></div><div class="line">RFC = RandomForestClassifier()</div><div class="line"></div><div class="line"><span class="comment">## Search grid for optimal parameters</span></div><div class="line">rf_param_grid = &#123;<span class="string">"max_depth"</span>: [<span class="keyword">None</span>],</div><div class="line">                <span class="string">"max_features"</span>: [<span class="string">'auto'</span>,<span class="number">0.3</span>],</div><div class="line">                <span class="string">"min_samples_split"</span>: [<span class="number">5</span>],</div><div class="line">                <span class="string">"min_samples_leaf"</span>: [<span class="number">6</span>],</div><div class="line">                <span class="string">"bootstrap"</span>: [<span class="keyword">False</span>],</div><div class="line">                <span class="string">"n_estimators"</span>: [<span class="number">150</span>],</div><div class="line">                <span class="string">"criterion"</span>: [<span class="string">"gini"</span>]&#125;</div><div class="line"></div><div class="line">gsRFC = GridSearchCV(RFC, param_grid=rf_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line">gsRFC.fit(X_train, Y_train)</div><div class="line">print(<span class="string">'Random Forest:'</span>)</div><div class="line">RFC_best = gsRFC.best_estimator_</div><div class="line">print(gsRFC.best_params_)</div><div class="line"><span class="comment"># Best score</span></div><div class="line">print(gsRFC.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 2 candidates, totalling 10 fits


[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    3.1s finished


Random Forest:
{&#39;bootstrap&#39;: False, &#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: None, &#39;max_features&#39;: 0.3, &#39;min_samples_leaf&#39;: 6, &#39;min_samples_split&#39;: 5, &#39;n_estimators&#39;: 150}
0.8552188552188552
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Gradient boosting tunning</span></div><div class="line">GBC = GradientBoostingClassifier()</div><div class="line">gb_param_grid = &#123;<span class="string">'loss'</span>: [<span class="string">"deviance"</span>],</div><div class="line">                     <span class="string">'n_estimators'</span>: [<span class="number">200</span>],</div><div class="line">                     <span class="string">'learning_rate'</span>: [<span class="number">0.01</span>],</div><div class="line">                     <span class="string">'max_depth'</span>: [<span class="number">4</span>],</div><div class="line">                     <span class="string">'min_samples_leaf'</span>: [<span class="number">100</span>],</div><div class="line">                     <span class="string">"max_features"</span>: [<span class="string">'auto'</span>]</div><div class="line">                     &#125;</div><div class="line"></div><div class="line">gsGBC = GridSearchCV(GBC, param_grid=gb_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line">gsGBC.fit(X_train, Y_train)</div><div class="line">print(<span class="string">'Gradient Boost:'</span>)</div><div class="line">print(gsGBC.best_params_)</div><div class="line">GBC_best = gsGBC.best_estimator_</div><div class="line">print(gsGBC.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 1 candidates, totalling 5 fits


[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.5s finished


Gradient Boost:
{&#39;learning_rate&#39;: 0.01, &#39;loss&#39;: &#39;deviance&#39;, &#39;max_depth&#39;: 4, &#39;max_features&#39;: &#39;auto&#39;, &#39;min_samples_leaf&#39;: 100, &#39;n_estimators&#39;: 200}
0.8484848484848485
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">### SVC classifier</span></div><div class="line">SVMC = SVC(probability=<span class="keyword">True</span>)</div><div class="line">svc_param_grid = &#123;<span class="string">'kernel'</span>: [<span class="string">'rbf'</span>],</div><div class="line">                      <span class="string">'gamma'</span>: [ <span class="number">1</span>],</div><div class="line">                      <span class="string">'C'</span>: [<span class="number">0.1</span>]&#125;</div><div class="line">gsSVMC = GridSearchCV(SVMC, param_grid=svc_param_grid, cv=kfold, scoring=<span class="string">"accuracy"</span>, n_jobs=<span class="number">4</span>, verbose=<span class="number">1</span>)</div><div class="line">gsSVMC.fit(X_train, Y_train)</div><div class="line">print(<span class="string">'SVC'</span>)</div><div class="line">print(gsSVMC.best_params_)</div><div class="line">SVMC_best = gsSVMC.best_estimator_</div><div class="line"><span class="comment"># Best score</span></div><div class="line">print(gsSVMC.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 5 folds for each of 1 candidates, totalling 5 fits


[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.5s finished


SVC
{&#39;C&#39;: 0.1, &#39;gamma&#39;: 1, &#39;kernel&#39;: &#39;rbf&#39;}
0.8305274971941639
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Voting</span></div><div class="line">votingC = VotingClassifier(estimators=[(<span class="string">'rfc'</span>, RFC_best), (<span class="string">'extc'</span>, ExtC_best),</div><div class="line">                                           (<span class="string">'svc'</span>, SVMC_best), (<span class="string">'adac'</span>, ada_best), (<span class="string">'gbc'</span>, GBC_best),</div><div class="line">                                           (<span class="string">'xgbc'</span>,XGBC_best),(<span class="string">'lr'</span>,LR_best)], voting=<span class="string">'soft'</span>,</div><div class="line">                               n_jobs=<span class="number">4</span>)</div><div class="line"></div><div class="line">votingC = votingC.fit(X_train, Y_train)</div><div class="line">voting_score=cross_val_score(votingC, X_train, y=Y_train, scoring=<span class="string">"accuracy"</span>, cv=kfold)</div><div class="line">print(<span class="string">'voting:'</span>,voting_score)</div></pre></td></tr></table></figure>
<pre><code>voting: [0.86592179 0.84357542 0.85393258 0.81460674 0.84745763]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Stacking</span></div><div class="line">stack = StackingClassifier(classifiers=[RFC_best, ExtC_best,SVMC_best,ada_best,GBC_best,LR_best],</div><div class="line">                              meta_classifier=XGBC_best)</div><div class="line">stack = stack.fit(X_train, Y_train)</div><div class="line">stack_score=cross_val_score(stack,X_train, y=Y_train, scoring=<span class="string">"accuracy"</span>, cv=kfold)</div><div class="line">print(<span class="string">'stack_score:'</span>,stack_score)</div></pre></td></tr></table></figure>
<pre><code>stack_score: [0.83240223 0.81564246 0.85393258 0.82022472 0.82485876]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span><span class="params">(estimator, title, X, y, ylim=None, cv=None,n_jobs=<span class="number">-1</span>, train_sizes=np.linspace<span class="params">(<span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span>)</span>)</span>:</span></div><div class="line">        <span class="string">"""Generate a simple plot of the test and training learning curve"""</span></div><div class="line">        plt.figure()</div><div class="line">        plt.title(title)</div><div class="line">        <span class="keyword">if</span> ylim <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            plt.ylim(*ylim)</div><div class="line">        plt.xlabel(<span class="string">"Training examples"</span>)</div><div class="line">        plt.ylabel(<span class="string">"Score"</span>)</div><div class="line">        train_sizes, train_scores, test_scores = learning_curve(</div><div class="line">            estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)</div><div class="line">        train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</div><div class="line">        train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</div><div class="line">        test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</div><div class="line">        test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</div><div class="line">        plt.grid()</div><div class="line"></div><div class="line">        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,</div><div class="line">                         train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</div><div class="line">                         color=<span class="string">"r"</span>)</div><div class="line">        plt.fill_between(train_sizes, test_scores_mean - test_scores_std,</div><div class="line">                         test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>, color=<span class="string">"g"</span>)</div><div class="line">        plt.plot(train_sizes, train_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"r"</span>,</div><div class="line">                 label=<span class="string">"Training score"</span>)</div><div class="line">        plt.plot(train_sizes, test_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"g"</span>,</div><div class="line">                 label=<span class="string">"Cross-validation score"</span>)</div><div class="line">        plt.legend(loc=<span class="string">"best"</span>)</div><div class="line">        <span class="keyword">return</span> plt</div><div class="line"></div><div class="line">g = plot_learning_curve(gsRFC.best_estimator_, <span class="string">"RF mearning curves"</span>, X_train, Y_train, cv=kfold)</div><div class="line">g = plot_learning_curve(gsExtC.best_estimator_, <span class="string">"ExtraTrees learning curves"</span>, X_train, Y_train, cv=kfold)</div><div class="line">g = plot_learning_curve(gsSVMC.best_estimator_, <span class="string">"SVC learning curves"</span>, X_train, Y_train, cv=kfold)</div><div class="line">g = plot_learning_curve(gsadaDTC.best_estimator_, <span class="string">"AdaBoost learning curves"</span>, X_train, Y_train, cv=kfold)</div><div class="line">g = plot_learning_curve(gsGBC.best_estimator_, <span class="string">"GradientBoosting learning curves"</span>, X_train, Y_train, cv=kfold)</div><div class="line">g = plot_learning_curve(gsXGBC.best_estimator_,<span class="string">"xgboost learning curves"</span>,X_train,Y_train,cv=kfold)</div><div class="line">g = plot_learning_curve(gsLR.best_estimator_,<span class="string">"Logistic Regression learning curves"</span>,X_train,Y_train,cv=kfold)</div></pre></td></tr></table></figure>
<p><img src="output_40_0.png" alt="png"></p>
<p><img src="output_40_1.png" alt="png"></p>
<p><img src="output_40_2.png" alt="png"></p>
<p><img src="output_40_3.png" alt="png"></p>
<p><img src="output_40_4.png" alt="png"></p>
<p><img src="output_40_5.png" alt="png"></p>
<p><img src="output_40_6.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">nrows =<span class="number">3</span></div><div class="line">ncols=<span class="number">2</span></div><div class="line">fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=<span class="string">"all"</span>, figsize=(<span class="number">15</span>, <span class="number">15</span>))</div><div class="line">names_classifiers = [(<span class="string">'rfc'</span>, RFC_best), (<span class="string">'extc'</span>, ExtC_best),</div><div class="line">                        (<span class="string">'adac'</span>, ada_best), (<span class="string">'gbc'</span>, GBC_best),</div><div class="line">                        (<span class="string">'xgbc'</span>,XGBC_best)]</div><div class="line">nclassifier = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> row <span class="keyword">in</span> range(nrows):</div><div class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> range(ncols):</div><div class="line">        <span class="keyword">if</span> nclassifier&gt;=<span class="number">5</span>:</div><div class="line">            <span class="keyword">break</span></div><div class="line">        name = names_classifiers[nclassifier][<span class="number">0</span>]</div><div class="line">        classifier = names_classifiers[nclassifier][<span class="number">1</span>]</div><div class="line">        indices = np.argsort(classifier.feature_importances_)[::<span class="number">-1</span>][:<span class="number">40</span>]</div><div class="line">        g = sns.barplot(y=X_train_original.columns[indices][:<span class="number">40</span>], x=classifier.feature_importances_[indices][:<span class="number">40</span>],</div><div class="line">                            orient=<span class="string">'h'</span>, ax=axes[row][col])</div><div class="line">        g.set_xlabel(<span class="string">"Relative importance"</span>, fontsize=<span class="number">12</span>)</div><div class="line">        g.set_ylabel(<span class="string">"Features"</span>, fontsize=<span class="number">12</span>)</div><div class="line">        g.tick_params(labelsize=<span class="number">9</span>)</div><div class="line">        g.set_title(name + <span class="string">" feature importance"</span>)</div><div class="line">        nclassifier += <span class="number">1</span></div><div class="line"></div><div class="line"></div><div class="line">test_Survived_RFC = pd.Series(RFC_best.predict(test), name=<span class="string">"RFC"</span>)</div><div class="line">test_Survived_ExtC = pd.Series(ExtC_best.predict(test), name=<span class="string">"ExtC"</span>)</div><div class="line">test_Survived_SVMC = pd.Series(SVMC_best.predict(test), name=<span class="string">"SVC"</span>)</div><div class="line">test_Survived_AdaC = pd.Series(ada_best.predict(test), name=<span class="string">"Ada"</span>)</div><div class="line">test_Survived_GBC = pd.Series(GBC_best.predict(test), name=<span class="string">"GBC"</span>)</div><div class="line">test_Survived_XGBC=pd.Series(XGBC_best.predict(test),name=<span class="string">'XGBC'</span>)</div><div class="line">test_Survived_LR=pd.Series(LR_best.predict(test),name=<span class="string">'LR'</span>)</div><div class="line">test_Survived_Voting=pd.Series(votingC.predict(test),name=<span class="string">'Voting'</span>)</div><div class="line">    <span class="comment"># Concatenate all classifier results</span></div><div class="line">ensemble_results = pd.concat(</div><div class="line">        [test_Survived_RFC, test_Survived_ExtC, test_Survived_AdaC, test_Survived_GBC, test_Survived_SVMC,</div><div class="line">         test_Survived_XGBC,test_Survived_LR,test_Survived_Voting], axis=<span class="number">1</span>)</div><div class="line"></div><div class="line">g = sns.heatmap(ensemble_results.corr(), annot=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p><img src="output_41_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">test_Survived = pd.Series(votingC.predict(test), name=<span class="string">"Survived"</span>)</div><div class="line">test_Survived_XGBC_submition=pd.Series(XGBC_best.predict(test),name=<span class="string">'Survived'</span>)</div><div class="line">xgbc_results=pd.concat([IDtest,test_Survived_XGBC_submition],axis=<span class="number">1</span>)</div><div class="line">xgbc_results.to_csv(<span class="string">'xgbc.csv'</span>,index=<span class="keyword">False</span>)</div><div class="line">print(IDtest.shape)</div><div class="line">print(test_Survived.shape)</div><div class="line">results = pd.concat([IDtest, test_Survived], axis=<span class="number">1</span>)</div><div class="line">results.to_csv(<span class="string">"ensemble_python_voting.csv"</span>, index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<pre><code>(418,)
(418,)
</code></pre><p>最后提交的voting方法的结果得到了0.81339的分数,还有一定的提升空间，其中超参数调整应该还会带来一定的效果提升。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、<a href="https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling" target="_blank" rel="external">yassineghouzam’s kernel</a><br>2、<a href="https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83" target="_blank" rel="external">konstantinmasich’s kernel</a><br>3、<a href="http://pandas.pydata.org/pandas-docs/stable/" target="_blank" rel="external">pandas document</a><br>4、<a href="https://seaborn.pydata.org/tutorial.html" target="_blank" rel="external">seaborn tutorial</a><br>5、<a href="https://github.com/wwdguu/wwdguu.github.io/tree/master/2018/08/11/titanic/titanic.ipynb" target="_blank" rel="external">notebook</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习//" class="article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/11/titanic/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-dynamic" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  
</div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">st=&gt;start: 开始</div><div class="line">e=&gt;end: 结束</div><div class="line">op=&gt;operation: 操作</div><div class="line">cond=&gt;condition: 确认？</div><div class="line"></div><div class="line">st-&gt;op-&gt;cond</div><div class="line">cond(yes)-&gt;e</div><div class="line">cond(no)-&gt;op</div></pre></td></tr></table></figure>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/05/17/dynamic/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-what-is-mAP" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/04/what-is-mAP/">mAP详解</a>
    </h1>
  

        
        <a href="/2018/05/04/what-is-mAP/" class="archive-article-date">
  	<time datetime="2018-05-04T03:14:03.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-05-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#mean-average-precise"><span class="toc-text">mean average precise</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <h1 id="mean-average-precise"><a href="#mean-average-precise" class="headerlink" title="mean average precise"></a>mean average precise</h1><p><strong>1、precise and recall</strong><br><img src="pr.jpg" alt=""><br><img src="precise_recall.jpg" alt="precise and recall"><br>如上图所示：<br>precise=true_positive/(true_positive+false_positive)<br>recall=true_positive/(true_positive+false_negative)<br>precise表示预测正确的占所有预测的百分比。<br>recall表示预测的某一类正确的占该类总数的百分比。<br><strong>2、average precise</strong><br>根据 precise recall曲线计算得到。<br>关键在于理解precise recall 曲线怎么得到？<br>具体详见参考1。<br>即对每个recall对应的precise取平均。<br><strong>3、mean average precise</strong><br>上面average precise是针对每一类的情况。再对所有类的ap取平均即可得到mAP。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、<a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="external">多标签图像分类任务的评价方法-mAP</a><br>2、<a href="https://www.zhihu.com/question/41540197" target="_blank" rel="external">mean average precision（MAP）在计算机视觉中是如何计算和应用的？</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cv//" class="article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/05/04/what-is-mAP/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-normalization-in-deeplearning" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/01/normalization-in-deeplearning/">深度学习中的Normalization方法</a>
    </h1>
  

        
        <a href="/2018/05/01/normalization-in-deeplearning/" class="archive-article-date">
  	<time datetime="2018-05-01T06:12:26.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-05-01</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Batch-Normalization"><span class="toc-text">Batch Normalization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature-Scaling"><span class="toc-text">Feature Scaling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Internal-Convariate-Shift"><span class="toc-text">Internal Convariate Shift</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Batch-Normalization-1"><span class="toc-text">Batch Normalization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么要加gamma，beta参数"><span class="toc-text">为什么要加gamma，beta参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#forward"><span class="toc-text">forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backward"><span class="toc-text">backward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#benefit"><span class="toc-text">benefit</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Other-Normalization"><span class="toc-text">Other Normalization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Layer-Normalization"><span class="toc-text">Layer Normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Group-Normalization"><span class="toc-text">Group Normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Local-Response-Normalization"><span class="toc-text">Local Response Normalization</span></a></li></ol></li></ol>
</div>

        <p>总结深度学习中常用的Normalization方法，包括BatchNormalization,LayerNormalization,GroupNormalization以及LocalResponseNorm。</p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><h2 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h2><p>是指对不同的feature做归一化，使得其有着相同的scaling。<br><img src="feature_scaling.jpg" alt="Feature Scaling"><br>从上图可以看出，输入的两个维度x1,x2相差比较大，如果想要得到比较好的学习效果，需要针对不同维度采用不同learning rate，但是操作起来困难。进行feature scaling可以解决这个问题。<br>如何做：<br><img src="how_to_scaling.jpg" alt="如何做scaling"></p>
<h2 id="Internal-Convariate-Shift"><a href="#Internal-Convariate-Shift" class="headerlink" title="Internal Convariate Shift"></a>Internal Convariate Shift</h2><p><strong>We define Internal Covariate Shift as the change in the distribution of network activations due to the change in network parameters during training</strong><br>减少Internal Convariate Shift有助于训练。<br><img src="internal_convariate_shift.jpg" alt="Internal Convariate Shift"><br>对于deeplearning 网络来说，可以对每个layer做feature scaling。<br>然而如果只是上面提到的简单的feature scaling的话会带来一个问题：<br>在训练过程中，中间的每一层的参数都是在变化的，那么其每层的output也会随之改变，则mean和std也在不断变化。我们将难以简单计算出mean和std来进行feature scaling。Batch Normalization则可以用来解决这个问题，因为其将normalization加入训练过程中。</p>
<h2 id="Batch-Normalization-1"><a href="#Batch-Normalization-1" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p><img src="bn.jpg" alt="Batch Normalization"></p>
<h3 id="为什么要加gamma，beta参数"><a href="#为什么要加gamma，beta参数" class="headerlink" title="为什么要加gamma，beta参数"></a>为什么要加gamma，beta参数</h3><p>gamma，beta参数的加入使得整个BN过程可训练，使得其与普通的预处理归一化操作区别开。??<br><strong>为了保证模型的表达能力不因为规范化而下降</strong><br><a href="https://zhuanlan.zhihu.com/p/33173246" target="_blank" rel="external">详解深度学习中的Normalization，不只是BN</a></p>
<h3 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h3><p>针对每一个batch做归一化操作。<br><strong>training</strong><br><img src="training_bn.jpg" alt="训练"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">sample_mean=np.mean(x,axis=<span class="number">0</span>)</div><div class="line">sample_var=np.var(x,axis=<span class="number">0</span>)</div><div class="line">x_hat=(x-sample_mean)/np.sqrt(sample_var+eps)</div><div class="line">out=gamma*x_hat+beta</div><div class="line"></div><div class="line"><span class="comment"># move average mean</span></div><div class="line">running_mean=momentum*running_mean+(<span class="number">1</span>-momentum)*sample_mean</div><div class="line"><span class="comment"># move average var</span></div><div class="line">running_var=momentum*running_var+(<span class="number">1</span>-momentum)*sample_mean</div></pre></td></tr></table></figure></p>
<p><strong>test</strong><br>存在一个问题：我们无法知道batch的信息，所以没法算mean和std。<br>解决方法：<br><strong>1</strong>ideal solution: Computing mean and std using the whole training dataset<br><strong>2</strong>practical solution: computing  the moving average of mean and std of the batches during training</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">temp=(x-running_mean)/np.sqrt(running_var+eps)</div><div class="line">out=gamma*temp+beta</div></pre></td></tr></table></figure>
<h3 id="backward"><a href="#backward" class="headerlink" title="backward"></a>backward</h3><p><a href="http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" target="_blank" rel="external">Understanding the backward pass through Batch Normalization Layer</a></p>
<h3 id="benefit"><a href="#benefit" class="headerlink" title="benefit"></a>benefit</h3><p><strong>1、BN通过减少Internal Convariate Shift使得我们可以使用更高的learning rate来让训练更快速。</strong><br><strong>2、BN对解决梯度爆炸和梯度消失有作用，特别是对tanh、sigmoid等激活函数。</strong><br>    原因：因为BN确保了数据都在0附近斜率比较大的地方，不会出现梯度爆炸和消失的问题。<br><strong>3、使得参数初始化对训练的影响不大</strong><br><img src="init.jpg" alt="参数初始化"><br><strong>4、BN也有regularization的作用，防止overfitting</strong></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1、<a href="https://www.quora.com/Why-does-batch-normalization-help" target="_blank" rel="external">Why-does-batch-normalization-help</a><br>2、<a href="http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" target="_blank" rel="external">Understanding the backward pass through Batch Normalization Layer</a><br>3、<a href="https://www.youtube.com/watch?v=BZh1ltr5Rkg&amp;t=21s" target="_blank" rel="external">李宏毅老师讲BN(图片都来自该视频截图)</a><br>4、<a href="http://pytorch.org/docs/master/nn.html#batchnorm2d" target="_blank" rel="external">pytorch doc</a><br>5、<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="external">BN论文</a><br>6、<a href="https://zhuanlan.zhihu.com/p/33173246" target="_blank" rel="external">详解深度学习中的Normalization，不只是BN</a></p>
<h1 id="Other-Normalization"><a href="#Other-Normalization" class="headerlink" title="Other Normalization"></a>Other Normalization</h1><h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>Layer Normalization和BN的区别在于：LN是对每个单独的数据做归一化，BN是对mini-batch的数据做归一化。</p>
<h2 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h2><p><strong>GN divides the channels into groups and computes within each group the mean and variance for normalization. GN’s computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes.</strong><br>其可以用于在batch_size较小时对BN的替代。<br><img src="gn_tf.jpg" alt="GN implement"></p>
<h2 id="Local-Response-Normalization"><a href="#Local-Response-Normalization" class="headerlink" title="Local Response Normalization"></a>Local Response Normalization</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/05/01/normalization-in-deeplearning/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cpp-lvalue-and-rvalue" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/23/cpp-lvalue-and-rvalue/">C++中的左值和右值以及std::move, std::forward</a>
    </h1>
  

        
        <a href="/2018/04/23/cpp-lvalue-and-rvalue/" class="archive-article-date">
  	<time datetime="2018-04-23T15:15:25.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-04-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#lvalue-and-rvalue"><span class="toc-text">lvalue and rvalue</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Effective-Modern-C-中相关条款笔记总结"><span class="toc-text">Effective Modern C++中相关条款笔记总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-23-Understanding-std-move-and-std-forward"><span class="toc-text">Item 23: Understanding std::move and std::forward</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-24：Distinguish-universal-references-from-rvalue-references"><span class="toc-text">Item 24：Distinguish universal references from rvalue references</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-25：Use-std-move-on-rvalue-references-std-forward-on-universal-references"><span class="toc-text">Item 25：Use std::move on rvalue references, std::forward on universal references</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-26-Avoid-overloading-on-universal-references"><span class="toc-text">Item 26: Avoid overloading on universal references</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-27-Familiarize-yourself-with-alternatives-to-overloading-on-universal-references"><span class="toc-text">Item 27: Familiarize yourself with alternatives to overloading on universal references.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-28-Understand-reference-collapsing"><span class="toc-text">Item 28: Understand reference collapsing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-29-Assume-that-move-operations-are-not-present-not-cheap-and-not-used"><span class="toc-text">Item 29: Assume that move operations are not present, not cheap, and not used</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Item-30-Familiarize-yourself-with-perfect-forwarding-failure-cases"><span class="toc-text">Item 30: Familiarize yourself with perfect forwarding failure cases</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <h1 id="lvalue-and-rvalue"><a href="#lvalue-and-rvalue" class="headerlink" title="lvalue and rvalue"></a>lvalue and rvalue</h1><p> 在概念上,右值对应于从函数返回的临时对象，而左值对应于可以引用的对象，无论是通过名称还是通过跟随指针或左值引用。一种判断表达式是左值还是右值的方法是：如果能得到其地址，那么它是左值，否则其是右值。<br><strong>注意:</strong>一个表达式的类型和这个表达式本身是左值还是右值无关。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//一个参数始终是lvalue，即便其类型是一个rvalue reference</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span>&#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    Widget(Widget&amp;&amp; rhs);<span class="comment">//rhs是一个左值，但是其有一个右值引用的类型。</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="Effective-Modern-C-中相关条款笔记总结"><a href="#Effective-Modern-C-中相关条款笔记总结" class="headerlink" title="Effective Modern C++中相关条款笔记总结"></a>Effective Modern C++中相关条款笔记总结</h1><h2 id="Item-23-Understanding-std-move-and-std-forward"><a href="#Item-23-Understanding-std-move-and-std-forward" class="headerlink" title="Item 23: Understanding std::move and std::forward"></a>Item 23: Understanding std::move and std::forward</h2><p><strong>要点</strong><br><strong>1、std::move</strong><br>move semantic使得编译器将代价昂贵的copy操作替换为相对代价低的move。move semantics使得move-only类型的创建成为可能，比如std::unique_ptr,std::future,std::thread。<br>实际上std::move并没有移动任何东西。它做的其实是一个类型转换工作。就是将输入转型为rvalue。<br><strong>2、std::forward </strong><br>std::forward和std::move类似，比较大的区别就是std::forward是有条件的类型转换，<br>只有当参数是和rvalue绑定时将其转型为rvalue，否则不做转换。</p>
<h2 id="Item-24：Distinguish-universal-references-from-rvalue-references"><a href="#Item-24：Distinguish-universal-references-from-rvalue-references" class="headerlink" title="Item 24：Distinguish universal references from rvalue references"></a>Item 24：Distinguish universal references from rvalue references</h2><p><strong>要点</strong><br><strong>1、判断原则</strong><br><strong>A、当函数的模板参数有着T&amp;&amp;的形式，并且有推导类型T，或者一个对象被声明为auto&amp;&amp;，那么它就是一个universal reference。</strong><br><strong>B、如果type的声明的格式并不完全是type&amp;&amp;，或者类型推断没有发生，那么type&amp;&amp;表示的就是rvalue reference。</strong><br><strong>C、对于universal reference，如果它被rvalue初始化，它就是rvalue，与之对应，如果被lvalue初始化，其就是lvalue。</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//实例</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(Widget&amp;&amp; param)</span></span>;<span class="comment">//B rvalue  reference  没有类型推断</span></div><div class="line">Widget&amp;&amp; var1=Widget();<span class="comment">//B rvalue reference 没有类型推断</span></div><div class="line"><span class="keyword">auto</span>&amp;&amp; var2=var1;<span class="comment">//A universal references var2有形式auto&amp;&amp;</span></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;T&gt;&amp;&amp; param)</span></span>; <span class="comment">//B rvalue references param类型不完全是type&amp;&amp;</span></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(T&amp;&amp; param)</span></span>;<span class="comment">//universal references param有推导类型T，且形式是T&amp;&amp;</span></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">const</span> T&amp;&amp; param)</span></span>;<span class="comment">//universal reference 因</span></div><div class="line"><span class="comment">//为type的声明格式并不完全是type&amp;&amp;(多了const)</span></div><div class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>, <span class="title">class</span> <span class="title">Allocator</span> = <span class="title">allocator</span>&lt;T&gt;&gt;</span></div><div class="line"><span class="class"><span class="title">class</span> <span class="title">vector</span>&#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push_back</span><span class="params">(T&amp;&amp; x)</span><span class="comment">//rvalue reference </span></span></div><div class="line"><span class="function">    <span class="comment">//因为没有类型推断，当vector被初始化时，T的类型就被确定了。</span></span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>,<span class="title">class</span> <span class="title">Allocator</span>=<span class="title">allcator</span>&lt;T&gt;&gt;</span></div><div class="line"><span class="class"><span class="title">class</span> <span class="title">vector</span>&#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span>... <span class="title">Args</span>&gt;</span></div><div class="line"><span class="class">    <span class="title">void</span> <span class="title">emplace_back</span>(<span class="title">Args</span>&amp;&amp;... <span class="title">args</span>);</span><span class="comment">//universal </span></div><div class="line">    <span class="comment">//reference，存在类型推断，因为即</span></div><div class="line">    <span class="comment">//便T的类型在vector初始化时确定，但是Args的类型不能确定，需要类型推导。</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="Item-25：Use-std-move-on-rvalue-references-std-forward-on-universal-references"><a href="#Item-25：Use-std-move-on-rvalue-references-std-forward-on-universal-references" class="headerlink" title="Item 25：Use std::move on rvalue references, std::forward on universal references"></a>Item 25：Use std::move on rvalue references, std::forward on universal references</h2><p><strong>要点</strong><br><strong>1、当将rvalue reference转发给其它函数时，其应该被无条件转型为rvalue，即用std::move，因为它总是被rvalues限制，而将universal referencies转发给其它函数时，应该有条件地转型，即使用std::forward,因为它可能是lvalues。</strong><br><strong>注意1</strong>为什么不在任何情况下都使用std::forward？尽管使用std::forward对于rvalue references也能产生正确的行为，但是这样源代码冗长也容易出错。<br><strong>注意2</strong>对universal references使用std::move会对lvalues造成意外的修改，更应该避免。<br><strong>2、当一个函数按值返回时，如果是返回一个与 universal reference或者rvalue reference绑定的对象，那么在返回时可以对其施加std::forward或者std::move操作，这样效率更高</strong><br><strong>注意:</strong>即便该对象不支持move操作也没有任何副作用，因为如果不支持的话会自动调用该对象的拷贝构造函数完成copy。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Matrix </div><div class="line"><span class="keyword">operator</span>+(Matrix&amp;&amp; lhs,<span class="keyword">const</span> Matrix&amp; rhs)&#123;</div><div class="line">    lhs+=rhs;</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::move(lhs);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>3、不要将std::move或者std::forward应用到local  object</strong><br>原因详见P174，和编译器的返回值优化有关。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function">Widget <span class="title">makeWidget</span><span class="params">()</span></span>&#123;</div><div class="line">    Widget w;</div><div class="line">    ...</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::move(w);<span class="comment">//避免这样做</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="Item-26-Avoid-overloading-on-universal-references"><a href="#Item-26-Avoid-overloading-on-universal-references" class="headerlink" title="Item 26: Avoid overloading on universal references"></a>Item 26: Avoid overloading on universal references</h2><p><strong>要点</strong>看原书比较清楚(没太看懂。)<br><strong>1、对通用引用进行重载往往导致其被调用的次数比预期要多很多。</strong><br><strong>2、完美转发的构造函数特别有问题，因为它们通常比拷贝构造函数更适合非常量lvalue，并且它们可以劫持派生类调用到其基类的拷贝和移动构造函数</strong></p>
<h2 id="Item-27-Familiarize-yourself-with-alternatives-to-overloading-on-universal-references"><a href="#Item-27-Familiarize-yourself-with-alternatives-to-overloading-on-universal-references" class="headerlink" title="Item 27: Familiarize yourself with alternatives to overloading on universal references."></a>Item 27: Familiarize yourself with alternatives to overloading on universal references.</h2><h2 id="Item-28-Understand-reference-collapsing"><a href="#Item-28-Understand-reference-collapsing" class="headerlink" title="Item 28: Understand reference collapsing"></a>Item 28: Understand reference collapsing</h2><p><strong>要点</strong><br><strong>1、</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(T&amp;&amp; param)</span></span>;</div><div class="line"><span class="comment">/*</span></div><div class="line"><span class="comment">根据传入param是lvalue或者rvalue，T的推导类型会有不同。param是lvalue，则T推导为lvalue reference，当param是rvalue，T推导为non-reference。</span></div><div class="line"><span class="comment">*/</span></div></pre></td></tr></table></figure></p>
<p><strong>2、在C++中引用的引用是违法的</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> x;</div><div class="line">...</div><div class="line"><span class="keyword">auto</span>&amp; &amp; rx=x;<span class="comment">//ERROR</span></div></pre></td></tr></table></figure></p>
<p><strong>3、但是当lvalue传入一个以universal reference为类型的模板时</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(T&amp;&amp; param)</span></span>;</div><div class="line"></div><div class="line">Widget w;</div><div class="line">func(w);<span class="comment">//w是一个lvalue，那么T推导为Widget&amp;</span></div><div class="line"><span class="comment">//则模板应该被实例化为以下：</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(Widget&amp; &amp;&amp; param)</span></span>;</div><div class="line"><span class="comment">//实际上这时一种叫做reference collapsing的机制，使得模板的最终实例化如下：</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(Widget&amp; param)</span></span>;<span class="comment">//这与之前所说的以lvalue初始化universal </span></div><div class="line"><span class="comment">//reference，其结果为lvalue  reference一致。</span></div></pre></td></tr></table></figure></p>
<p><strong>4、reference collapsing规则</strong><br>在允许reference collapsing的情况下，如果两个reference中，任一个是lvalue reference，则结果是lvalue reference，否则结果是rvalue reference。<br>实际上，std::forward就是根据这个机制实现的。<br><strong>5、深入理解universal reference</strong><br>实际上，universal reference不是一种新引用，它是rvalue reference在以下条件满足时的一种特殊情况：<br><strong>条件1</strong>类型推导区分左值和右值。类型T的左值推导为类型 T&amp;，类型T的右值推导为类型 T。<br><strong>条件2</strong>发生了reference collapsing。<br><strong>6、reference collapsing发生的情况</strong><br><strong>情况1</strong>模板实例化<br><strong>情况2</strong>auto类型生成<br><strong>情况3</strong>生成、使用typedef 和 使用别名声明<br><strong>情况4</strong>使用decltype</p>
<h2 id="Item-29-Assume-that-move-operations-are-not-present-not-cheap-and-not-used"><a href="#Item-29-Assume-that-move-operations-are-not-present-not-cheap-and-not-used" class="headerlink" title="Item 29: Assume that move operations are not present, not cheap, and not used"></a>Item 29: Assume that move operations are not present, not cheap, and not used</h2><p><strong>要点</strong><br><strong>1、在以下情况下，std::move不会带来任何好处。</strong><br><strong>No move operations</strong><br><strong>Move not faster</strong><br><strong>Move not usable</strong><br><strong>Source object is lvalue</strong><br><strong>2、最好假设move操作不存在，不高效，没用过。只有在类型明确或者支持move语义时不需要这个假设。</strong></p>
<h2 id="Item-30-Familiarize-yourself-with-perfect-forwarding-failure-cases"><a href="#Item-30-Familiarize-yourself-with-perfect-forwarding-failure-cases" class="headerlink" title="Item 30: Familiarize yourself with perfect forwarding failure cases"></a>Item 30: Familiarize yourself with perfect forwarding failure cases</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、Scott Meyers<br>Effective Modern C++ : 42 Specific Ways to Improve Your Use of C++11 and C++14</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">cpp</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cpp//" class="article-tag-list-link color4">cpp</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/04/23/cpp-lvalue-and-rvalue/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cpp-smart-ptr" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/21/cpp-smart-ptr/">C++中的智能指针笔记</a>
    </h1>
  

        
        <a href="/2018/04/21/cpp-smart-ptr/" class="archive-article-date">
  	<time datetime="2018-04-21T07:28:33.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-04-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#STL中智能指针"><span class="toc-text">STL中智能指针</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#shared-ptr"><span class="toc-text">shared_ptr</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#shared-ptr的声明和初始化"><span class="toc-text">shared_ptr的声明和初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#析构策略"><span class="toc-text">析构策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#shared-ptr陷阱"><span class="toc-text">shared_ptr陷阱</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#weak-ptr"><span class="toc-text">weak_ptr</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#unique-ptr"><span class="toc-text">unique_ptr</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Modern-C-中的有关条款"><span class="toc-text">Effective Modern C++ 中的有关条款</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#opencv-中的cv-Ptr"><span class="toc-text">opencv 中的cv::Ptr</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>最近在看opencv的文档时，对cv::Ptr类了解了一些，其与STL中的shared_ptr类似，是一种智能指针，于是又看了《C++标准库》中有关智能指针的章节和《Effective Modern C++》中的有关智能指针的章节，将智能指针所涉及的一些内容总结如下。</p>
<h1 id="STL中智能指针"><a href="#STL中智能指针" class="headerlink" title="STL中智能指针"></a>STL中智能指针</h1><p>C++中比较棘手的一个问题就是内存的管理，指针在其中扮演了及其重要的作用，但是同时对指针的不当使用会造成很多问题。自C++11起，STL提供了两大类型的智能指针，使得对指针的操作更加安全。其中shared_ptr类实现了共享式拥有概念，而unique_ptr实现了独占式拥有概念。另外还有weak_ptr等辅助类。所有这些指针类都定义在头文件 &lt; memory&gt;中。</p>
<h2 id="shared-ptr"><a href="#shared-ptr" class="headerlink" title="shared_ptr"></a>shared_ptr</h2><p>shared_ptr主要使用一种称为引用计数的方法来管理其所指向的内容。当该指针多指向一个内容时，引用计数加一，少指向一个内容时，引用计数值减1，当引用计数值减到0时，该内容会被自动删除。</p>
<h3 id="shared-ptr的声明和初始化"><a href="#shared-ptr的声明和初始化" class="headerlink" title="shared_ptr的声明和初始化"></a>shared_ptr的声明和初始化</h3><p>1、<strong>使用构造函数初始化</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pInt(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>));</div></pre></td></tr></table></figure></p>
<p>2、<strong>新式初始化语法</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pInt&#123;<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>)&#125;;</div></pre></td></tr></table></figure></p>
<p>3、<strong>使用make_shared()初始化</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pInt=<span class="built_in">std</span>::make_shared&lt;<span class="keyword">int</span>&gt;(<span class="number">1</span>);</div></pre></td></tr></table></figure></p>
<p>4、<strong>先声明shared pointer，然后使用reset()方法赋值</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pInt;</div><div class="line">pInt.reset(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>));</div></pre></td></tr></table></figure></p>
<p><strong>注意不能使用赋值符进行初始化</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pInt=<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>);<span class="comment">//ERROR</span></div></pre></td></tr></table></figure></p>
<p>最常用和可靠的初始化方法是使用make_shared()函数。</p>
<h3 id="析构策略"><a href="#析构策略" class="headerlink" title="析构策略"></a>析构策略</h3><p>实际上，我们可以声明特化的deleter，可以通过传递一个lambda作为shared_ptr构造函数的第二实参。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pInt(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>),[](<span class="keyword">int</span>* p)&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span>&lt;&lt;<span class="string">"delete "</span>&lt;&lt;*p&lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">delete</span> p;</div><div class="line">    &#125;);</div></pre></td></tr></table></figure></p>
<p><strong>注意</strong>：shared_ptr提供的default deleter 调用的是 delete,而不是delete []，所以即便为array建立一个shared_ptr是可以的，但是却有致命错误，解决方法是为其指定delete []作为析构函数，最好不要这样使用shared_ptr。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pArray(<span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>]);<span class="comment">//ERROR,能通过编译</span></div><div class="line"><span class="comment">//(《C++标准库》一书中这样写，但是实际测试没有出现问题？)</span></div><div class="line"></div><div class="line"><span class="comment">//解决方案</span></div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pArray(<span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>],[](<span class="keyword">int</span>* p)&#123;</div><div class="line">    <span class="keyword">delete</span>[] p;</div><div class="line">    &#125;)</div><div class="line"><span class="comment">//也可以这样</span></div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; pArray(<span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>],<span class="built_in">std</span>::default_delete&lt;<span class="keyword">int</span>[]&gt;());</div></pre></td></tr></table></figure></p>
<p><strong>如果析构时不仅仅需要删除内存，还需要 一些其它操作，那么必须指定deleter</strong></p>
<h3 id="shared-ptr陷阱"><a href="#shared-ptr陷阱" class="headerlink" title="shared_ptr陷阱"></a>shared_ptr陷阱</h3><p><strong>1、cyclic reference问题</strong><br>两个对象使用shared_ptr互相指向对方时，使用shared_ptr无法释放相应的资源，因为每个对象的use_count()至少为1。<br><strong>解决方法</strong>:1、使用普通指针，但是这样又得自行管理资源释放，比较麻烦也更容易出问题。2、其中一方的指向使用weak_ptr，可以完美解决该问题。<br><strong>2、试图访问已被释放的数据</strong><br>也可通过使用weak_ptr解决。<br><strong>3、应该确保某对象只被一组shared_ptr拥有</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span>* p=<span class="keyword">new</span> <span class="keyword">int</span>;</div><div class="line"><span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; sp1(p);</div><div class="line"><span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; sp2(p);<span class="comment">//ERROR 但是可以编译通过 具体在后面有解释</span></div></pre></td></tr></table></figure></p>
<p>当sp1和sp2丢失p的拥有权时，两者都会试图释放p的资源，即释放资源的操作会执行两次。解决方法是在创建对象和其相应资源的时候直接设立shared_ptr。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; sp1(<span class="keyword">new</span> <span class="keyword">int</span>);</div><div class="line"><span class="built_in">shared_ptr</span>&lt;<span class="keyword">int</span>&gt; sp2(sp1);</div></pre></td></tr></table></figure></p>
<h2 id="weak-ptr"><a href="#weak-ptr" class="headerlink" title="weak_ptr"></a>weak_ptr</h2><p>weak_ptr是辅助shared_ptr的类，其用来共享但是不拥有对象。</p>
<h2 id="unique-ptr"><a href="#unique-ptr" class="headerlink" title="unique_ptr"></a>unique_ptr</h2><p><strong>概念</strong><br>unique_ptr实现了独占式拥有概念，其可以确保一个对象和其相应的资源在同一时间只能被一个pointer拥有。unique_ptr是其所指向的对象的唯一拥有者。unique_ptr有着与普通指针相同的接口，不同的是：它不提供pointer算术比如++等操作，但是实际上这省去了一些麻烦。<br><strong>转移unique_ptr的拥有权</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span>* p=<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>);</div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up1(p);</div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up2(p);<span class="comment">//ERROR,up1和up2拥有相同对象了。</span></div><div class="line"></div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up3(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>));</div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up4(up3);<span class="comment">//ERROR, 不能对unique_ptr进行拷贝和赋值</span></div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up5(<span class="built_in">std</span>::move(up3));<span class="comment">//OK 使用move转移所有权是可以的</span></div><div class="line"></div><div class="line"><span class="comment">//同理</span></div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up6=<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">1</span>);</div><div class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up7;</div><div class="line">up7=up6;<span class="comment">//ERROR</span></div><div class="line">up7=<span class="built_in">std</span>::move(up6);<span class="comment">//可以</span></div><div class="line"></div><div class="line">up7=<span class="literal">nullptr</span>;<span class="comment">//给unique_ptr赋值nullptr是可以的，和调用reset()方法相同</span></div></pre></td></tr></table></figure></p>
<p><strong>源头和去处</strong><br>函数可以利用unique_ptr的转移所有权的功能将拥有权转给其他函数。<br><strong>unique_ptr当做当做class内的成员</strong><br>可以避免资源泄漏。</p>
<h2 id="Effective-Modern-C-中的有关条款"><a href="#Effective-Modern-C-中的有关条款" class="headerlink" title="Effective Modern C++ 中的有关条款"></a>Effective Modern C++ 中的有关条款</h2><p>《Effective Modern C++》一书中有几个关于smart pointer的条款。<br><strong>Item 18: Use std::unique_ptr for exclusive-ownership resource management</strong><br>要点：详见原书 P118<br>1、std::unique_ptr是一种足够小，很快并且只支持move的智能指针，其用来管理独占式资源。默认情况下，std::unique_ptr的大小和raw pointer  是一样的，而且对于大多数包括解引用在内的操作，其都和raw pointer一致。<br>2、默认情况下，其使用delete作为deleter。但是当deleter采用自定义时，std::unique_ptr的大小会变大，其具体大小取决于函数对象的状态。使用lambda表达式作为deleter是比较好的一种选择。<br>3、std::unique_ptr不能进行复制，否则就违反了其只能拥有一个对象的规则。<br>4、std::unique_ptr有两种形式: std::unique_ptr<t>,std::unique_ptr<t[]>。这两种形式所能进行的操作略有不同，对于单对象形式，其没有索引操作，对于数组形式，其没有 解引用操作。<br>5、从std::unique_ptr转型为std::shared_ptr很方便，在不知道指针的具体用途时最好先用unique_ptr，待需要时再转型为shared_ptr。<br><strong>题外话</strong>要想正确调用继承类的析构函数，基类的析构函数必须是虚函数。</t[]></t></p>
<p><strong>Item 19: Use std::shared_ptr for shared_ownership resource management</strong><br>要点：详见原书 P125<br>1、<strong>关于引用计数</strong><br>通常，构造函数增加引用计数；析构函数减少引用计数；复制赋值操作减少左边所指对象的引用计数，增加右边所指对象的引用计数。<br>2、<strong>引用计数会影响性能</strong><br>主要由以下原因造成：首先，shared_ptr的大小是原始指针的2倍，因为其有1个指针指向所引的对象，1个指针指向引用计数；然后，用于引用计数的内存要动态分配；对于引用计数的增加和减少操作必须是原子性的，这是为了保证其在多线程情况下的安全性。<br>3、<strong>shared_ptr和unique_ptr的区别和联系</strong><br>A、都支持自定义deleter，但是实现有所不同，对于unique_ptr，deleter的类型是智能指针类型的一部分，而对于shared_ptr,deleter的类型不是其一部分。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> loggingDel =[](Type* pc)&#123;</div><div class="line">    makeLogEntry(pt);</div><div class="line">    <span class="keyword">delete</span> pt;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Type, <span class="keyword">decltype</span>(loggingDel)&gt; upt(<span class="keyword">new</span> Type,loggingDel);</div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt(<span class="keyword">new</span> Type,loggingDel);</div></pre></td></tr></table></figure></p>
<p>所以，对于不同类型的deleter的两个shared_ptr，只要它们的对象类型相同，其就可以相互赋值；而对于unique_ptr则不能，因为deleter也是其类型的一部分，这意味着这两个unique_ptr的类型不同，不能相互转移所有权。<br>B、对于shared_ptr，自定义deleter并不改变shared_ptr的大小，但是对于unique_ptr是有影响的。<br>C、shared_ptr不支持数组类型。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">shared_ptr</span>&lt;T[]&gt; sp;<span class="comment">//不能编译</span></div></pre></td></tr></table></figure></p>
<p><strong>4、shared_ptr的实现原理</strong><br>其使用control block管理引用计数及其他(包括自定义deleter)数据。<br><img src="shared_ptr.JPG" alt="shared_ptr原理"><br>我们希望某个对象的control block是在初次有指针指该对象时创建。然而当创建shared_ptr指向某一对象时，我们事先并不能知道是否已有其它shared_ptr指向该对象。于是使用以下规则来进行control block的创建：<br><strong>std::make_shared总是创建一个control block</strong><br><strong>当shared_ptr是由unique_ptr转型创建时要建立control block_</strong><br><strong>当用raw pointer构造shared_ptr时要创建control block</strong></p>
<p>考虑如下语句<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> pt = <span class="keyword">new</span> Type;</div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt1(pt,loggingDel);</div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt2(pt,loggingDel);</div></pre></td></tr></table></figure></p>
<p>按照之前的control block创建规则，对于pt指针指向的对象，将会创建2个control block，于是离开作用域时，会尝试对*pt进行两次内存释放操作，这样第二次操作将会造成未定义行为。这是我们不愿意看到的。<br>从以上例子我们可以得到这样的经验：<br><strong>避免向shared_ptr的构造函数传递raw pointer</strong><br>可以采用以下方法<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//对于自定义deleter的情况</span></div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt1(<span class="keyword">new</span> Type,loggingDel);</div><div class="line"><span class="comment">//无自定义deleter时还可使用make_shared</span></div><div class="line"><span class="built_in">std</span>::make_shared&lt;Type&gt;(t);</div></pre></td></tr></table></figure></p>
<p><strong>5、可使用std::enable_shared_from_this将this指针转型成shared_ptr</strong></p>
<p><strong>Item 20: Use std::weak_ptr for std::shared_ptr like pointers that can dangle</strong><br>要点：具体看原书P134<br><strong>std::weak_ptr不会影响引用计数值</strong><br>std::weak_ptr的行为和shared_ptr相似，但是其不会影响所指对象的引用计数值，也不能被解引用，其是shared_ptr的辅助。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> spt=<span class="built_in">std</span>::make_shared&lt;Type&gt;();<span class="comment">//ref count=1</span></div><div class="line"><span class="built_in">std</span>::weak_ptr&lt;Type&gt; wpt(spt);<span class="comment">// ref count remains 1</span></div><div class="line">spt=<span class="literal">nullptr</span>;<span class="comment">//ref count=0 and wpt now dangles</span></div><div class="line"><span class="keyword">if</span>(wpt.expired())&#123;&#125; <span class="comment">//test if wpt doesn't point to an object</span></div></pre></td></tr></table></figure></p>
<p>一个问题就是：在判断weak_ptr仍然指着一个特定对象时，如何访问该对象？这里有几个棘手的问题需要解决：weak_ptr并没有解引用操作，而且即便有解引用操作，在判断是否expired和解引用的语句之间，可能有另一个线程使得最后一个指向该对象的指针失效，使得该对象被destroy，这样解引用操作将会导致未定义行为，即我们无法保证线程安全性。<br>我们需要的是一个原子性的操作检查weak_ptr是否expired，如果没有，那么访问该指针所指对象，这可以通过从weak_ptr构造一个shared_ptr实现。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//第一种形式</span></div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt1=wpt.lock();<span class="comment">//if wpt's expired,spt1 is nullptr</span></div><div class="line"></div><div class="line"><span class="comment">//第二种形式</span></div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt2(wpt);<span class="comment">//if wpt's expired, throw std::bad_weak_ptr</span></div></pre></td></tr></table></figure></p>
<p><strong>2、weak_ptr的应用场景</strong><br>A、管理缓存时，需要知道cache什么时候会dangle，这样的场景就需要weak_ptr辅助。(P136)<br>B、解决shared_ptr的环形引用问题。<br><strong>3、weak_ptr和shared_ptr</strong><br>从效率的角度讲，weak_ptr的效率和shared_ptr是一样的。其存储和shared_ptr是一样的 ，其大小和shared_ptr也是一样的，它也要使用control block管理对象。<strong>注意</strong>：weak_ptr不是不管理引用计数，而是不拥有对象共享关系，所以不会影响所指对象的引用计数，但是其会管理另外的不同功能的引用计数。</p>
<p><strong>Item 21: Prefer std::make_unique and std::make_shared to direct use of new</strong><br>要点：具体看原书P139<br><strong>1、使用make函数的优点</strong><br>make_shared是C++11的标准，make_unique是C++14的标准。<br><strong>A、使得代码和编译的目标代码更精简</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">auto upt1(std::make_unique&lt;Type&gt;());</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Type&gt; upt2(<span class="keyword">new</span> Type);</div><div class="line"></div><div class="line">auto spt1(std::make_shared&lt;Type&gt;());</div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Type&gt; spt2(<span class="keyword">new</span> Type);</div></pre></td></tr></table></figure></p>
<p><strong>B、使用make函数使得异常安全(exception safety)</strong><br><strong>C、make_shared和allocate_shared函数使得编译器生成更小更快的代码(相比使用new创建)</strong></p>
<p>原则是优先使用make函数创建只能指针，但是也有make函数不能使用的情况。<br><strong>A</strong>、比如要自定义deleter时，就只能使用new作为参数创建，而不能使用make函数。<br><strong>B</strong>、一些所指对象的初始化细节使得不能使用make函数创建智能指针。<br><strong>C</strong>、一些自定义了new和delete的对象不方便用make函数创建智能指针。<br><strong>D</strong>、对于比较大的对象，不要使用make函数创建智能指针。</p>
<p><strong>Item 22: When using the Pimpl  Idiom, define special member functions in the implementation file</strong><br>要点：<br><strong>1、Pimpl Idiom通过类客户和类实现之间减少编译依赖来减少构建时间</strong><br><strong>2、对于std::unique_ptr pImpl指针，需要在类头文件中声明特殊成员函数，在实现文件中实现。即便是默认函数实现，也需要声明和定义。</strong><br><strong>3、对于 shared_ptr则没有以上这种限制。主要原因还是在于unique_ptr和shared_ptr中deleter是否是类型的一部分的一个区别。</strong></p>
<h1 id="opencv-中的cv-Ptr"><a href="#opencv-中的cv-Ptr" class="headerlink" title="opencv 中的cv::Ptr"></a>opencv 中的cv::Ptr</h1><p>其行为和std::shared_ptr类似。用法也基本相同。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、Nicolai M. Josuttis<br> The C++ Standard Library - A Tutorial and Reference, 2nd Edition<br> Addison Wesley Longman, 2012<br>2、Scott Meyers<br>Effective Modern C++ : 42 Specific Ways to Improve Your Use of C++11 and C++14<br>3、<a href="http://en.cppreference.com/w/cpp/memory/shared_ptr" target="_blank" rel="external">std::shared_ptr</a><br>4、<a href="http://en.cppreference.com/w/cpp/memory/weak_ptr" target="_blank" rel="external">std::weak_ptr</a><br>5、<a href="http://en.cppreference.com/w/cpp/memory/unique_ptr" target="_blank" rel="external">std::unique_ptr</a><br>6、<a href="https://docs.opencv.org/3.4.1/d0/de7/structcv_1_1Ptr.html" target="_blank" rel="external">cv::Ptr</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">cpp</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cpp//" class="article-tag-list-link color4">cpp</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/04/21/cpp-smart-ptr/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-ssd-detailed" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/27/ssd-detailed/">SSD-Single Shot MultiBox Detector</a>
    </h1>
  

        
        <a href="/2018/03/27/ssd-detailed/" class="archive-article-date">
  	<time datetime="2018-03-27T08:48:10.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-27</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#亮点"><span class="toc-text">亮点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基本结构"><span class="toc-text">基本结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本思想"><span class="toc-text">基本思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#网络结构"><span class="toc-text">网络结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实现细节"><span class="toc-text">实现细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prior-box的生成"><span class="toc-text">prior box的生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#匹配策略"><span class="toc-text">匹配策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#loss-function"><span class="toc-text">loss function</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>因为毕设是做关于目标检测的项目，也看了一些目标检测的论文，由于项目对实时性的要求，最后选用了MobilenetV2+SSD作为基础结构，也仔细阅读了SSD的论文，现梳理如下。</p>
<h2 id="亮点"><a href="#亮点" class="headerlink" title="亮点"></a>亮点</h2><p>一步完成检测，同时进行边框回归和类别预测，相对于两步完成的网络在时间上会快很多。结合多个feature maps的特征进行预测。</p>
<h2 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h2><h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><p><img src="default_boxes.jpg" alt="feature map"><br>在不同尺度的feature map上指定一系列default boxes。具体来说就是，上图的feature map中，对于每个cell，首先生成k个default boxes，对于每个default box,预测其类别和位置，于是共有(4+cls)个参数。每层的k个default boxes的aspect ratio不同，而不同feature maps上的default boxes的scale不同，这样基本就能适配各种状态下的目标。最后将不同feature maps上的结果综合起来进行训练。这样对于一个输入的大小为mxm的feature map，最后的得到的default boxes个数为 m<em>m</em>k<em>(4+cls),为了达到这样的输出维度，用一个深度为k</em>(4+cls)的3<em>3，stride=1的卷积核即可得到，但是实际上是分为两个不同的卷积来实现，一个深度为4</em>k的loc层，一个深度为k*cls的conf层。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="ssd_architecture.jpg" alt="SSD网络结构"><br>SSD的网络结构中包括base部分的特征提取层，以及额外的extra layer用于生成不同尺度的feature map用于default boxes的生成。base部分理论上可以是任何用于classification的卷积网络。在原论文中，作者使用VGG-16作为base网络，feature maps总共有6层，前两层为base 网络中的两个卷积层，后4层feature maps来自extra layers。在6个feature maps上做卷积操作得到综合的输出送入loss层进行回归训练。</p>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="prior-box的生成"><a href="#prior-box的生成" class="headerlink" title="prior box的生成"></a>prior box的生成</h3><p>实际上就是解决不同level的feature maps上的default boxes如何与原图上的default boxes相对应的问题，也就是根据default box的4个offset参数，如何找到其在原图上的对应坐标。这就是prior box的生成问题。<br>简单来说就是根据scale以及aspect ratio按照步长生成，步长就相当于feature map中一个像素对应的原图中的像素数，实际上就是原图大小和feature map的比值。论文中生成的坐标格式是[cx,cy,w,h]格式。</p>
<h3 id="匹配策略"><a href="#匹配策略" class="headerlink" title="匹配策略"></a>匹配策略</h3><p>在确定default box和 groud truth的对应关系时，采用best jaccard overlap方法，对于jaccard overlap高于一个阈值(0.5)的匹配对，我们都认为它们匹配成功。然后利用这些匹配对计算loss，进行回归。</p>
<h3 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h3><p>loss由loc loss和 conf loss两部分组成，分别表示定位损失和分类损失，具体计算公式在原文中讲的很具体。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="external">SSD论文</a><br><a href="https://github.com/ShuangXieIrene/ssds.pytorch" target="_blank" rel="external">ssds.pytorch</a><br><a href="http://www.cnblogs.com/xuanyuyt/p/7222867.html" target="_blank" rel="external">SSD阅读笔记</a><br><a href="https://zhuanlan.zhihu.com/p/33544892" target="_blank" rel="external">目标检测|SSD原理与实现</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/paper//" class="article-tag-list-link color1">paper</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/27/ssd-detailed/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-paperlist" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/25/paperlist/">论文列表</a>
    </h1>
  

        
        <a href="/2018/03/25/paperlist/" class="archive-article-date">
  	<time datetime="2018-03-25T15:49:03.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Detection"><span class="toc-text">Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Detection"><span class="toc-text">Object Detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Video-Detection"><span class="toc-text">Video Detection</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Classfication"><span class="toc-text">Classfication</span></a></li></ol>
</div>

        <p>主要列一些计算机视觉方面的论文。</p>
<h1 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h1><h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><p>目前主流方法都是基于深度学习的。<br><strong>One Stage</strong><br><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="external">SSD</a><br><a href="https://pjreddie.com/media/files/papers/yolo.pdf" target="_blank" rel="external">YOLO</a><br><a href="https://pjreddie.com/media/files/papers/YOLO9000.pdf" target="_blank" rel="external">YOLOv2</a><br><a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="external">YOLOv3</a><br><a href="https://arxiv.org/pdf/1802.06488.pdf" target="_blank" rel="external">Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection</a><br><strong>Two Stage</strong></p>
<h2 id="Video-Detection"><a href="#Video-Detection" class="headerlink" title="Video Detection"></a>Video Detection</h2><p><a href="https://arxiv.org/pdf/1804.05830.pdf" target="_blank" rel="external">Towards High Performance Video Object Detection for Mobiles</a></p>
<h1 id="Classfication"><a href="#Classfication" class="headerlink" title="Classfication"></a>Classfication</h1>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cv//" class="article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/25/paperlist/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-pytorch-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/25/pytorch-notes/">Pytorch使用问题记录</a>
    </h1>
  

        
        <a href="/2018/03/25/pytorch-notes/" class="archive-article-date">
  	<time datetime="2018-03-25T06:40:59.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  
</div>

        <p>主要记录使用pytorch过程中的一些问题及解决方法<br>1、<strong>GPU训练网络后，在CPU中使用的问题</strong><br>1.1、使用load_static_dict API时需要根据是否使用GPU指定map参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> self.num_gpu == <span class="number">0</span>:</div><div class="line">    map_location = <span class="keyword">lambda</span> storage, loc: storage</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    map_location = <span class="keyword">None</span></div></pre></td></tr></table></figure></p>
<p>1.2、在我的一次实验中，多GPU训练后保存的pth模型和单GPU的有点不太一致，使得多GPU的模型不能在CPU上加载。解决方案是，先在多GPU训练，最后几个epoch使用单GPU训练，之后保存单GPU的训练模型。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/pytorch//" class="article-tag-list-link color3">pytorch</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/25/pytorch-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-ads-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/18/ads-notes/">高级数据结构与算法分析 课程要点</a>
    </h1>
  

        
        <a href="/2018/03/18/ads-notes/" class="archive-article-date">
  	<time datetime="2018-03-18T08:37:01.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#week1-AVL-Trees-Splay-Trees-and-Amoritized-Analysis"><span class="toc-text">week1 AVL Trees, Splay Trees and Amoritized Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AVL-Trees"><span class="toc-text">AVL Trees</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Splay-Trees"><span class="toc-text">Splay Trees</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Amoritized-Analysis"><span class="toc-text">Amoritized Analysis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week2-Red-Black-Trees-and-B-Trees"><span class="toc-text">Week2 Red-Black Trees and B+ Trees</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Red-Black-Trees"><span class="toc-text">Red-Black Trees</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Trees"><span class="toc-text">B+ Trees</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week3-Inverted-File-Index"><span class="toc-text">Week3 Inverted File Index</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week4-Leftist-Heaps-and-Skew-Heaps"><span class="toc-text">Week4 Leftist Heaps and Skew Heaps</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Leftist-Heaps"><span class="toc-text">Leftist Heaps</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Skew-Heaps"><span class="toc-text">Skew Heaps</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week5-Binomial-Queue"><span class="toc-text">Week5 Binomial Queue</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week6-Backtracking"><span class="toc-text">Week6 Backtracking</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week7-Divide-and-Conquer"><span class="toc-text">Week7 Divide and Conquer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Week8-Dynamic-Programming"><span class="toc-text">Week8 Dynamic Programming</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h2 id="week1-AVL-Trees-Splay-Trees-and-Amoritized-Analysis"><a href="#week1-AVL-Trees-Splay-Trees-and-Amoritized-Analysis" class="headerlink" title="week1 AVL Trees, Splay Trees and Amoritized Analysis"></a>week1 AVL Trees, Splay Trees and Amoritized Analysis</h2><h3 id="AVL-Trees"><a href="#AVL-Trees" class="headerlink" title="AVL Trees"></a>AVL Trees</h3><p><strong>Insert</strong><br>RR LL LR RL<br><strong>Delete</strong><br>no child<br>only left/right child<br>left and right children: find smallest node in right child, swap and delete</p>
<h3 id="Splay-Trees"><a href="#Splay-Trees" class="headerlink" title="Splay Trees"></a>Splay Trees</h3><p><strong>Find</strong><br>每查询一次都将其旋转到根节点。<br><strong>Delete</strong><br>Find X —&gt; Remove X —&gt; FindMax(LTree) —&gt; 将右子树作为左子树的右孩子</p>
<h3 id="Amoritized-Analysis"><a href="#Amoritized-Analysis" class="headerlink" title="Amoritized Analysis"></a>Amoritized Analysis</h3><p><strong>Aggregate analysis</strong><br><strong>Accounting method</strong><br><strong>Potential method</strong></p>
<h2 id="Week2-Red-Black-Trees-and-B-Trees"><a href="#Week2-Red-Black-Trees-and-B-Trees" class="headerlink" title="Week2 Red-Black Trees and B+ Trees"></a>Week2 Red-Black Trees and B+ Trees</h2><h3 id="Red-Black-Trees"><a href="#Red-Black-Trees" class="headerlink" title="Red-Black Trees"></a>Red-Black Trees</h3><p><strong>Definition</strong><br>A red-black tree with N internal nodes has height at most 2ln(N +1).<br><strong>Insert</strong><br>3 cases<br><strong>Delete</strong><br>delete a leaf node<br>delete a degree 1 node<br>delete a degree 2 node<br>关键是调整颜色：4 cases</p>
<h3 id="B-Trees"><a href="#B-Trees" class="headerlink" title="B+ Trees"></a>B+ Trees</h3><p><strong>Definition</strong><br><strong>Insert</strong><br><strong>Delete</strong></p>
<h2 id="Week3-Inverted-File-Index"><a href="#Week3-Inverted-File-Index" class="headerlink" title="Week3 Inverted File Index"></a>Week3 Inverted File Index</h2><p><strong>Some definition</strong><br>Index<br>Inverted file<br><strong>Key points</strong><br>Word Stemming<br>Stop Words<br>Accessing a term: Search trees(B-trees,B+ trees, Tries,..) or Hashing?<br>Distributed indexing: Term-partitioned index and Document-partitioned index<br>Measures for a search engine: 1-How fast does it index? 2-How fast does it search? 3-Expressiveness of query language<br>Relevance measurement: Precise Recall</p>
<h2 id="Week4-Leftist-Heaps-and-Skew-Heaps"><a href="#Week4-Leftist-Heaps-and-Skew-Heaps" class="headerlink" title="Week4 Leftist Heaps and Skew Heaps"></a>Week4 Leftist Heaps and Skew Heaps</h2><h3 id="Leftist-Heaps"><a href="#Leftist-Heaps" class="headerlink" title="Leftist Heaps"></a>Leftist Heaps</h3><p><strong>Definition</strong><br>null path length<br>A leftist tree with r nodes on the right path must have at least \(b^2-1\) nodes.<br><strong>Merge</strong><br>recursive version and iterative version<br><strong>DeleteMin</strong><br>delete the root and merge the two subtrees</p>
<h3 id="Skew-Heaps"><a href="#Skew-Heaps" class="headerlink" title="Skew Heaps"></a>Skew Heaps</h3><p><strong>Definition</strong><br>a simple version of the leftest heaps<br><strong>Merge</strong><br><strong>Amortized Analysis for Skew Heaps</strong></p>
<h2 id="Week5-Binomial-Queue"><a href="#Week5-Binomial-Queue" class="headerlink" title="Week5 Binomial Queue"></a>Week5 Binomial Queue</h2><p><strong>Definition</strong><br><strong>FindMin</strong><br><strong>Merge</strong><br><strong>DeleteMin</strong><br><strong>Implementation</strong><br>left child and right next sibling<br>Performing N Inserts on an initially empty binomial queue will take O(N) worst-case time.  Hence the average time is constant.</p>
<h2 id="Week6-Backtracking"><a href="#Week6-Backtracking" class="headerlink" title="Week6 Backtracking"></a>Week6 Backtracking</h2><h2 id="Week7-Divide-and-Conquer"><a href="#Week7-Divide-and-Conquer" class="headerlink" title="Week7 Divide and Conquer"></a>Week7 Divide and Conquer</h2><h2 id="Week8-Dynamic-Programming"><a href="#Week8-Dynamic-Programming" class="headerlink" title="Week8 Dynamic Programming"></a>Week8 Dynamic Programming</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">algorithm</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/algorithm//" class="article-tag-list-link color5">algorithm</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/18/ads-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-effective-python-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/12/effective-python-notes/">Effective Python 编写高质量代码的59个有效方法</a>
    </h1>
  

        
        <a href="/2018/03/12/effective-python-notes/" class="archive-article-date">
  	<time datetime="2018-03-12T13:51:24.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-12</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#条款总览"><span class="toc-text">条款总览</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#用Pythonic方式来思考"><span class="toc-text">用Pythonic方式来思考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#函数"><span class="toc-text">函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#类与继承"><span class="toc-text">类与继承</span></a></li></ol></li></ol>
</div>

        <h1 id="条款总览"><a href="#条款总览" class="headerlink" title="条款总览"></a>条款总览</h1><h2 id="用Pythonic方式来思考"><a href="#用Pythonic方式来思考" class="headerlink" title="用Pythonic方式来思考"></a>用Pythonic方式来思考</h2><p>1、<strong>确认自己所用的Python版本</strong><br>2、<strong>遵循PEP 8 风格指南</strong><br>3、<strong>了解bytes、str与unicode的区别</strong><br>4、<strong>用辅助函数来取代复杂的表达式</strong><br>5、<strong>了解切割序列的方法</strong><br>6、<strong>在单次切片操作内，不要同时指定start、end和stride</strong><br>7、<strong>用列表推导取代 map 和 filter</strong><br>8、<strong>不要使用含有两个以上表达式的列表推导</strong><br>9、<strong>用生成器表达式来改写数据量较大的列表推导</strong><br>列表推导方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">value = [len(x) <span class="keyword">for</span> x <span class="keyword">in</span> open(<span class="string">'/tmp/my_file.txt'</span>)]</div><div class="line">print(value)</div></pre></td></tr></table></figure></p>
<p>生成器表达式是对列表推导和生成器的一种泛化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">it = (len(x) <span class="keyword">for</span> x <span class="keyword">in</span> open(<span class="string">'/tmp/my_file.txt'</span>))</div><div class="line">print(it)</div><div class="line">print(next(it))</div></pre></td></tr></table></figure></p>
<p>输入数据量较大时，列表推导可能会因为占用太多内存而出问题 。有生成器表达式所返回的迭代器，可以逐次产生输入值，从而避免了内存用量问题。把某个生成器表达式所返回的迭代器，放在另一个生成器表达式的for子表达式中，可将二者组合起来。串在一起的生成器表达式执行速度更快。<br>10、<strong>尽量用enumerate取代range</strong><br>enumerate函数提供了一种精简的写法，可以在遍历迭代器时获知每个元素的索引。尽量用enumerate来改写那种将range与下标访问相结合的序列遍历代码。可以给enumerate提供第二个参数，以指定开始计数时所用的值(默认值是0)<br>11、<strong>用zip函数同时遍历两个迭代器</strong><br>12、<strong>不要在for和while循环后面写else块</strong><br>13、<strong>合理利用try\except\else\finally结构中的每个代码块</strong><br>无论try块是否发生异常，都可以利用try/finally复合语句中的finally块来执行清理工作。else块可以用来缩减try块中的代码量，并把没有发生异常时所要执行的语句与try/except代码块隔开。顺利运行try块后，若想使得某些操作能在finally块的清理代码之前执行，则可将这些操作写到else块中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">example</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        do_something()</div><div class="line">    <span class="keyword">except</span> Error <span class="keyword">as</span>  e:</div><div class="line">        <span class="keyword">return</span> UNDEFINED</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        do_otherthing()</div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        clean()</div></pre></td></tr></table></figure></p>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>14、<strong>尽量用异常来表示特殊情况，而不要返回None</strong><br>15、<strong>了解如何在闭包里使用外围作用域中的变量</strong><br>对于定义在某作用域内的闭包来说，它可以引用这些作用域中的变量。使用默认方式对闭包内的变量赋值，不会影响外围作用域中的同名变量。在Python3中，程序可以在闭包内用nonlocal语句来修饰某个名称，使得该闭包能够修改外围作用域中的同名变量。除了一些比较简单的函数，尽量不要使用nonlocal语句。<br>16、<strong>考虑用生成器来改写直接返回列表的函数</strong><br>17、<strong>在参数上面迭代时，要多加小心</strong><br>18、<strong>用数量可变的位置参数减少视觉杂讯</strong><br>在def语句中使用<em>args,即可令函数接受数量可变的位置参数。调用函数时，可以采用</em>操作符，把序列中的元素当成位置参数, 传给该函数。对生成器使用<em>操作符，可能导致程序耗尽内存并崩溃。在已经接受 </em>args参数的函数上面继续添加位置参数，可能会产生难以排查的bug。<br>19、<strong>用关键字参数来表示可选的行为</strong><br>函数参数可以按位置或关键字来指定。只使用位置参数来调用函数，可能会导致这些参数值的含义不够明确，而关键字参数则能够阐明每个参数的意图。给函数添加新的行为时，可以使用带默认值的关键字参数，以便与原有的函数调用代码保持兼容。可选的关键字参数，总是应该以关键字形式来指定，而不应该以位置参数的形式来指定。<br>20、<strong>用None和文档字符串来描述具有动态默认值的参数</strong><br>参数的默认值，只会在程序加载模块并读到本函数的定义时评估一次，对于{}或[]等动态的值，这可能会导致奇怪的行为。对于以动态值作为实际默认值的关键字参数来说，应该把形式上的默认值写为None，并在函数的文档字符串里描述该默认值所对应的实际行为。<br>21、<strong>用只能以关键字形式指定的参数来确保代码明晰</strong><br>实现方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">function</span><span class="params">(args1,args2,*,args3=default_args,args4=default_args)</span></span></div></pre></td></tr></table></figure></p>
<p>关键字参数能够使函数调用的意图更加明确。对于各参数之间很容易混淆的函数，可以声明只能以关键字形式指定的参数，以确保调用者必须通过关键字来指定它们。对于接受多个Boolean标志的函数，更应该这样做。</p>
<h2 id="类与继承"><a href="#类与继承" class="headerlink" title="类与继承"></a>类与继承</h2><p>22、<strong>尽量用辅助类来维护程序的状态，而不要用字典和元组</strong><br>不要使用包含其他字典的字典，也不要使用过长的元组。如果容器中包含简单而又不可变的数据，那么可以先使用namedtuple来表示，待稍后有需要时，再修改为完整的类。保留内部状态的字典如果变得比较复杂，那就应该吧这些代码拆解为多个辅助类。<br>23、<strong>简单的接口应该接受函数，而不是类的实例</strong><br>对于连接各种Python组件的简单接口来说，通常应该给其直接传入函数，而不是先定义某个类，然后再传入该类的实例。Python中的函数和方法都可以像一级类那样引用，因此，它们与其他类型的对象一样，也能够放在表达式里面。通过名为<strong>call</strong>的特殊方法，可以使得该类的实例能够像普通的Python函数那样得到调用。如果要用函数来保存状态，那就应该定义新的类，并令其实现<strong>call</strong>方法，而不要定义带状态的闭包。<br>24、<strong>以@classmethod形式的多态去通用地构建对象</strong><br>Python程序中，每个类只能有一个构造器，也就是<strong>init</strong>方法。通过@classmethod机制，可以用一种与构造器相仿的方式来构造类的对象。通过类方法多态机制，我们能够以更加通用的方式来构建并拼接具体的子类。<br>25、<strong>用super初始化父类</strong><br>Python使用标准的方法解析顺序来解决超类初始化次序及钻石继承问题。总是应该使用内置的super函数来初始化父类。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/python//" class="article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/12/effective-python-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-Properties in Python" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/11/Properties in Python/">Properties in Python</a>
    </h1>
  

        
        <a href="/2018/03/11/Properties in Python/" class="archive-article-date">
  	<time datetime="2018-03-11T02:22:25.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-11</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Properties-in-Python"><span class="toc-text">Properties in Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#property-初探"><span class="toc-text">property 初探</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#深入理解-property"><span class="toc-text">深入理解 property</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#property会覆盖实例属性"><span class="toc-text">property会覆盖实例属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为property添加文档"><span class="toc-text">为property添加文档</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特性工厂函数"><span class="toc-text">特性工厂函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol></li></ol>
</div>

        <h1 id="Properties-in-Python"><a href="#Properties-in-Python" class="headerlink" title="Properties in Python"></a>Properties in Python</h1><h2 id="property-初探"><a href="#property-初探" class="headerlink" title="property 初探"></a>property 初探</h2><p>Properties 通常用于把公开的属性变成使用读值方法和设值方法管理的属性，且在不影响客户端代码的前提下实施业务规则。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LineItem</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, description, weight, price)</span>:</span></div><div class="line">        self.description = description</div><div class="line">        self.weight = weight</div><div class="line">        self.price = price</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subtotal</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.weight * self.price</div><div class="line">    </div><div class="line">    <span class="comment"># 读值方法</span></div><div class="line"><span class="meta">    @property</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.__weight</div><div class="line">    </div><div class="line">    <span class="comment"># 设值方法</span></div><div class="line"><span class="meta">    @weight.setter</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight</span><span class="params">(self, value)</span>:</span></div><div class="line">        <span class="keyword">if</span> value &gt; <span class="number">0</span>:</div><div class="line">            self.__weight = value</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'value must be  &gt; 0'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">walnuts_valid = LineItem(<span class="string">'walnuts_valid'</span>,<span class="number">10</span>,<span class="number">10</span>)</div><div class="line">walnuts_invalid = LineItem(<span class="string">'walnuts_invalid'</span>, <span class="number">0</span>, <span class="number">10.00</span>)</div></pre></td></tr></table></figure>
<pre><code>10



---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-9-68054ba7debc&gt; in &lt;module&gt;()
      1 walnuts_valid = LineItem(&#39;walnuts_valid&#39;,10,10)
      2 print(walnuts_valid.weight)
----&gt; 3 walnuts_invalid = LineItem(&#39;walnuts_invalid&#39;, 0, 10.00)


&lt;ipython-input-8-2cd43540d5e1&gt; in __init__(self, description, weight, price)
      2     def __init__(self, description, weight, price):
      3         self.description = description
----&gt; 4         self.weight = weight
      5         self.price = price
      6 


&lt;ipython-input-8-2cd43540d5e1&gt; in weight(self, value)
     19             self.__weight = value
     20         else:
---&gt; 21             raise ValueError(&#39;value must be  &gt; 0&#39;)


ValueError: value must be  &gt; 0
</code></pre><p>如上所示，我们使用property禁止了用户为 weight 属性提供负值或零。值得注意的是，如果一个属性只有读值方法而没有设值方法，那么该属性就是只读属性，对其赋值的操作是不被允许的。</p>
<h2 id="深入理解-property"><a href="#深入理解-property" class="headerlink" title="深入理解 property"></a>深入理解 property</h2><p>虽然内置的property经常用于装饰器，但是其实它是一个类。而Python中，函数和类通常可以互换。property构造方法的完整签名如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">property(fget=<span class="keyword">None</span>, fset=<span class="keyword">None</span>, fdel=<span class="keyword">None</span>, doc=<span class="keyword">None</span>)</div></pre></td></tr></table></figure>
<p>其所有参数均是可选的，如果没有把某个函数传递给某个参数，那么得到的特性对象就不允许执行相应操作。<br>下面是一个不使用装饰器定义的经典方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LineItem</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, description, weight, price)</span>:</span></div><div class="line">        self.description = description</div><div class="line">        self.weight = weight</div><div class="line">        self.price = price</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subtotal</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.weight * self.price</div><div class="line">    </div><div class="line">    <span class="comment"># 读值方法</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.__weight</div><div class="line">    </div><div class="line">    <span class="comment"># 设值方法</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_weight</span><span class="params">(self, value)</span>:</span></div><div class="line">        <span class="keyword">if</span> value &gt; <span class="number">0</span>:</div><div class="line">            self.__weight = value</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'value must be  &gt; 0'</span>)</div><div class="line">    weight = property(fget=get_weight, fset = set_weight)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">walnuts_valid = LineItem(<span class="string">'walnuts_valid'</span>,<span class="number">10</span>,<span class="number">10</span>)</div><div class="line">walnuts_invalid = LineItem(<span class="string">'walnuts_invalid'</span>, <span class="number">0</span>, <span class="number">10.00</span>)</div></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-11-2126031d851a&gt; in &lt;module&gt;()
      1 walnuts_valid = LineItem(&#39;walnuts_valid&#39;,10,10)
----&gt; 2 walnuts_invalid = LineItem(&#39;walnuts_invalid&#39;, 0, 10.00)


&lt;ipython-input-10-74ad4ef73232&gt; in __init__(self, description, weight, price)
      2     def __init__(self, description, weight, price):
      3         self.description = description
----&gt; 4         self.weight = weight
      5         self.price = price
      6 


&lt;ipython-input-10-74ad4ef73232&gt; in set_weight(self, value)
     17             self.__weight = value
     18         else:
---&gt; 19             raise ValueError(&#39;value must be  &gt; 0&#39;)
     20     weight = property(fget=get_weight, fset = set_weight)


ValueError: value must be  &gt; 0
</code></pre><h3 id="property会覆盖实例属性"><a href="#property会覆盖实例属性" class="headerlink" title="property会覆盖实例属性"></a>property会覆盖实例属性</h3><p>特性都是类属性，但是特性管理的其实是实例属性的存取。如果实例和所属的类具有同名数据属性，那么实例属性会覆盖类属性。但是实例属性不会遮盖类特性。新添加的类特性会遮盖现有的实例属性。</p>
<h3 id="为property添加文档"><a href="#为property添加文档" class="headerlink" title="为property添加文档"></a>为property添加文档</h3><p>对于经典调用句法，只需要对property函数传入doc参数即可。对于装饰器用法，读值方法的文档字符串作为特性的文档。</p>
<h2 id="特性工厂函数"><a href="#特性工厂函数" class="headerlink" title="特性工厂函数"></a>特性工厂函数</h2><p>LineItem类存在一个问题，如果其有多个属性需要做限制，那么我们将需要写若干个读值和设值方法来达到目的，而这些方法实际上都是类似的，显得有些麻烦。而借助特性工厂函数，我们可以不用手动实现这样若干对几乎一致的读值和设值方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">quantity</span><span class="params">(storage_name)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">qty_getter</span><span class="params">(instance)</span>:</span></div><div class="line">        <span class="keyword">return</span> instance.__dict__[storage_name]</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">qty_setter</span><span class="params">(instance, value)</span>:</span></div><div class="line">        <span class="keyword">if</span> value &gt; <span class="number">0</span>:</div><div class="line">            instance.__dict__[storage_name] = value</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'value must be &gt; 0'</span>)</div><div class="line">    <span class="keyword">return</span> property(qty_getter, qty_setter)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LineItem</span>:</span></div><div class="line">    weight = quantity(<span class="string">'weight'</span>)</div><div class="line">    price = quantity(<span class="string">'price'</span>)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, description, weight, price)</span>:</span></div><div class="line">        self.description = description</div><div class="line">        self.weight = weight</div><div class="line">        self.price = price</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subtotal</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.weight * self.price</div></pre></td></tr></table></figure>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1、Fluent Python by Luciano Ramalho (O’Reilly). Copyright 2015 Luciano Ramalho, 978-1-491-94600-8<br>2、<a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143186781871161bc8d6497004764b398401a401d4cce000" target="_blank" rel="external">廖雪峰Python教程—@property</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/python//" class="article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/11/Properties in Python/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-mobilenet-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/06/mobilenet-notes/">MobileNets论文笔记</a>
    </h1>
  

        
        <a href="/2018/03/06/mobilenet-notes/" class="archive-article-date">
  	<time datetime="2018-03-06T13:08:10.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-06</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MobileNetV1"><span class="toc-text">MobileNetV1</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#实现"><span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MobileNetV2"><span class="toc-text">MobileNetV2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#实现-1"><span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>MobileNets论文笔记，包括MobileNetV1和MobileNetV2。</p>
<h1 id="MobileNetV1"><a href="#MobileNetV1" class="headerlink" title="MobileNetV1"></a>MobileNetV1</h1><p>MobileNet的主要贡献在于损失少量精度的前提下减少计算量和参数数量，使得网络可以在移动设备上高效部署。<br>其重要的一个结构就是Depthwise Separable Convolution，其将普通卷积分解成depthwise卷积和pointwise卷积，以达到减少计算量和参数的目的。<br><img src="https://wwdguu.github.io/2018/03/06/mobilenet-notes/dsc.png" alt="Depthwise Separable Convolution"><br>关于参数减少计算：<br><img src="compute.jpg" alt="参数减少量计算"></p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><strong>网络结构定义</strong><br><img src="mobilenet_v1.JPG" alt="MobilenetV1网络结构"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># MobilenetV1 base </span></div><div class="line">Conv = namedtuple(<span class="string">'Conv'</span>, [<span class="string">'stride'</span>, <span class="string">'depth'</span>])</div><div class="line">DepthSepConv = namedtuple(<span class="string">'DepthSepConv'</span>, [<span class="string">'stride'</span>, <span class="string">'depth'</span>])</div><div class="line">MOBILENT_CONV_DEFS = [</div><div class="line">    Conv(stride=<span class="number">2</span>, depth=<span class="number">32</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">64</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">2</span>, depth=<span class="number">128</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">128</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">2</span>, depth=<span class="number">256</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">256</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">2</span>, depth=<span class="number">512</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">512</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">512</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">512</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">512</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">512</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">2</span>, depth=<span class="number">1024</span>),</div><div class="line">    DepthSepConv(stride=<span class="number">1</span>, depth=<span class="number">1024</span>)</div><div class="line">]</div></pre></td></tr></table></figure></p>
<h1 id="MobileNetV2"><a href="#MobileNetV2" class="headerlink" title="MobileNetV2"></a>MobileNetV2</h1><p>MobileNetV2在MobileNetV1的基础上做了一些改进，其实我更感兴趣的是作者提出SSDLite，将MobileNetV2用于目标检测，其精度和速度都超过了YOLOv2。</p>
<h2 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h2><p><strong>网络结构</strong><br><img src="mobilenet_v2.JPG" alt="MobilenetV2结构"><br><strong>微结构单元</strong><br>注意stride=1时有残差结构，stride=2时无残差结构。<br><img src="inverted_residual.JPG" alt="Inverted Residual"><br><strong>结构定义</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">InvertedResidual = namedtuple(<span class="string">'InvertedResidual'</span>, [<span class="string">'stride'</span>, <span class="string">'depth'</span>, <span class="string">'num'</span>, <span class="string">'t'</span>])</div><div class="line">MOBILENET_V2_CONV_DEFS = [</div><div class="line">    Conv(stride=<span class="number">2</span>, depth=<span class="number">32</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">1</span>, depth=<span class="number">16</span>, num=<span class="number">1</span>, t=<span class="number">1</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">2</span>, depth=<span class="number">24</span>, num=<span class="number">2</span>, t=<span class="number">6</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">2</span>, depth=<span class="number">32</span>, num=<span class="number">3</span>, t=<span class="number">6</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">2</span>, depth=<span class="number">64</span>, num=<span class="number">4</span>, t=<span class="number">6</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">1</span>, depth=<span class="number">96</span>, num=<span class="number">3</span>, t=<span class="number">6</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">2</span>, depth=<span class="number">160</span>, num=<span class="number">3</span>, t=<span class="number">6</span>),</div><div class="line">    InvertedResidual(stride=<span class="number">1</span>, depth=<span class="number">320</span>, num=<span class="number">1</span>, t=<span class="number">6</span>),</div><div class="line">]</div></pre></td></tr></table></figure></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="external">MobileNetV1 paper</a><br><a href="https://arxiv.org/abs/1801.04381" target="_blank" rel="external">MobileNetV2 paper</a><br><a href="http://cuijiahua.com/blog/2018/02/dl_6.html" target="_blank" rel="external">MobileNets详解</a><br><a href="https://github.com/ShuangXieIrene/ssds.pytorch/blob/master/lib/modeling/nets/mobilenet.py" target="_blank" rel="external">Mobilenet pytorch实现</a><br><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py" target="_blank" rel="external">tensorflow mobilenet_v1</a><br><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v2.py" target="_blank" rel="external">tensorflow mobilenet_v2</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">paper</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/paper//" class="article-tag-list-link color1">paper</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/06/mobilenet-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-tensorflow-programming-eager-execution" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/29/tensorflow-programming-eager-execution/">Tensorflow Programming -- Eager Execution</a>
    </h1>
  

        
        <a href="/2018/01/29/tensorflow-programming-eager-execution/" class="archive-article-date">
  	<time datetime="2018-01-28T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-29</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Eager-Execution"><span class="toc-text">Eager Execution</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#计算图的优点"><span class="toc-text">计算图的优点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#优化的"><span class="toc-text">优化的</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#自动缓冲区重用"><span class="toc-text">自动缓冲区重用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#不断折叠"><span class="toc-text">不断折叠</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#操作间并行性"><span class="toc-text">操作间并行性</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#计算和内存之间的自动权衡"><span class="toc-text">计算和内存之间的自动权衡</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#可部署"><span class="toc-text">可部署</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#图就是模型的中间表示"><span class="toc-text">图就是模型的中间表示</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#可重写"><span class="toc-text">可重写</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#尝试自动设备放置或-量化"><span class="toc-text">尝试自动设备放置或 量化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算图的缺点"><span class="toc-text">计算图的缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#难以调试"><span class="toc-text">难以调试</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#计算图构建之后会报告错误"><span class="toc-text">计算图构建之后会报告错误</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#执行不能用pdb或者打印语句来调试"><span class="toc-text">执行不能用pdb或者打印语句来调试</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Un-Pythonic"><span class="toc-text">Un-Pythonic</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#编写一个Tensorflow程序是元编程的练习"><span class="toc-text">编写一个Tensorflow程序是元编程的练习</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#控制流-如-tf-while-loop-与Python不同"><span class="toc-text">控制流(如  tf.while_loop)与Python不同</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#不能轻松地将计算图构建与自定义数据结构混合"><span class="toc-text">不能轻松地将计算图构建与自定义数据结构混合</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Eager-Execution-1"><span class="toc-text">Eager Execution</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Eager-Execution的优点"><span class="toc-text">Eager Execution的优点</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#与Python调试工具兼容"><span class="toc-text">与Python调试工具兼容</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#提供即时的错误报告"><span class="toc-text">提供即时的错误报告</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#允许使用Python数据结构"><span class="toc-text">允许使用Python数据结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#启用Pythonic控制流程"><span class="toc-text">启用Pythonic控制流程</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Eager-Execution可以简化代码"><span class="toc-text">Eager Execution可以简化代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Tensors和NumPy数组的行为相似"><span class="toc-text">Tensors和NumPy数组的行为相似</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#梯度"><span class="toc-text">梯度</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linear-Regression-in-Eager"><span class="toc-text">Linear Regression in Eager</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Collection-of-Operations"><span class="toc-text">A Collection of Operations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#什么情况下使用eager-execution"><span class="toc-text">什么情况下使用eager execution?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#作为研究人员希望一个灵活的框架"><span class="toc-text">作为研究人员希望一个灵活的框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#需要开发一个新的模型"><span class="toc-text">需要开发一个新的模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#刚接触TensorFlow"><span class="toc-text">刚接触TensorFlow</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=406730941&auto=1&height=66"></iframe></p>
<h2 id="Eager-Execution"><a href="#Eager-Execution" class="headerlink" title="Eager Execution"></a>Eager Execution</h2><p>目前使用TensorFlow时，需要编写一个Python程序，首先构建一个表示计算的图，然后调用Session.run()将这个计算图交给C++运行库执行，从这个意义上说，Tensorflow提供了一个声明式编程模型，其计算图的构建和实际的执行是分离的。</p>
<h3 id="计算图的优点"><a href="#计算图的优点" class="headerlink" title="计算图的优点"></a>计算图的优点</h3><p>TensorFlow从某种意义上说是一种编程语言和一种用于机器学习模型的编译器，其将机器学习模型作为输入，编码成一个名为Graph的低级表示，然后将其重写为优化的可执行形式，沿途使用类似编译器的优化。这种模式有许多好处：<br>1、优化可以减少训练模型或运行推理的挂钟时间和内存占用时间<br>2、计算图作为平台不可知的中间表示，简化了部署。<br>3、重写图形的能力使得我们可以尝试像自动设备放置和重量量化这样的策略。 </p>
<h4 id="优化的"><a href="#优化的" class="headerlink" title="优化的"></a>优化的</h4><h5 id="自动缓冲区重用"><a href="#自动缓冲区重用" class="headerlink" title="自动缓冲区重用"></a>自动缓冲区重用</h5><h5 id="不断折叠"><a href="#不断折叠" class="headerlink" title="不断折叠"></a>不断折叠</h5><h5 id="操作间并行性"><a href="#操作间并行性" class="headerlink" title="操作间并行性"></a>操作间并行性</h5><h5 id="计算和内存之间的自动权衡"><a href="#计算和内存之间的自动权衡" class="headerlink" title="计算和内存之间的自动权衡"></a>计算和内存之间的自动权衡</h5><h4 id="可部署"><a href="#可部署" class="headerlink" title="可部署"></a>可部署</h4><h5 id="图就是模型的中间表示"><a href="#图就是模型的中间表示" class="headerlink" title="图就是模型的中间表示"></a>图就是模型的中间表示</h5><h4 id="可重写"><a href="#可重写" class="headerlink" title="可重写"></a>可重写</h4><h5 id="尝试自动设备放置或-量化"><a href="#尝试自动设备放置或-量化" class="headerlink" title="尝试自动设备放置或 量化"></a>尝试自动设备放置或 量化</h5><h3 id="计算图的缺点"><a href="#计算图的缺点" class="headerlink" title="计算图的缺点"></a>计算图的缺点</h3><p>尽管计算图的表示方法有很多优点，但是其缺点也不小。声明式范例导致难以调试的程序，因为在构建计算图之后会报告错误。而且由于计算图执行是由Session管理的，所以不能够使用pdb甚至是打印语句来调试模型。构建图形就像使用汇编语言进行编码-原则上我们可以使用计算图来实现我们所需要的任何机器学习模型，但是这样做可能比较困难。编写一个TensorFlow程序是元编程的一个练习: 使用Python用TensorFlow图形语言编写程序。因此，我们不能使用本地Python控制流结构，而必须依赖它们在TensorFlow中的等价物。而且，不能轻易地将图形构造与自定义数据混合在一起，我们可能想要使用Python类来表示结构化数据，但是无法传递类，无法沿着图的边缘流动。总结下来就是如下缺点：</p>
<h4 id="难以调试"><a href="#难以调试" class="headerlink" title="难以调试"></a>难以调试</h4><h5 id="计算图构建之后会报告错误"><a href="#计算图构建之后会报告错误" class="headerlink" title="计算图构建之后会报告错误"></a>计算图构建之后会报告错误</h5><h5 id="执行不能用pdb或者打印语句来调试"><a href="#执行不能用pdb或者打印语句来调试" class="headerlink" title="执行不能用pdb或者打印语句来调试"></a>执行不能用pdb或者打印语句来调试</h5><h4 id="Un-Pythonic"><a href="#Un-Pythonic" class="headerlink" title="Un-Pythonic"></a>Un-Pythonic</h4><h5 id="编写一个Tensorflow程序是元编程的练习"><a href="#编写一个Tensorflow程序是元编程的练习" class="headerlink" title="编写一个Tensorflow程序是元编程的练习"></a>编写一个Tensorflow程序是元编程的练习</h5><h5 id="控制流-如-tf-while-loop-与Python不同"><a href="#控制流-如-tf-while-loop-与Python不同" class="headerlink" title="控制流(如  tf.while_loop)与Python不同"></a>控制流(如  tf.while_loop)与Python不同</h5><h5 id="不能轻松地将计算图构建与自定义数据结构混合"><a href="#不能轻松地将计算图构建与自定义数据结构混合" class="headerlink" title="不能轻松地将计算图构建与自定义数据结构混合"></a>不能轻松地将计算图构建与自定义数据结构混合</h5><h3 id="Eager-Execution-1"><a href="#Eager-Execution-1" class="headerlink" title="Eager Execution"></a>Eager Execution</h3><p>我们可以直接从Python执行TensorFlow操作吗？实际上，我们不能将任何给定的计算图打破到它的组件操作并直接从Python中调用它们。<br>Eager Execution是用于计算的类Numpy库，支持GPU加速和自动分化，以及灵活的机器学习研究和实验平台。<br>使用Eager的例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$python</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># version &gt;= 1.50</span></div><div class="line"><span class="keyword">import</span> tensorflow.contrib.eager <span class="keyword">as</span> tfe</div><div class="line">tfe.enable_eager_execution()</div></pre></td></tr></table></figure></p>
<h4 id="Eager-Execution的优点"><a href="#Eager-Execution的优点" class="headerlink" title="Eager Execution的优点"></a>Eager Execution的优点</h4><h5 id="与Python调试工具兼容"><a href="#与Python调试工具兼容" class="headerlink" title="与Python调试工具兼容"></a>与Python调试工具兼容</h5><h5 id="提供即时的错误报告"><a href="#提供即时的错误报告" class="headerlink" title="提供即时的错误报告"></a>提供即时的错误报告</h5><h5 id="允许使用Python数据结构"><a href="#允许使用Python数据结构" class="headerlink" title="允许使用Python数据结构"></a>允许使用Python数据结构</h5><p>例如用于结构化输入。</p>
<h5 id="启用Pythonic控制流程"><a href="#启用Pythonic控制流程" class="headerlink" title="启用Pythonic控制流程"></a>启用Pythonic控制流程</h5><h4 id="Eager-Execution可以简化代码"><a href="#Eager-Execution可以简化代码" class="headerlink" title="Eager Execution可以简化代码"></a>Eager Execution可以简化代码</h4><p>我们不再需要担心以下这些问题:<br>1、placeholders<br>下面是一个程序，它将一个矩阵与自身相乘。我们首先用一个占位符定义一个计算图，并将矩阵提供给平方。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, shape=[<span class="number">1</span>,<span class="number">1</span>])</div><div class="line">m = tf.matmul(x, x)</div><div class="line"></div><div class="line">print(m)</div><div class="line"><span class="comment"># Tensor("MatMul:0",shape=(1, 1),dtype=float32)</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    m_out = sess.run(m, feed_dict=&#123;x:[[<span class="number">2.0</span>]]&#125;)</div><div class="line">print(m_out)</div><div class="line"><span class="comment"># [[4.0]]</span></div></pre></td></tr></table></figure></p>
<p>而如果使用了Eager Execution，下面三行代码提供了相同的效果。没有Session，没有placeholder和matmul操作，立即得出运算结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x = [[<span class="number">2.</span>]] <span class="comment"># No need for placeholders!</span></div><div class="line">m = tf.matmul(x,x)</div><div class="line">print(m) <span class="comment"># No sessions!</span></div><div class="line"><span class="comment"># tf.Tensor([[4.]], shape=(1,1), dtype=float32)</span></div></pre></td></tr></table></figure></p>
<p>2、sessions<br>3、control dependencies<br>4、”lazy loading”<br>Eager Execution还有利于避免元编程的一些缺点。例如，以下的代码就是在程序中间快速破解分析Tensor X的代码。循环的每一次迭代都是将操作添加到计算图的内存中表示。在这种情况下，每次调用session.run()都会执行random_uniform操作，所以这里的代码片段并没有打印Tensor的一致快照。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">x = tf.random_uniform([<span class="number">2</span>, <span class="number">2</span>])</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">0</span>]):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(x.shape[<span class="number">1</span>]):</div><div class="line">            print(sess.run(x[i,j]))</div></pre></td></tr></table></figure></p>
<p>而当在Eager Execution的情况下，没有一个计算图的概念或者一个操作的重复执行，所以最明显的做法是很好的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x = tf.random_uniform([<span class="number">2</span>,<span class="number">2</span>])</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">0</span>]):</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(x.shape[<span class="number">1</span>]):</div><div class="line">        print(x[i,j])</div></pre></td></tr></table></figure></p>
<p>5、{name, variable, op} scopes</p>
<h4 id="Tensors和NumPy数组的行为相似"><a href="#Tensors和NumPy数组的行为相似" class="headerlink" title="Tensors和NumPy数组的行为相似"></a>Tensors和NumPy数组的行为相似</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">x = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])</div><div class="line"><span class="comment"># Tensors are backed by Numpy arrays</span></div><div class="line"><span class="keyword">assert</span> type(x.numpy()) == np.ndarray</div><div class="line">squared = np.square(x) <span class="comment"># Tensors are compatible with Numpy functions</span></div><div class="line"><span class="comment"># Tensors are iterable </span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</div><div class="line">    print(i)</div></pre></td></tr></table></figure>
<h4 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h4><p>自动梯度求解已经加入到eager execution中。当启用eager execution时，执行的操作将在一个”tape”中进行追踪，以回放计算梯度。如果熟悉autograd包的话，这个API非常相似。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> x**<span class="number">2</span></div><div class="line"></div><div class="line">grad = tfe.gradients_function(square)</div><div class="line"></div><div class="line">print(square(<span class="number">3.</span>)) <span class="comment"># tf.Tensor(9., shape=(), dtype=float32)</span></div><div class="line">print(grad(<span class="number">3.</span>)) <span class="comment"># tf.Tensor(6., shape=(), dtype=float32)</span></div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">x = tfe.Variable(<span class="number">2.0</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(y)</span>:</span></div><div class="line">    <span class="keyword">return</span> (y - x ** <span class="number">2</span>) ** <span class="number">2</span></div><div class="line">grad = tfe.implicit_gradients(loss)</div><div class="line"></div><div class="line">print(loss(<span class="number">7.</span>)) <span class="comment"># tf.Tensor(9., shape=(), dtype=float32)</span></div><div class="line">print(grad(<span class="number">7.</span>)) <span class="comment"># [(&lt;tf.Tensor: -24.0, shape=(), dtype=float32&gt;, </span></div><div class="line">                <span class="comment">#    &lt;tf.Variable 'Variable:0' shape=()                </span></div><div class="line">                <span class="comment">#     dtype=float32, numpy=2.0&gt;)]</span></div></pre></td></tr></table></figure>
<p>即便eager execution没被允许，计算梯度的API依然有效。<br>tfe.gradients_function()<br>tfe.value_and_gradients_function()<br>tfe.implicit_gradients()<br>tfe.implicit_value_and_gradients()<br>详情可参考：<br><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md" target="_blank" rel="external">eager execution document</a></p>
<h2 id="Linear-Regression-in-Eager"><a href="#Linear-Regression-in-Eager" class="headerlink" title="Linear Regression in Eager"></a>Linear Regression in Eager</h2><h3 id="A-Collection-of-Operations"><a href="#A-Collection-of-Operations" class="headerlink" title="A Collection of Operations"></a>A Collection of Operations</h3><p>TensorFlow = Operation Kernels + Execution<br>Graph construction: 使用Session来执行操作的组合<br>Eager execution: 用Python执行操作的组合。<br>观察TensorFlow的一种方式是作为一系列操作：数学，线性代数，图像处理，Tensorboard可视化的总结生成等以及执行构成它们的计算的手段。Session提供了一种方法来执行这些操作，在执行的时候，Python是执行组合的方法，但是底层的操作保持不变，结果，API表面的大部分也保持不变。<br>不管eager execution是否被允许，大多数TensorFlow API都可以工作，但是当eager exectution允许时，有一些特殊情况需要注意：<br>1、在eager execution模式下最好使用tfe.Variable<br>2、管理好自己的变量存储，变量集合是不被允许的。<br>3、使用 tf.contrib.summary<br>4、使用tfe.Iterator 进行数据迭代<br>5、最好使用面向对象的层(比如 tf.layers.Dense)<br>6、使用tfe.py_func 代替 tf.py_func</p>
<h3 id="什么情况下使用eager-execution"><a href="#什么情况下使用eager-execution" class="headerlink" title="什么情况下使用eager execution?"></a>什么情况下使用eager execution?</h3><h4 id="作为研究人员希望一个灵活的框架"><a href="#作为研究人员希望一个灵活的框架" class="headerlink" title="作为研究人员希望一个灵活的框架"></a>作为研究人员希望一个灵活的框架</h4><p>python控制流和数据结构使得实验成为可能</p>
<h4 id="需要开发一个新的模型"><a href="#需要开发一个新的模型" class="headerlink" title="需要开发一个新的模型"></a>需要开发一个新的模型</h4><p>即时的错误报告简化了调试</p>
<h4 id="刚接触TensorFlow"><a href="#刚接触TensorFlow" class="headerlink" title="刚接触TensorFlow"></a>刚接触TensorFlow</h4><p>eager execution使得我们方便在Python REPL中学习TF API。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/04%20Eager%20Execution%20%2B%20word2vec.pdf" target="_blank" rel="external">04_eager_execution slides</a><br><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/04_Lecture%20note_%20Eager%20execution%20and%20interface.pdf" target="_blank" rel="external">04_eager_execution notes</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/tensorflow//" class="article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/29/tensorflow-programming-eager-execution/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-effective-java-classes-and-interfaces" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/23/effective-java-classes-and-interfaces/">Effective Java -- Classes and Interfaces</a>
    </h1>
  

        
        <a href="/2018/01/23/effective-java-classes-and-interfaces/" class="archive-article-date">
  	<time datetime="2018-01-23T06:36:44.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Java-Items-about-Classes-and-Interfaces"><span class="toc-text">Effective Java Items about Classes and Interfaces</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-15-Minimize-the-accessibility-of-classes-and-members"><span class="toc-text">Item 15: Minimize the accessibility of classes and members</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-16-In-public-classes-use-accessor-methods-not-public-fields"><span class="toc-text">Item 16: In public classes, use accessor methods, not public fields</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-17-Minimize-mutability"><span class="toc-text">Item 17: Minimize mutability</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-18-Favor-composition-over-inheritance"><span class="toc-text">Item 18: Favor composition over inheritance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-19-Design-and-document-for-inheritance-or-else-prohibit-it"><span class="toc-text">Item 19: Design and document for inheritance or else prohibit it</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-20-Prefer-interfaces-to-abstract-classes"><span class="toc-text">Item 20: Prefer interfaces to abstract classes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-21-Design-interfaces-for-posterity"><span class="toc-text">Item 21: Design interfaces for posterity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-22-Use-interfaces-only-to-define-types"><span class="toc-text">Item 22: Use interfaces only to define types</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-23-Prefer-class-hierarchies-to-tagged-classes"><span class="toc-text">Item 23: Prefer class hierarchies to tagged classes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-24-Favor-static-member-classes-over-nonstatic"><span class="toc-text">Item 24: Favor static member classes over nonstatic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-25-Limit-source-files-to-a-single-top-level-class"><span class="toc-text">Item 25: Limit source files to a single top-level class</span></a></li></ol></li></ol>
</div>

        <h2 id="Effective-Java-Items-about-Classes-and-Interfaces"><a href="#Effective-Java-Items-about-Classes-and-Interfaces" class="headerlink" title="Effective Java Items about Classes and Interfaces"></a>Effective Java Items about Classes and Interfaces</h2><p>类和接口是Java的核心，其也是Java的基本抽象单元。Java提供了许多强大的基本元素，供程序员用来设计类和接口。以下一些指导原则可以帮助我们更好地利用这些元素设计出更加有用、健壮和灵活的类和接口。</p>
<h3 id="Item-15-Minimize-the-accessibility-of-classes-and-members"><a href="#Item-15-Minimize-the-accessibility-of-classes-and-members" class="headerlink" title="Item 15: Minimize the accessibility of classes and members"></a>Item 15: Minimize the accessibility of classes and members</h3><p>使类和成员的可访问性最小化。我们始终应该尽可能地降低可访问性。你在仔细地设计了一个最小的公有API之后，应该防止把任何散乱的类、接口和成员变成API的一部分。除了公有静态final域的特殊情形之外，公有类都不应该包含公有域。并且要确保公有静态final所引用的对象都是不可变得。</p>
<h3 id="Item-16-In-public-classes-use-accessor-methods-not-public-fields"><a href="#Item-16-In-public-classes-use-accessor-methods-not-public-fields" class="headerlink" title="Item 16: In public classes, use accessor methods, not public fields"></a>Item 16: In public classes, use accessor methods, not public fields</h3><p>在公有类中使用访问方法而非公有域。公有类永远都不应该暴露可变的域，虽然还是有问题，但是让公有类暴露不可变的域其危害比较小。但是，有时候会需要用包级私有的或者私有的嵌套来暴露域，无论这个类是可变的还是不可变的。</p>
<h3 id="Item-17-Minimize-mutability"><a href="#Item-17-Minimize-mutability" class="headerlink" title="Item 17: Minimize mutability"></a>Item 17: Minimize mutability</h3><p>使可变性最小化。不可变的类比可变类更加易于设计、实现和使用。它们不容易出错，且更加安全。为了使类成为不可变，要遵循以下五条规则:<br>1、不要提供任何会修改对象状态的方法。<br>2、保证类不会被扩展。一般做法是使这个类成为final的。<br>3、使所有的域都是final的。<br>4、使所有的域都成为私有的。<br>5、确保对于任何可变组件的互斥访问。</p>
<p>不可变对象本质上是线程安全的，它们不要求同步。不可变类可以被自由地共享。永远也不需要对不可变类进行保护性拷贝。不仅可以共享不可变对象，甚至也可以共享它们的内部信息。不可变对象为其他对象提供了大量的构件，无论是可变的还是不可变的。不可变类真正唯一的缺点是，对于每个不同的值都需要一个单独的对象。<br>为了确保不可变类不被子类化。除了使得类成为final的方法之外，还可以让类的所有构造器都变成私有的或者包级私有的，并添加公有的静态工厂来代替公有的构造器。</p>
<h3 id="Item-18-Favor-composition-over-inheritance"><a href="#Item-18-Favor-composition-over-inheritance" class="headerlink" title="Item 18: Favor composition over inheritance"></a>Item 18: Favor composition over inheritance</h3><p>复合优先于继承。继承的功能非常强大，但是也存在诸多问题，因为它违背了封装原则。只有当子类和超类之间确实存在子类型关系时，使用继承才是恰当的。即便如此，如果子类和超类处在不同的包中，并且超类并不是为了继承而设计的，那么继承将会导致脆弱性。为了避免这种脆弱性，可以用复合和转发机制来代替继承，尤其是当存在适当的接口可以实现包装类的时候。包装类不仅比子类更加健壮，而且功能也更加强大。    </p>
<h3 id="Item-19-Design-and-document-for-inheritance-or-else-prohibit-it"><a href="#Item-19-Design-and-document-for-inheritance-or-else-prohibit-it" class="headerlink" title="Item 19: Design and document for inheritance or else prohibit it"></a>Item 19: Design and document for inheritance or else prohibit it</h3><p>要么为继承而设计，并提供说明文档，要么就禁止继承。</p>
<h3 id="Item-20-Prefer-interfaces-to-abstract-classes"><a href="#Item-20-Prefer-interfaces-to-abstract-classes" class="headerlink" title="Item 20: Prefer interfaces to abstract classes"></a>Item 20: Prefer interfaces to abstract classes</h3><h3 id="Item-21-Design-interfaces-for-posterity"><a href="#Item-21-Design-interfaces-for-posterity" class="headerlink" title="Item 21: Design interfaces for posterity"></a>Item 21: Design interfaces for posterity</h3><h3 id="Item-22-Use-interfaces-only-to-define-types"><a href="#Item-22-Use-interfaces-only-to-define-types" class="headerlink" title="Item 22: Use interfaces only to define types"></a>Item 22: Use interfaces only to define types</h3><h3 id="Item-23-Prefer-class-hierarchies-to-tagged-classes"><a href="#Item-23-Prefer-class-hierarchies-to-tagged-classes" class="headerlink" title="Item 23: Prefer class hierarchies to tagged classes"></a>Item 23: Prefer class hierarchies to tagged classes</h3><h3 id="Item-24-Favor-static-member-classes-over-nonstatic"><a href="#Item-24-Favor-static-member-classes-over-nonstatic" class="headerlink" title="Item 24: Favor static member classes over nonstatic"></a>Item 24: Favor static member classes over nonstatic</h3><h3 id="Item-25-Limit-source-files-to-a-single-top-level-class"><a href="#Item-25-Limit-source-files-to-a-single-top-level-class" class="headerlink" title="Item 25: Limit source files to a single top-level class"></a>Item 25: Limit source files to a single top-level class</h3>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/23/effective-java-classes-and-interfaces/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-thinkingng-in-javavava-notes-interfaces-and-inner-classes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/23/thinkingng-in-javavava-notes-interfaces-and-inner-classes/">Thinking in Java Notes -- Interfaces and Inner Classes</a>
    </h1>
  

        
        <a href="/2018/01/23/thinkingng-in-javavava-notes-interfaces-and-inner-classes/" class="archive-article-date">
  	<time datetime="2018-01-22T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Interfaces"><span class="toc-text">Interfaces</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#抽象类和抽象方法"><span class="toc-text">抽象类和抽象方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#接口"><span class="toc-text">接口</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#完全解耦"><span class="toc-text">完全解耦</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用接口实现多重继承"><span class="toc-text">用接口实现多重继承</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#通过继承来扩展接口"><span class="toc-text">通过继承来扩展接口</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#适配接口"><span class="toc-text">适配接口</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#接口中的域"><span class="toc-text">接口中的域</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#嵌套接口"><span class="toc-text">嵌套接口</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#接口与工厂"><span class="toc-text">接口与工厂</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Inner-Classess"><span class="toc-text">Inner Classess</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#创建内部类"><span class="toc-text">创建内部类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#链接到外部类"><span class="toc-text">链接到外部类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用-this与-new"><span class="toc-text">使用.this与.new</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#内部类与向上转型"><span class="toc-text">内部类与向上转型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#在方法和作用域内的内部类"><span class="toc-text">在方法和作用域内的内部类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#匿名内部类"><span class="toc-text">匿名内部类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#嵌套类"><span class="toc-text">嵌套类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么需要内部类"><span class="toc-text">为什么需要内部类?</span></a></li></ol></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=407002091&auto=1&height=66"></iframe></p>
<h1 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h1><h2 id="抽象类和抽象方法"><a href="#抽象类和抽象方法" class="headerlink" title="抽象类和抽象方法"></a>抽象类和抽象方法</h2><p>包含抽象方法的类叫做抽象类，如果一个类包含一个或多个抽象方法，该类必须被限定为抽象的。如果从一个抽象类继承，并想创建该新类的对象，那么就必须为基类中的所有抽象方法提供方法定义。</p>
<h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>interface关键字使得抽象的概念更向前迈进一步。interface关键字产生一个完全抽象的类，其根本没有提供任何具体实现。接口可以包含域，但是这些域隐式地是static和final的。接口中定义的方法必须是public的，否则，其就只能得到默认的包访问权限。</p>
<h2 id="完全解耦"><a href="#完全解耦" class="headerlink" title="完全解耦"></a>完全解耦</h2><p>将接口从具体实现中解耦使得接口可以应用于多种不同的具体实现，因此代码也就更具有可复用性。？ </p>
<h2 id="用接口实现多重继承"><a href="#用接口实现多重继承" class="headerlink" title="用接口实现多重继承"></a>用接口实现多重继承</h2><p>使用接口的核心原因是：为了能够向上转型为多个基类型以及由此带来的灵活性。第二个原因与使用抽象基类相同：防止客户端程序员创建该类的对象，并确保这仅仅是建立一个接口。如何在接口和抽象类之间进行选择？如果要创建不带任何方法定义和成员变量的基类，那么就应该选择接口而不是抽象类。如果知道某事物应该成为一个基类，那么第一选择是使它成为一个接口。</p>
<h2 id="通过继承来扩展接口"><a href="#通过继承来扩展接口" class="headerlink" title="通过继承来扩展接口"></a>通过继承来扩展接口</h2><p>通过继承可以容易地在接口中添加新的方法声明，还可以通过继承在新接口中组合数个接口。注意在打算组合的不同接口中使用相同的方法名通常会造成代码可读性的混乱，需要尽量避免这种情况。</p>
<h2 id="适配接口"><a href="#适配接口" class="headerlink" title="适配接口"></a>适配接口</h2><p>接口最吸引人的原因之一是允许同一个接口有多个不同的具体实现。简单的情况中，它的体现形式通常是一个接受接口类型的方法，而该接口的实现和向该方法传递的对象则取决于方法的使用者。</p>
<h2 id="接口中的域"><a href="#接口中的域" class="headerlink" title="接口中的域"></a>接口中的域</h2><p>接口中的任何域都自动是static和final的。</p>
<h2 id="嵌套接口"><a href="#嵌套接口" class="headerlink" title="嵌套接口"></a>嵌套接口</h2><h2 id="接口与工厂"><a href="#接口与工厂" class="headerlink" title="接口与工厂"></a>接口与工厂</h2><p>接口是实现多重继承的途径，而生成遵循某个接口的对象的典型方式就是工厂方法设计模式。</p>
<h1 id="Inner-Classess"><a href="#Inner-Classess" class="headerlink" title="Inner Classess"></a>Inner Classess</h1><p>将一个类的定义放在另一个类的定义内部，这就是内部类。</p>
<h2 id="创建内部类"><a href="#创建内部类" class="headerlink" title="创建内部类"></a>创建内部类</h2><p>如果想从外部类的非静态方法之外的任意位置创建某个内部类的对象，那么必须像在main()方法中 那样，具体地指明这个对象的类型: OuterClassName.InnerClassName。</p>
<h2 id="链接到外部类"><a href="#链接到外部类" class="headerlink" title="链接到外部类"></a>链接到外部类</h2><p>当生成一个内部类的对象时，此对象与制造它的外围对象之间就有了一种联系，所以它能访问其外围对象的所有成员，而不需要任何特殊条件。此外，内部类 还拥有其外围类的所有元素的访问权。</p>
<h2 id="使用-this与-new"><a href="#使用-this与-new" class="headerlink" title="使用.this与.new"></a>使用.this与.new</h2><h2 id="内部类与向上转型"><a href="#内部类与向上转型" class="headerlink" title="内部类与向上转型"></a>内部类与向上转型</h2><h2 id="在方法和作用域内的内部类"><a href="#在方法和作用域内的内部类" class="headerlink" title="在方法和作用域内的内部类"></a>在方法和作用域内的内部类</h2><h2 id="匿名内部类"><a href="#匿名内部类" class="headerlink" title="匿名内部类"></a>匿名内部类</h2><h2 id="嵌套类"><a href="#嵌套类" class="headerlink" title="嵌套类"></a>嵌套类</h2><h2 id="为什么需要内部类"><a href="#为什么需要内部类" class="headerlink" title="为什么需要内部类?"></a>为什么需要内部类?</h2><p>…?<br>不太看得懂，剩下的以后再补充</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/23/thinkingng-in-javavava-notes-interfaces-and-inner-classes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-thinking-in-java-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/22/thinking-in-java-notes/">Thinking in Java Notes -- Basic</a>
    </h1>
  

        
        <a href="/2018/01/22/thinking-in-java-notes/" class="archive-article-date">
  	<time datetime="2018-01-22T12:48:26.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#第1章-对象导论"><span class="toc-text">第1章 对象导论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第2章-一切都是对象"><span class="toc-text">第2章 一切都是对象</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第3章-操作符"><span class="toc-text">第3章 操作符</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第4章-控制执行流程"><span class="toc-text">第4章 控制执行流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第5章-初始化与清理"><span class="toc-text">第5章 初始化与清理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第6章-访问权限控制"><span class="toc-text">第6章 访问权限控制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第7章-复用类"><span class="toc-text">第7章 复用类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第8章-多态"><span class="toc-text">第8章 多态</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=29023561&auto=1&height=66"></iframe></p>
<h2 id="第1章-对象导论"><a href="#第1章-对象导论" class="headerlink" title="第1章 对象导论"></a>第1章 对象导论</h2><h2 id="第2章-一切都是对象"><a href="#第2章-一切都是对象" class="headerlink" title="第2章 一切都是对象"></a>第2章 一切都是对象</h2><p>1、理解static关键词。当声明一个事物是static时，就意味着这个域或方法不会与包含它的那个类的任何对象实例关联在一起。</p>
<h2 id="第3章-操作符"><a href="#第3章-操作符" class="headerlink" title="第3章 操作符"></a>第3章 操作符</h2><p>1、注意 == 操作符和equals()方法的区别。<br>2、移位操作符&lt;&lt;和&gt;&gt;，对于&lt;&lt;左移操作符，低位补0即可，对于&gt;&gt;右移操作符，采用“符号扩展”，符号为正，在高位插入0，符号为负则在高位插入1。Java中增加了一种有别于其它语言的“无符号”右移操作符&gt;&gt;&gt;，无论正负都在高位插入0。</p>
<h2 id="第4章-控制执行流程"><a href="#第4章-控制执行流程" class="headerlink" title="第4章 控制执行流程"></a>第4章 控制执行流程</h2><h2 id="第5章-初始化与清理"><a href="#第5章-初始化与清理" class="headerlink" title="第5章 初始化与清理"></a>第5章 初始化与清理</h2><p>1、只能根据参数列表区分重载方法，而不能根据返回值的类型区分重载方法。<br>2、JVM垃圾回收机制。需要之后深入理解。<br>3、成员初始化。Java尽力保证，所有变量在使用前都能得到恰当的初始化。对于方法的局部变量，Java以编译时错误的形式来贯彻这种保证。如果类的数据成员是基本类型，那么可以不用初始化，其保证会有一个默认的初始值。在类里定义一个对象引用时，如果不将其初始化，此引用就会获得一个特殊值null。注意初始化时出现的“向前引用”的错误。<br>4、初始化顺序：类的内部，变量定义的先后顺序决定了初始化的顺序。<br>5、静态数据的初始化：无论创建多少个对象，静态数据都只占用一份存储区域。static关键字不能应用于局部变量，因此它只能作用于域。初始化的顺序是先静态对象（如果它们还没有因为前面的对象创建过程而被初始化），而后是“非静态对象”。<br>6、对象的创建过程大概如下：<br>假设有个名为Dog的类。<br>a、即便没有显式地使用static关键字，构造器实际上也是静态方法，因此，当首次创建类型为Dog的对象时(构造器可以看做static方法)，或者Dog类的静态方法/静态域首次被访问时，Java解释器必须查找类路径，以定位Dog.class文件。<br>b、然后载入Dog.class，有关静态初始化的所有动作都会执行。因此，静态初始化只在Class对象首次加载的时候进行一次。<br>c、当用new Dog() 创建对象的时候，首先将在堆上为Dog对象分配足够的存储空间。<br>d、这块存储空间会被清零，这就自动地将Dog对象中的所有基本类型数据都设置成了默认值，而引用则被设置成了null。<br>e、执行所有出现于字段定义处的初始化动作。<br>f、执行构造器。</p>
<h2 id="第6章-访问权限控制"><a href="#第6章-访问权限控制" class="headerlink" title="第6章 访问权限控制"></a>第6章 访问权限控制</h2><p>1、关键字<br>   private<br>   protected：继承访问权限。<br>   public：接口访问权限。<br>   默认访问权限：包访问权限。</p>
<h2 id="第7章-复用类"><a href="#第7章-复用类" class="headerlink" title="第7章 复用类"></a>第7章 复用类</h2><p>1、可以通过组合语法，继承语法，代理，结合使用组合和继承等方法实现类的复用。<br>2、@Override 的使用，当想要覆写某个方法时，可以选择添加这个注解，在不小心重载并非覆写了该方法时，编译器会生成错误信息。<br>3、在组合和继承之间做合适选择。一般来说，is-a关系用继承表达，has-a关系用组合表达。究竟改用组合还是用继承，一个比较清晰的判断方法就是看是否需要从新类向基类进行向上转型，如果必须向上转型，那么继承是必要的；如果不需要，则应该慎重考虑是否需要继承。<br>4、final关键字：包括final参数，final方法， final类的意义。</p>
<h2 id="第8章-多态"><a href="#第8章-多态" class="headerlink" title="第8章 多态"></a>第8章 多态</h2><p>1、面向对象的语言的特征：数据抽象，继承和多态。<br>2、前期绑定和后期绑定：Java中除了static方法和final方法(private方法属于final方法)之外，其他所有的方法都是后期绑定。实际上将方法声明为final的一个重要原因之一是防止他人覆盖该方法，另一个更为重要的原因则是有效关闭动态绑定。<br>3、缺陷：试图覆盖私有方法。实际上试图在继承类中覆盖基类的私有方法是不对的，如果使用了@Override注解，那么编译会报错，而如果没有使用该注解，那么实际上我们试图要覆盖的那个方法是全新的方法，甚至因为private的权限，这也不是重载。事实上只有非private方法才能被覆盖。<br>4、复杂对象调用构造器按照下面的顺序：a、在其他任何事物发生之前，将分配给对象的存储空间初始化成二进制的零；b、调用基类构造器；c、按声明顺序调用成员的初始化方法；d、调用导出类构造器的主体。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/22/thinking-in-java-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-paper-and-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/21/paper-and-notes/">资料和文章备份</a>
    </h1>
  

        
        <a href="/2018/01/21/paper-and-notes/" class="archive-article-date">
  	<time datetime="2018-01-21T05:14:54.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#cs20si-2017-notes-and-slides"><span class="toc-text">cs20si 2017 notes and slides</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、Overview-Of-Tensorflow"><span class="toc-text">1、Overview Of Tensorflow</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、Operations"><span class="toc-text">2、Operations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、Linear-and-Logistic-Regression"><span class="toc-text">3、Linear and Logistic Regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4、Structure-Your-Tensorflow-Model"><span class="toc-text">4、Structure Your Tensorflow Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5、Manage-Experiments-and-Process-Data"><span class="toc-text">5、Manage Experiments and Process Data</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Computer-Vision"><span class="toc-text">Computer Vision</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Object-Detection"><span class="toc-text">Object Detection</span></a></li></ol></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=1141564&auto=1&height=66"></iframe><br>一些资料的备份。</p>
<h2 id="cs20si-2017-notes-and-slides"><a href="#cs20si-2017-notes-and-slides" class="headerlink" title="cs20si 2017 notes and slides"></a>cs20si 2017 notes and slides</h2><h3 id="1、Overview-Of-Tensorflow"><a href="#1、Overview-Of-Tensorflow" class="headerlink" title="1、Overview Of Tensorflow"></a>1、Overview Of Tensorflow</h3><p><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/notes_01.pdf" target="_blank" rel="external">notes_01</a><br><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/slides_01.pdf" target="_blank" rel="external">slides_01</a></p>
<h3 id="2、Operations"><a href="#2、Operations" class="headerlink" title="2、Operations"></a>2、Operations</h3><p><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/notes_02.pdf" target="_blank" rel="external">notes_02</a><br><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/slides_02.pdf" target="_blank" rel="external">slides_02</a></p>
<h3 id="3、Linear-and-Logistic-Regression"><a href="#3、Linear-and-Logistic-Regression" class="headerlink" title="3、Linear and Logistic Regression"></a>3、Linear and Logistic Regression</h3><p><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/notes_03.pdf" target="_blank" rel="external">notes_03</a><br><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/slides_03.pdf" target="_blank" rel="external">slides_03</a></p>
<h3 id="4、Structure-Your-Tensorflow-Model"><a href="#4、Structure-Your-Tensorflow-Model" class="headerlink" title="4、Structure Your Tensorflow Model"></a>4、Structure Your Tensorflow Model</h3><p><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/notes_04.pdf" target="_blank" rel="external">notes_04</a><br><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/slides_04.pdf" target="_blank" rel="external">slides_04</a></p>
<h3 id="5、Manage-Experiments-and-Process-Data"><a href="#5、Manage-Experiments-and-Process-Data" class="headerlink" title="5、Manage Experiments and Process Data"></a>5、Manage Experiments and Process Data</h3><p><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/notes_05.pdf" target="_blank" rel="external">notes_05</a><br><a href="https://github.com/wwdguu/wwdguu.github.io/blob/master/2018/01/21/paper-and-notes/cs20si/slides_05.pdf" target="_blank" rel="external">slides_05</a></p>
<h2 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h2><h3 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h3>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">link</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/link//" class="article-tag-list-link color5">link</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/21/paper-and-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-tensorflow-programming-manage-your-experiments-in-tf" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/21/tensorflow-programming-manage-your-experiments-in-tf/">How to Manage Your Experiments in TensorFlow</a>
    </h1>
  

        
        <a href="/2018/01/21/tensorflow-programming-manage-your-experiments-in-tf/" class="archive-article-date">
  	<time datetime="2018-01-20T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-train-Saver"><span class="toc-text">tf.train.Saver()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-summary"><span class="toc-text">tf.summary</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Control-Randomization"><span class="toc-text">Control Randomization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#在操作级别设置随机种子。-所有的随机张量都允许你在初始化时传入种子值。"><span class="toc-text">在操作级别设置随机种子。 所有的随机张量都允许你在初始化时传入种子值。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#在计算图级别用tf-Graph-seed设置随机种子"><span class="toc-text">在计算图级别用tf.Graph.seed设置随机种子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reading-Data-in-Tensorflow"><span class="toc-text">Reading Data in Tensorflow</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#从队列读取数据。"><span class="toc-text">从队列读取数据。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Threads-和-Queues"><span class="toc-text">Threads 和  Queues</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=31134197&auto=1&height=66"></iframe><br>主要介绍TensorFlow提供的一系列用来管理实验的优秀的工具。包括tf.train.Saver类，<br>TensorFlow的随机种子和NumPy的随机状态，并可视化我们的训练过程。</p>
<h2 id="tf-train-Saver"><a href="#tf-train-Saver" class="headerlink" title="tf.train.Saver()"></a>tf.train.Saver()</h2><p>tf.train.Saver()类使得我们能够用二进制文件保存计算图的变量。这样使得我们可以在若干步训练过后保存参数并随时重新加载参数进行训练。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tf.train.Saver.save(sess, save_path, global_step=<span class="keyword">None</span>, lastest_filename=<span class="keyword">None</span>,</div><div class="line">                meta_graph_suffix=<span class="string">'meta'</span>, write_meta_graph=<span class="keyword">True</span>, write_state=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p>
<p>例如我们想每训练1000步保存一次参数，我们可以这样做：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">saver = tf.train.Saver()</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(trianing_steps):</div><div class="line">        sess.run([optimizer])</div><div class="line">        <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>：</div><div class="line">            saver.save(sess, <span class="string">'checkpoint_directory/model_name'</span>,</div><div class="line">            global_step=model.global_step)</div></pre></td></tr></table></figure></p>
<p>在TensorFlow术语中，保存图形变量的步骤称为检查点。由于我们将创建多个检查点，因此将模型所经历的训练步骤的数量附加到名为global_step的变量中会很有帮助。 在TensorFlow程序中看到这是一个非常常见的变量。 我们首先需要创建它，将其初始化为0，并将其设置为不可训练，因为我们不希望TensorFlow对其进行优化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.global_step = tf.Variable(<span class="number">0</span>, dtype=tf.int32, trainable=<span class="keyword">False</span>, name=<span class="string">'global_step'</span>)</div></pre></td></tr></table></figure></p>
<p>我们需要将global_step作为参数传递到optimizer中，使得它能够每训练一步加一。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, global_step=self.global_step)</div></pre></td></tr></table></figure></p>
<p>为了在名为“checkpoints”的文件夹保存检查点，我们这样操作：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver.save(sess, <span class="string">'checkpoints/skip-gram'</span>, global_step=model.global_step)</div></pre></td></tr></table></figure></p>
<p>于是整个word2vec的训练过程大概如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">self.global_step = tf.Variable(<span class="number">0</span>, dtype=tf.int32, trainable=<span class="keyword">False</span>, name=<span class="string">'global_step'</span>)</div><div class="line">self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss,global_step=self.global_step)</div><div class="line">saver = tf.train.Saver()</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    average_loss = <span class="number">0.0</span></div><div class="line">    writer = tf.summary.FileWriter(<span class="string">'./improved_graph'</span>,sess.graph)</div><div class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(num_train_steps):</div><div class="line">        batch = batch.gen_next()</div><div class="line">        loss_batch, _ = sess.run([model.loss,model.optimizer],</div><div class="line">            feed_dict=&#123;model.center_words: batch[<span class="number">0</span>],</div><div class="line">                      model.target_words: batch[<span class="number">1</span>]&#125;)</div><div class="line">        average_loss += loss_batch</div><div class="line">        <span class="keyword">if</span> (index + <span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">            saver.save(sess, <span class="string">'checkpoints/skip-gram'</span>,global_step=model.global_step)</div></pre></td></tr></table></figure></p>
<p>这时检查点文件都在文件夹checkpoints中。<br>如果想要恢复某个检查点，可以用以下语句：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver.restore(sess, <span class="string">'checkpoints/skip-gram-1000'</span>)</div></pre></td></tr></table></figure></p>
<p>值得注意的是，我们只能恢复已经存在的checkpoints文件，所以在恢复时，需要先检查文件的有效性，可以这样做：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ckpt = tf.train.get_checkpoint_state(os.path.dirname(<span class="string">'checkpoints/checkpoint'</span>))</div><div class="line"><span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</div><div class="line">    saver.restore(sess, ckept.model_checkpoint_path)</div></pre></td></tr></table></figure></p>
<p>默认情况下，saver.save()保存图中的所有变量，而且也是推荐这么做的。但是，但是也可以通过以下方法只保存部分变量的值：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">v1 = tf.Variable(..., name=<span class="string">'v1'</span>)</div><div class="line">v2 = tf.Variable(..., name=<span class="string">'v2'</span>)</div><div class="line"></div><div class="line"><span class="comment"># pass the variables as a dict:</span></div><div class="line">saver = tf.train.Saver(&#123;<span class="string">'v1'</span>: v1, <span class="string">'v2'</span>: v2&#125;)</div><div class="line"></div><div class="line"><span class="comment"># pass them as a list</span></div><div class="line">saver =tf.train.Saver([v1,v2])</div><div class="line"></div><div class="line"><span class="comment"># passing a list is equivalent to passing a dict with the variable op names </span></div><div class="line">saver = tf.train.Saver(&#123;v.op.name: v <span class="keyword">for</span> v <span class="keyword">in</span> [v1, v2]&#125;)</div></pre></td></tr></table></figure></p>
<p>注意：savers只是保存了变量的值，并没有保存整个计算图，所以我们需要自己创建计算图，然后载入变量。检查点文件指定了从变量到tensor的映射方式。人们通常不只是保存上一次迭代的参数，还保存迄今为止效果最好的参数，以便可以根据最佳参数评估模型。</p>
<h2 id="tf-summary"><a href="#tf-summary" class="headerlink" title="tf.summary"></a>tf.summary</h2><p>我们可以使用Tensorboard可视化训练数据，包括loss, average loss, accuracy等。可以将它们可视化为点，直方图，甚至是图像。所以我们建立一个新的name scope来管理所有这类操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_create_summaries</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'summaries'</span>):</div><div class="line">        tf.summary.scalar(<span class="string">'loss'</span>, self.loss)</div><div class="line">        tf.summary.scalar(<span class="string">'accuracy'</span>, self.accuracy)</div><div class="line">        tf.summary.histogram(<span class="string">'histogram loss'</span>, self.loss)</div><div class="line">        <span class="comment"># because you have several summaries, you should merge them all</span></div><div class="line">        <span class="comment"># into one op to make it easier to manage</span></div><div class="line">        self.summary_op = tf.summary.merge_all()</div></pre></td></tr></table></figure></p>
<p>然后用 sess.run()来执行。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loss_batch, _, summary = sess.run([model.loss, model.optimizer, model.summary_op], feed_dict=feed_dict)</div></pre></td></tr></table></figure></p>
<p>接着我们需要用用于可视化计算图的FileWriter对象来将这些summary写入文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">writer.add_summary(summary, global_step=step)</div></pre></td></tr></table></figure></p>
<p>然后我们就可以得到一些可视化结果。<br>值得注意的是，如果我们将summary数据保存在graph文件夹的不同子文件夹，就可以对不同超参数的训练结果进行比较。<br>我们也可以使用tf.summary.image将结果可视化为图片。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.summary.image(name, tensor, max_output=<span class="number">3</span>, collections=<span class="keyword">None</span>)</div></pre></td></tr></table></figure></p>
<h2 id="Control-Randomization"><a href="#Control-Randomization" class="headerlink" title="Control Randomization"></a>Control Randomization</h2><p>我们往往必须控制随机化过程才能为实验获得稳定的结果。NumPy以随机种子和随机状态获得随机数。但是TensorFlow不允许我们以numpy的方式获得随机状态，但它确实可以让我们通过以下两种方式获得稳定的随机结果：</p>
<h3 id="在操作级别设置随机种子。-所有的随机张量都允许你在初始化时传入种子值。"><a href="#在操作级别设置随机种子。-所有的随机张量都允许你在初始化时传入种子值。" class="headerlink" title="在操作级别设置随机种子。 所有的随机张量都允许你在初始化时传入种子值。"></a>在操作级别设置随机种子。 所有的随机张量都允许你在初始化时传入种子值。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">my_var = tf.Variable(tf.trucated_normal((<span class="number">-1.0</span>,<span class="number">1.0</span>), stddev=<span class="number">0.1</span>, seed=<span class="number">0</span>))</div></pre></td></tr></table></figure>
<p>注意每个新会话都会重新开始随机状态。例如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">c = tf.random_uniform([], <span class="number">-10</span>, <span class="number">10</span>, seed=<span class="number">2</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c)) <span class="comment"># &gt;&gt; 3.57492</span></div><div class="line">    print(sess.run(c)) <span class="comment"># &gt;&gt; -5.97319</span></div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">c = tf.random_uniform([], <span class="number">-10</span>, <span class="number">10</span>, seed=<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c)) <span class="comment"># &gt;&gt; 3.57493</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c)) <span class="comment"># &gt;&gt; 3.57493</span></div></pre></td></tr></table></figure>
<p>随着操作级别的随机种子，每个操作保持自己的种子。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">c = tf.random_uniform([], <span class="number">-10</span>, <span class="number">10</span>, seed=<span class="number">2</span>)</div><div class="line">d = tf.random_uniform([], <span class="number">-10</span>, <span class="number">10</span>, seed=<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c)) <span class="comment"># &gt;&gt; 3.57493</span></div><div class="line">    print(sess.run(d)) <span class="comment"># &gt;&gt; 3.57493</span></div></pre></td></tr></table></figure></p>
<h3 id="在计算图级别用tf-Graph-seed设置随机种子"><a href="#在计算图级别用tf-Graph-seed设置随机种子" class="headerlink" title="在计算图级别用tf.Graph.seed设置随机种子"></a>在计算图级别用tf.Graph.seed设置随机种子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.set_random_seed(seed)</div></pre></td></tr></table></figure>
<p>如果你不关心图中每个操作的随机化，而只是希望能够在另一个图上复制结果（以便其他人可以在你自己的图上复制你的结果），你可以使用tf.set_random_seed。设置当前的TensorFlow随机种子只影响当前的默认图形。<br>例如，有两个模型 a.py 和 b.py，它们有相同的代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">tf.set_random_seed(<span class="number">2</span>)</div><div class="line">c = tf.random_uniform([], <span class="number">-10</span>, <span class="number">10</span>)</div><div class="line">d = tf.random_uniform([], <span class="number">-10</span>, <span class="number">10</span>)</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c))</div><div class="line">    print(sess.run(d))</div></pre></td></tr></table></figure></p>
<p>当没有设置图级别的随机种子时，两个代码文件会运行得到不同的结果。而如果设置了，则会得到相同的结果。</p>
<h2 id="Reading-Data-in-Tensorflow"><a href="#Reading-Data-in-Tensorflow" class="headerlink" title="Reading Data in Tensorflow"></a>Reading Data in Tensorflow</h2><p>将数据加载到TensorFlow图中有两种主要的方法：一种是通过我们熟悉的feed_dict，另一种是通过读者使我们直接从文件中读取张量。当然，第三种方法是使用常量加载数据，但是这会造成图严重臃肿且无法运行。为了明白为什么我们需要比feed_dict更多的东西，我们需要看看feed_dict是如何工作的。Feed_dict将首先将数据从存储系统发送到客户端，然后从客户端发送到工作进程。这会导致数据变慢，特别是如果客户端与工作进程不在同一台机器上。TensorFlow有readers可以直接将数据加载到工作进程中。当我们不在分布式系统或者当我们的数据集很小的时候，这种改进将不会被注意到，但是它仍然值得研究。 TensorFlow有几个内置读卡器来满足您的阅读需求。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">tf.TextLineReader</div><div class="line"><span class="comment"># Outputs the lines of a file delimited by newlines</span></div><div class="line"><span class="comment"># E.g. text files, CSV files</span></div><div class="line">tf.FixedLengthRecordReader</div><div class="line"><span class="comment"># Outputs the entire file when all files have same fixed lengths</span></div><div class="line"><span class="comment"># E.g. each MNIST file has 28 x 28 pixels, CIFAR-10 32 x 32 x 3</span></div><div class="line">tf.WholeFileReader</div><div class="line"><span class="comment"># Outputs the entire file content</span></div><div class="line">tf.TFRecordReader</div><div class="line"><span class="comment"># Reads samples from TensorFlow's own binary format (TFRecord)</span></div><div class="line">tf.ReaderBase</div><div class="line"><span class="comment"># Allows you to create your own readers</span></div></pre></td></tr></table></figure></p>
<h3 id="从队列读取数据。"><a href="#从队列读取数据。" class="headerlink" title="从队列读取数据。"></a>从队列读取数据。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">filename_queue = tf.train.string_input_producer([<span class="string">'file0.csv'</span>, <span class="string">'file1.csv'</span>])</div><div class="line">reader = tf.TextLineReader()</div><div class="line">key , value = reader.read(filename_queue)</div></pre></td></tr></table></figure>
<h3 id="Threads-和-Queues"><a href="#Threads-和-Queues" class="headerlink" title="Threads 和  Queues"></a>Threads 和  Queues</h3><p>我们可以使用tf.Coordinator 和 tf.QueueRunner 来管理队列。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="comment"># start populating the filename queue</span></div><div class="line">    coord = tf.train.Coordinator()</div><div class="line">    threads = tf.train.start_queue_runners(coord=coord)</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://web.stanford.edu/class/cs20si/2017/lectures/notes_05.pdf" target="_blank" rel="external">notes_05</a><br><a href="https://web.stanford.edu/class/cs20si/2017/lectures/slides_05.pdf" target="_blank" rel="external">slides_05</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/tensorflow//" class="article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/21/tensorflow-programming-manage-your-experiments-in-tf/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-effective-java-methods-common-to-all-objects" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/21/effective-java-methods-common-to-all-objects/">Effective Java -- Methods Common to All Objects</a>
    </h1>
  

        
        <a href="/2018/01/21/effective-java-methods-common-to-all-objects/" class="archive-article-date">
  	<time datetime="2018-01-20T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-21</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Java-Items-about-Methods-Common-to-All-Objects"><span class="toc-text">Effective Java Items about Methods Common to All Objects</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-10-Obey-the-general-contract-when-overriding-equals"><span class="toc-text">Item 10: Obey the general contract when overriding equals</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-11-Always-override-hashCode-when-you-override-equals"><span class="toc-text">Item 11: Always override hashCode when you override equals</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-12-Always-override-toString"><span class="toc-text">Item 12: Always override toString</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-13-Override-clone-judiciously"><span class="toc-text">Item 13: Override clone judiciously</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item-14-Consider-implementing-Comparable"><span class="toc-text">Item 14: Consider implementing Comparable</span></a></li></ol></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=483671599&auto=1&height=66"></iframe></p>
<h2 id="Effective-Java-Items-about-Methods-Common-to-All-Objects"><a href="#Effective-Java-Items-about-Methods-Common-to-All-Objects" class="headerlink" title="Effective Java Items about Methods Common to All Objects"></a>Effective Java Items about Methods Common to All Objects</h2><p>设计Object类的目的是为了扩展，它所有的非final方法(equals, hashCode, toString, clone, finalize)都有着明确的通用约定，它们都被设计成要被覆盖的。任何一个类在覆盖这些方法时都要遵守一些通用规定。</p>
<h3 id="Item-10-Obey-the-general-contract-when-overriding-equals"><a href="#Item-10-Obey-the-general-contract-when-overriding-equals" class="headerlink" title="Item 10: Obey the general contract when overriding equals"></a>Item 10: Obey the general contract when overriding equals</h3><p>equals方法实现了等价关系，主要要满足以下条件：自反性，对称性，传递性，一致性，非空性。为了高效编写符合要求的equals方法，书中总结了以下方法：<br>1、使用==操作符检查参数是否是这个对象的引用。<br>2、使用instanceof操作符检查“参数是否为正确的类型”。<br>3、把参数转换成正确的类型。<br>4、对于该类中的每个“关键”域,检查参数中的域是否与该对象中对应的域相匹配。<br>5、编写好equals方法之后，再仔细检查是否满足之前的几个条件。<br>6、覆盖equals时要同时覆盖hashCode<br>7、不要企图让equals方法过于智能。<br>8、不要将equals声明中的Object对象替换为其他的类型。</p>
<h3 id="Item-11-Always-override-hashCode-when-you-override-equals"><a href="#Item-11-Always-override-hashCode-when-you-override-equals" class="headerlink" title="Item 11: Always override hashCode when you override equals"></a>Item 11: Always override hashCode when you override equals</h3><p>每个覆盖了equals方法的类中，也必须同时覆盖hashCode方法。</p>
<h3 id="Item-12-Always-override-toString"><a href="#Item-12-Always-override-toString" class="headerlink" title="Item 12: Always override toString"></a>Item 12: Always override toString</h3><p>遵守toString的约定并不像遵守equals和hashCode的约定那么重要，但是提供好的toString实现可以使得类使用起来更为舒适。</p>
<h3 id="Item-13-Override-clone-judiciously"><a href="#Item-13-Override-clone-judiciously" class="headerlink" title="Item 13: Override clone judiciously"></a>Item 13: Override clone judiciously</h3><h3 id="Item-14-Consider-implementing-Comparable"><a href="#Item-14-Consider-implementing-Comparable" class="headerlink" title="Item 14: Consider implementing Comparable"></a>Item 14: Consider implementing Comparable</h3>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/21/effective-java-methods-common-to-all-objects/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-tensorflow-programming-structure-your-tf-model" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/20/tensorflow-programming-structure-your-tf-model/">Structure Your Tensorflow Model Notes</a>
    </h1>
  

        
        <a href="/2018/01/20/tensorflow-programming-structure-your-tf-model/" class="archive-article-date">
  	<time datetime="2018-01-20T07:03:29.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-20</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#如何结构化Tensorflow模型"><span class="toc-text">如何结构化Tensorflow模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tensorflow中模型的结构"><span class="toc-text">tensorflow中模型的结构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#第一步，构建计算图"><span class="toc-text">第一步，构建计算图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第二步，计算"><span class="toc-text">第二步，计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word2Vec-skip-gram-model实例"><span class="toc-text">Word2Vec, skip-gram model实例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#第一步，构建计算图-1"><span class="toc-text">第一步，构建计算图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第二步，执行-计算"><span class="toc-text">第二步，执行 计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Name-Scope"><span class="toc-text">Name Scope</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么要学习梯度？"><span class="toc-text">为什么要学习梯度？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=500293527&auto=1&height=66"></iframe><br>之前已经介绍了使用tensorflow构建线性回归以及用逻辑回归来进行MNIST手写字母识别,这些都属于比较简单的网络结构。当我们需要构建更为复杂的结构时，就需要好好计划编码结构，不然代码混乱不说而且难于调试。这里主要介绍如何高效结构化模型，以word2vec作为例子说明。<br>关于word2vec的理论知识可以参考cs224n的课件。主要介绍利用tensorflow搭建skip-gram模型。原理可参考：<br><a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" target="_blank" rel="external">Word2Vec Tutorial—The Skip-Gram Model</a></p>
<h2 id="如何结构化Tensorflow模型"><a href="#如何结构化Tensorflow模型" class="headerlink" title="如何结构化Tensorflow模型"></a>如何结构化Tensorflow模型</h2><h3 id="tensorflow中模型的结构"><a href="#tensorflow中模型的结构" class="headerlink" title="tensorflow中模型的结构"></a>tensorflow中模型的结构</h3><h4 id="第一步，构建计算图"><a href="#第一步，构建计算图" class="headerlink" title="第一步，构建计算图"></a>第一步，构建计算图</h4><p>1、为输入和输出定义placeholders<br>2、定义权重weights<br>3、定义inference model<br>4、定义损失函数<br>5、定义优化器</p>
<h4 id="第二步，计算"><a href="#第二步，计算" class="headerlink" title="第二步，计算"></a>第二步，计算</h4><p>1、初次初始化所有模型变量<br>2、输入训练数据，可能还会涉及随机化数据样本的顺序。<br>3、对训练数据执行推理模型，从而计算每个训练输入以当前模型参数的输出结果。<br>4、计算损失<br>5、调整模型参数使得模型的损失最大或者最小。<br><img src="compute.jpg" alt=""></p>
<h3 id="Word2Vec-skip-gram-model实例"><a href="#Word2Vec-skip-gram-model实例" class="headerlink" title="Word2Vec, skip-gram model实例"></a>Word2Vec, skip-gram model实例</h3><h4 id="第一步，构建计算图-1"><a href="#第一步，构建计算图-1" class="headerlink" title="第一步，构建计算图"></a>第一步，构建计算图</h4><p>1、为输入和输出定义placeholders<br>输入是中心词，输出是目标(上下文)词，我们直接输入这些词的索引而不是one-hot向量，例如：如果中心词是单词表中的第1001个单词，我们输入数字1001。每个样本输入都是一个标量，所以我们以形状[BATCH_SIZE]的占位符定义批量大小为BATCH_SIZE的输入。同样，输出也是用同样的方法定义。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">center_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE])</div><div class="line">target_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE])</div></pre></td></tr></table></figure></p>
<p>2、定义权重weights<br>每行对应一个词的表示向量。如果用一个词表示一个大小为EMBED_SIZE的向量，那么嵌入矩阵的形状为[VOCAB_SIZE,EMBED_SIZE]。我们将嵌入矩阵初始化为随机分布的值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">embed_matrix = tf.Variable(tf.random_uniform([VOCAB_SIZE,EMBED_SIZE],<span class="number">-1.0</span>,<span class="number">1.0</span>))</div></pre></td></tr></table></figure></p>
<p>3、定义推理模型<br>我们的目标是得到词汇表中单词的向量表示，embed_matrix的维度是[VOCAB_SIZE x EMBED_SIZE]，embedding矩阵的每一行和该索引出的单词的矢量表示相对应。为了得到批次中所有中心词的表示，我们得到所有相应行的切片嵌入矩阵。Tensorflow为我们提供了一个简单的API：tf.nn.embedding_lookup()。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.nn.embedding_lookup(parmas, ids, partition_strategy=<span class="string">'mod'</span>, name=<span class="keyword">None</span>, validate_indices=<span class="keyword">True</span>, max_norm=<span class="keyword">None</span>)</div></pre></td></tr></table></figure></p>
<p>于是为了得到输入中心词的嵌入矩阵表示，我们这样操作:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">embed = tf.nn.embedding_lookup(embed_matrix, center_words)</div></pre></td></tr></table></figure></p>
<p>4、定义损失函数<br>对于NCE损失，我们需要隐藏层的权重和偏置来计算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">nce_weight = tf.Variable(tf.truncated_normal([VOCAB_SIZE, EMBED_SIZE],stddev=<span class="number">1.0</span>/EMBED_SIZE**<span class="number">0.5</span>))</div><div class="line">nce_bias = tf.Variable(tf.zeros([VOCAB_SIZE]))</div><div class="line">loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight,</div><div class="line">                                     biases=nce_bias,</div><div class="line">                                     labels=target_words,</div><div class="line">                                     inputs=embed,</div><div class="line">                                     num_sampled=NUM_SAMPLED,</div><div class="line">                                     num_classes=VOCAB_SIZE))</div></pre></td></tr></table></figure></p>
<p>5、定义优化器<br>我们使用梯度下降法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)</div></pre></td></tr></table></figure></p>
<h4 id="第二步，执行-计算"><a href="#第二步，执行-计算" class="headerlink" title="第二步，执行 计算"></a>第二步，执行 计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variable_initializer())</div><div class="line">    average_loss = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(NUM_TRAIN_STEPS):</div><div class="line">        batch = batch_gen.next()</div><div class="line">        loss_batch, _=sess.run([loss, optimizer],</div><div class="line">                                feed_dict=&#123;center_words: batch[<span class="number">0</span>], target_words: batch[<span class="number">1</span>]&#125;)</div><div class="line">        average_loss +=loss_batch</div><div class="line">        <span class="keyword">if</span> (index + <span class="number">1</span>) % <span class="number">200</span> == <span class="number">0</span>:</div><div class="line">            print(<span class="string">'Average loss at step &#123;&#125;: &#123;:5.1f&#125;'</span>.format(index+<span class="number">1</span>,</div><div class="line">                                                    average_loss/(index+<span class="number">1</span>)))</div></pre></td></tr></table></figure>
<h3 id="Name-Scope"><a href="#Name-Scope" class="headerlink" title="Name Scope"></a>Name Scope</h3><p>给出张量的名称，在Tensorboard中查看<br><img src="tensorboard.jpg" alt=""><br>这看起来可读性并不强，节点到处都是。Tensorboard并不知道哪些节点之间关联性比较强并将它们组合在一起。当构建更为复杂的模型时，这看起来会更混乱。实际上我们可以同过name scope的方法指定节点之间的关联关系，这样有着相同name scope的节点会被放置在一起。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.name_scope(name_of_that_scope):</div><div class="line">    <span class="comment"># declare op_1</span></div><div class="line">    <span class="comment"># declare op_2</span></div></pre></td></tr></table></figure></p>
<p>这样我们就可以将之前的代码再规范一下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'data'</span>):</div><div class="line">    center_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE], name=<span class="string">'center_words'</span>)</div><div class="line">    target_words = tf.placeholder(tf.in32, shape=[BATCH_SIZE, <span class="number">1</span>], name=<span class="string">'target_words'</span>)</div><div class="line"><span class="keyword">with</span> tf.name_scope(embed):</div><div class="line">    embed_matrix = tf.Variable(tf.random_uniform([VOCAB_SIZE, EMBED_SIZE], <span class="number">-1.0</span>, <span class="number">1.0</span>), name=<span class="string">'embed_matrx'</span>)</div><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</div><div class="line">    embed = tf.nn.embedding_lookup(embed_matrix, center_words, name=<span class="string">'embed'</span>)</div><div class="line">    nce_weights = tf.Variable(tf.truncated_normal([VOCAB_SIZE, EMBED_SIZE],</div><div class="line">            stddev=<span class="number">1.0</span> / math.sqrt(EMBED_SIZE)), name=<span class="string">'nce_weights'</span>)</div><div class="line">    nce_bias = tf.Variable(tf.zeros([VOCAB_SIZE]), name=<span class="string">'nce_bias'</span>)</div><div class="line">    loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights, biases=nce_bias, labels=target_words, inputs=embbed, num_sampled=NUM_SAMPLED, num_classes=VOCAB_SIZE), name=<span class="string">'loss'</span>)</div></pre></td></tr></table></figure></p>
<p>这样Tensorboard中的图看起来更加直观了，鼠标点击相应的块会出现该块的具体内容。<br><img src="with_name_scope.JPG" alt=""><br>Tensorboard中有两种类型的边界，一种是实线一种是虚线，实线代表data flow边，而虚线代表控制依赖的边。<br>此外，为了让代码的复用性更强，我们可以将模型写成一个类，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span>  <span class="title">SkipGramModel</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, params)</span>:</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_placeholder</span><span class="params">(self)</span></span></div><div class="line"><span class="function">        <span class="title">pass</span></span></div><div class="line"><span class="function"></span></div><div class="line"><span class="function">    <span class="title">def</span> <span class="title">_create_embedding</span><span class="params">(self)</span></span></div><div class="line"><span class="function">        <span class="title">pass</span></span></div><div class="line"><span class="function"></span></div><div class="line"><span class="function">    <span class="title">def</span> <span class="title">_create_loss</span><span class="params">(self)</span></span></div><div class="line"><span class="function">        <span class="title">pass</span></span></div><div class="line"><span class="function"></span></div><div class="line"><span class="function">    <span class="title">def</span> <span class="title">_create_optimizer</span><span class="params">(self)</span></span></div><div class="line"><span class="function">        <span class="title">pass</span></span></div></pre></td></tr></table></figure></p>
<h3 id="为什么要学习梯度？"><a href="#为什么要学习梯度？" class="headerlink" title="为什么要学习梯度？"></a>为什么要学习梯度？</h3><p>从以上例子可以看出 ，我们在构建模型的时候并没有计算梯度，而是Tensorflow自动帮我们求解的，那么我们为什么还要学习梯度呢？因为Tensorflow虽然帮我们计算了梯度，但是它并没有告诉我们函数是否会受到梯度爆炸或者消失的影响，所以我们仍然需要了解梯度下降的工作原理。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://web.stanford.edu/class/cs20si/2017/lectures/notes_04.pdf" target="_blank" rel="external">notes_04</a><br><a href="https://web.stanford.edu/class/cs20si/2017/lectures/slides_04.pdf" target="_blank" rel="external">slides_04</a><br><a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">Visualizing MNIST</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/tensorflow//" class="article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/20/tensorflow-programming-structure-your-tf-model/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-tensorflow-programming-linear-and-logistic-regression" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/19/tensorflow-programming-linear-and-logistic-regression/">Linear and Logistic Regression in Tensorflow Notes</a>
    </h1>
  

        
        <a href="/2018/01/19/tensorflow-programming-linear-and-logistic-regression/" class="archive-article-date">
  	<time datetime="2018-01-18T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#线性回归和逻辑回归"><span class="toc-text">线性回归和逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归"><span class="toc-text">线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#代码"><span class="toc-text">代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#如何判断一个模型是正确的？"><span class="toc-text">如何判断一个模型是正确的？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#使用相关系数R的平方"><span class="toc-text">使用相关系数R的平方</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#在测试集上运行"><span class="toc-text">在测试集上运行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#用虚拟数据测试模型"><span class="toc-text">用虚拟数据测试模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#部分代码分析"><span class="toc-text">部分代码分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优化"><span class="toc-text">优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#更多关于梯度计算"><span class="toc-text">更多关于梯度计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#优化器种类"><span class="toc-text">优化器种类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#各种优化器的比较"><span class="toc-text">各种优化器的比较</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#逻辑回归"><span class="toc-text">逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#理解one-hot-encodiing"><span class="toc-text">理解one-hot encodiing</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=474117771&auto=1&height=66"></iframe></p>
<h1 id="线性回归和逻辑回归"><a href="#线性回归和逻辑回归" class="headerlink" title="线性回归和逻辑回归"></a>线性回归和逻辑回归</h1><p>之前已经在cs231n的笔记中介绍过基本的线性回归和逻辑回归模型，现在需要用tensorflow实现。</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p><a href="https://web.stanford.edu/class/cs20si/2017/lectures/notes_03.pdf" target="_blank" rel="external">notes_03</a></p>
<h3 id="如何判断一个模型是正确的？"><a href="#如何判断一个模型是正确的？" class="headerlink" title="如何判断一个模型是正确的？"></a>如何判断一个模型是正确的？</h3><h4 id="使用相关系数R的平方"><a href="#使用相关系数R的平方" class="headerlink" title="使用相关系数R的平方"></a>使用相关系数R的平方</h4><p><a href="http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit" target="_blank" rel="external">R-squared</a></p>
<h4 id="在测试集上运行"><a href="#在测试集上运行" class="headerlink" title="在测试集上运行"></a>在测试集上运行</h4><h4 id="用虚拟数据测试模型"><a href="#用虚拟数据测试模型" class="headerlink" title="用虚拟数据测试模型"></a>用虚拟数据测试模型</h4><h3 id="部分代码分析"><a href="#部分代码分析" class="headerlink" title="部分代码分析"></a>部分代码分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.01</span>).minimize(loss)</div><div class="line">sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</div></pre></td></tr></table></figure>
<p>有两个疑问？<br>1、为什么train_op在tf.Session.run()的提取列表中？<br>2、Tensorflow怎么知道要更新哪些变量？<br>实际上，我们可以将任何Tensorflow的操作作为tf.Session.run()的提取变量。Tensorflow会执行计算图中这些操作所依赖的部分。在以上例子中，train_op的目的是使loss最小，而loss依赖于w和b的值。<br><img src="graph.jpg" alt=""><br>从图中可以看出，节点GrandientDescentOptimizer依赖于节点weights，bias和gradients。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>GradientDescentOptimizer意味着我们的更新策略是梯度下降。Tensorflow已经为我们做了自动微分，然后更新w和b的值使得loss最小。默认情况下，optimizer训练目标函数所依赖的变量中的所有可训练变量，如果这里面有一些你不想训练的变量，可以将在定义参数时其参数trainable设置为False。一个具体的例子是变量global_step，这个变量是用来记录你运行模型多少次数的变量，其不应该为可训练的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">global_step = tf.Variable(<span class="number">0</span>,trainable=<span class="keyword">False</span>, dtype=tf.int32)</div><div class="line">learning_rate = <span class="number">0.01</span> * <span class="number">0.99</span> ** tf.cast(global_step, tf.float32)</div><div class="line">increment_step = global_step.assign_add(<span class="number">1</span>)</div><div class="line">optimizer = tf.GradientDescentOptimizer(learning_rate) <span class="comment"># learning rate 可以是一个tensor</span></div></pre></td></tr></table></figure></p>
<p>tf.Variable的完整定义是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tf.Variable(initial_value=<span class="keyword">None</span>, trainable=<span class="keyword">True</span>, collections=<span class="keyword">None</span>,</div><div class="line">    validate_shape=<span class="keyword">True</span>, caching_device=<span class="keyword">None</span>, name=<span class="keyword">None</span>, variable_def=<span class="keyword">None</span>,</div><div class="line">    dtype=<span class="keyword">None</span>, expected_shape=<span class="keyword">None</span>, import_scope=<span class="keyword">None</span>)</div></pre></td></tr></table></figure></p>
<p>我们甚至可以让optimizer计算特定变量的梯度，也可以修改由optimizer计算出的梯度。<br>如下所示是一些例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">optimizer = GradientDescentOptimizer(learning_rate=<span class="number">0.1</span>)</div><div class="line"><span class="comment"># 计算一系列变量的梯度</span></div><div class="line">grads_and_vars = opt.compute_gradients(loss, &lt;list of variables&gt;)</div><div class="line"><span class="comment"># grads_and_vars 是由元组(gradient, valriable)</span></div><div class="line"><span class="comment">#组成的列表。可以对其中的gradient项做一些操作。</span></div><div class="line">substracted_grads_and_vars = [(gv[<span class="number">0</span>] - <span class="number">1.0</span>, gv[<span class="number">1</span>]) <span class="keyword">for</span> gv <span class="keyword">in</span> grads_and_vars]</div><div class="line"><span class="comment"># 让optimizer应用减过1的梯度。</span></div><div class="line">optimizer.apply_gradients(subtracted_grads_and_vars)</div></pre></td></tr></table></figure></p>
<h4 id="更多关于梯度计算"><a href="#更多关于梯度计算" class="headerlink" title="更多关于梯度计算"></a>更多关于梯度计算</h4><p>优化器类会自动计算graph的梯度，但创建新的优化器或专家用户可以调用下面的低级函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.gradients(ys, xs, grad_ys=<span class="keyword">None</span>, name=<span class="string">'gradients'</span>, colocate_gradients_with_ops=<span class="keyword">False</span>, gate_gradients=<span class="keyword">False</span>, aggregation_method=<span class="keyword">None</span>)</div></pre></td></tr></table></figure></p>
<p>当只训练一个模型的一个部分时，这种方法很有用。例如我们可以使用tf.gradient()计算中间层loss的梯度G，然后我们使用优化器来最小化中间层输出M和M + G之间的差异，<br>只更新网络的下半部分。</p>
<h4 id="优化器种类"><a href="#优化器种类" class="headerlink" title="优化器种类"></a>优化器种类</h4><p><img src="optimizer.jpg" alt=""></p>
<h5 id="各种优化器的比较"><a href="#各种优化器的比较" class="headerlink" title="各种优化器的比较"></a>各种优化器的比较</h5><p>cs231n的笔记中有介绍。也可参考：<br><a href="http://sebastianruder.com/optimizing-gradient-descent/" target="_blank" rel="external">Optimizing Gradient Descent</a></p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>用逻辑回归解决MNIST字符识别的一个例子</p>
<h3 id="理解one-hot-encodiing"><a href="#理解one-hot-encodiing" class="headerlink" title="理解one-hot encodiing"></a>理解one-hot encodiing</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://web.stanford.edu/class/cs20si/2017/lectures/slides_03.pdf" target="_blank" rel="external">slides_03</a><br><a href="https://web.stanford.edu/class/cs20si/2017/lectures/notes_03.pdf" target="_blank" rel="external">notes_03</a><br><a href="https://zhuanlan.zhihu.com/p/28924642" target="_blank" rel="external">cs20si: tensorflow for research 学习笔记3</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/tensorflow//" class="article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/19/tensorflow-programming-linear-and-logistic-regression/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-tensorflow-programming-basic" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/18/tensorflow-programming-basic/">Tensorflow Programming--Basic</a>
    </h1>
  

        
        <a href="/2018/01/18/tensorflow-programming-basic/" class="archive-article-date">
  	<time datetime="2018-01-18T07:46:07.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensorflow基本操作"><span class="toc-text">Tensorflow基本操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-Graph"><span class="toc-text">tf.Graph()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#使用图的优点"><span class="toc-text">使用图的优点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensorboard简单使用"><span class="toc-text">Tensorboard简单使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常用API"><span class="toc-text">常用API</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运算操作"><span class="toc-text">运算操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tensorflow数据类型"><span class="toc-text">Tensorflow数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Tensorflow和Numpy中的数据类型比较"><span class="toc-text">Tensorflow和Numpy中的数据类型比较</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#使用原则"><span class="toc-text">使用原则</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#constants的弊端"><span class="toc-text">constants的弊端</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#variables"><span class="toc-text">variables</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#variables初始化"><span class="toc-text">variables初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tf-Variable-assign"><span class="toc-text">tf.Variable.assign()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#assign-add-和-assign-sub"><span class="toc-text">assign_add() 和 assign_sub()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#每个session都拥有它自己的变量的拷贝"><span class="toc-text">每个session都拥有它自己的变量的拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用一个变量初始化另一个变量"><span class="toc-text">用一个变量初始化另一个变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Session-和-InteractiveSesssion"><span class="toc-text">Session 和 InteractiveSesssion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Control-Dependencies"><span class="toc-text">Control Dependencies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Placeholder"><span class="toc-text">Placeholder</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Feeding-values-to-TF-ops"><span class="toc-text">Feeding values to TF ops</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lazy-Loading"><span class="toc-text">Lazy Loading</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=26124797&auto=1&height=66"></iframe></p>
<h2 id="Tensorflow基本操作"><a href="#Tensorflow基本操作" class="headerlink" title="Tensorflow基本操作"></a>Tensorflow基本操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">a = tf.add(<span class="number">3</span>,<span class="number">5</span>)</div><div class="line">sess = tf.Session()</div><div class="line">print(sess.run(a))</div><div class="line">sess.close()</div></pre></td></tr></table></figure>
<p>或者这样写更好：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">a = tf.add(<span class="number">3</span>,<span class="number">5</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(a))</div></pre></td></tr></table></figure></p>
<p>Session对象封装了Operation对象的执行环境和Tensor对象的验证。</p>
<p>更复杂的图的例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">x = <span class="number">2</span></div><div class="line">y = <span class="number">3</span></div><div class="line">add_op = tf.add(x,y)</div><div class="line">mul_op = tf.mul(x,y)</div><div class="line">useless = tf.mul(x,add_op)</div><div class="line">pow_op = tf.pow(add_op,mul_op)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    z, not_useless = sess.run([op3,useless])</div></pre></td></tr></table></figure></p>
<p>API: tf.Session.run(fetches, feed_dict=None,options=None,rum_metadata=None)<br>将所有你想要的值的变量传递给一个列表。<br>Tensorflow支持多GPU计算，可以将构建的图分成几个大块并在多个GPU或者CPU或者其他设备上进行并行计算。</p>
<p>指定特定GPU的方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.device(<span class="string">'/gpu:2'</span>):</div><div class="line">    a = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>],name=<span class="string">'a'</span>)</div><div class="line">    b = tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>],name=<span class="string">'b'</span>)</div><div class="line">    c = tf.matmul(a,b)</div><div class="line">    <span class="keyword">with</span> tf.Session(config=tf.ConfigProto(log_device_placement=<span class="keyword">True</span>)) <span class="keyword">as</span> sess:</div><div class="line">        print(sess.run())</div></pre></td></tr></table></figure></p>
<h2 id="tf-Graph"><a href="#tf-Graph" class="headerlink" title="tf.Graph()"></a>tf.Graph()</h2><p>向一个图中添加操作，并将图设置为默认：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">g = tf.Graph()</div><div class="line"><span class="keyword">with</span> g.as_default():</div><div class="line">    x = tf.add(<span class="number">3</span>,<span class="number">5</span>)</div><div class="line"></div><div class="line">sess = tf.Session(graph=g)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(x)</div></pre></td></tr></table></figure></p>
<p>使用一下语句得到默认的图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g = tf.get_default_graph()</div></pre></td></tr></table></figure></p>
<p>注意不要将默认图和用户自定义的图混合。</p>
<h3 id="使用图的优点"><a href="#使用图的优点" class="headerlink" title="使用图的优点"></a>使用图的优点</h3><p>1、节约计算资源，每次运算仅仅只需运行与结果有关的子图<br>2、可以将图分成小块进行自动微分<br>3、方便部署在多个设备上<br>4、很多机器学习算法都能够被可视化为图的结构</p>
<h2 id="Tensorboard简单使用"><a href="#Tensorboard简单使用" class="headerlink" title="Tensorboard简单使用"></a>Tensorboard简单使用</h2><p>Tensorboard用于可视化训练过程中的一些数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">a = tf.constant(<span class="number">2</span>)</div><div class="line">b = tf.constant(<span class="number">3</span>)</div><div class="line">x = tf.add(a,b)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="comment"># 利用tensorboard记录</span></div><div class="line">    writer = tf.summary.FileWriter(<span class="string">'./graphs'</span>,sess.graph)</div><div class="line">    print(sess.run(x))</div><div class="line">writer.close()</div></pre></td></tr></table></figure>
<p>注意是在建立图之后，运行Session之前进行summary操作。<br>采用以下命令查看Tensorboard可视化结果：</p>
<p>$ python [yourprogram].py<br>$ tensorboard —logdir=’./graph’ —port 6006<br>然后在相应浏览器地址打开即可看到可视化结果。</p>
<p>为了让可视化结果更清晰，可给操作和节点命名。<br>如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">a = tf.constant(<span class="number">2</span>, name=<span class="string">'a'</span>)</div><div class="line">b = tf.constant(<span class="number">3</span>, name=<span class="string">'b'</span>)</div><div class="line">x = tf.add(a, b, name=<span class="string">'add'</span>)</div><div class="line">writer = tf.summary.FileWriter(<span class="string">'./graphs'</span>,sess.graph)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(x))</div></pre></td></tr></table></figure>
<p>总之，Tensorboard是一个十分强大的工具，特别是对于分析复杂的网络结构以及观察网络训练过程特别有用。</p>
<h2 id="常用API"><a href="#常用API" class="headerlink" title="常用API"></a>常用API</h2><p>1、tf.constant(value, dtype=None, shape=None, name=’Const’,verify_shape=False)<br>2、tf.zeros(shape, dtype=tf.float32, name=None)<br>3、tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)<br>4、tf.ones(shape, dtype=tf.float32, name=None)<br>5、tf.ones_like(input_tensor, dtype=None, name=None, optimize=True)<br>6、tf.fill(dims, value, name=None)<br>7、tf.linspace(start, stop, num, name=None)<br>8、tf.range(start, limit=None, delta=1, dtype=None, name=’range’)<br>9、tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)<br>10、tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None,name=None)<br>10、tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None,name=None)<br>11、tf.random_shuffle(value, seed=None, name=None)<br>12、tf.random_crop(value, size, seed=None, name=None)<br>13、tf.multinomial(logits, num_samples, seed=None, name=None)<br>14、tf.random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)<br>15、tf.set_random_seed(seed)</p>
<h2 id="运算操作"><a href="#运算操作" class="headerlink" title="运算操作"></a>运算操作</h2><p><img src="operations.JPG" alt=""></p>
<h2 id="Tensorflow数据类型"><a href="#Tensorflow数据类型" class="headerlink" title="Tensorflow数据类型"></a>Tensorflow数据类型</h2><p>Tensorflow需要python的原生数据类型，如int，float， string等。<br><img src="data_types.JPG" alt=""></p>
<h3 id="Tensorflow和Numpy中的数据类型比较"><a href="#Tensorflow和Numpy中的数据类型比较" class="headerlink" title="Tensorflow和Numpy中的数据类型比较"></a>Tensorflow和Numpy中的数据类型比较</h3><p>1、tf.int3 == np.int32 #true<br>2、可将numpy数据类型传递给Tensorflow的操作<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.ones([<span class="number">2</span>,<span class="number">2</span>],np.float32) <span class="comment"># =&gt;[[1.0,1.0],[1.0,1.0]]</span></div></pre></td></tr></table></figure></p>
<p>3、对于语句 tf.Session.run(fetches), 如果 fetch是一个Tensor数据，那么输出将会是一个numpy数组。</p>
<h4 id="使用原则"><a href="#使用原则" class="headerlink" title="使用原则"></a>使用原则</h4><p>1、不要使用Python原生类型作为张量，因为TensorFlow必须推断Python<br>类型。<br>2、使用numpy类型时需要小心，以后numpy和tensorflow可能不兼容。</p>
<h2 id="constants的弊端"><a href="#constants的弊端" class="headerlink" title="constants的弊端"></a>constants的弊端</h2><p>Constants是存储在图的定义中的。当constants比较大时，加载图会很耗费资源。<br>为了解决这个问题, 一个使用原则是：只对原始类型使用constants，其他需要更多内存的数据可以使用variables或者readers表示。</p>
<h2 id="variables"><a href="#variables" class="headerlink" title="variables"></a>variables</h2><p>一些例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = tf.Variable(<span class="number">2</span>, name=<span class="string">'scalar'</span>)</div><div class="line">b = tf.Variable([<span class="number">2</span>,<span class="number">3</span>], name=<span class="string">'vector'</span>)</div><div class="line">c = tf.Variable([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">3</span>]], name=<span class="string">'matrix'</span>)</div><div class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</div></pre></td></tr></table></figure></p>
<p>一个简单的问题：为什么tf.constant中constant是小写，而tf.Variable中Variable是大写？因为tf.Variable是一个类，tf.constant是一个操作符。遵循python的命名习惯。</p>
<p>如果tf.Variable有一些运算符：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">x = tf.Variable(...)</div><div class="line">x.initializer <span class="comment">#init op </span></div><div class="line">x.value() <span class="comment"># read op</span></div><div class="line">x.assign(...) <span class="comment"># write op</span></div><div class="line">x.assign_add(...) <span class="comment"># and more</span></div></pre></td></tr></table></figure></p>
<h3 id="variables初始化"><a href="#variables初始化" class="headerlink" title="variables初始化"></a>variables初始化</h3><p>最简单的方法是一次初始化所有变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">init = tf.global_variables_initializer()</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(init)</div></pre></td></tr></table></figure></p>
<p>初始化部分变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">init_ab = tf.variables_initializer([a,b], name=<span class="string">'init_ab'</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(init_ab)</div></pre></td></tr></table></figure></p>
<p>初始化单个变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(W.initializer)</div></pre></td></tr></table></figure></p>
<h3 id="tf-Variable-assign"><a href="#tf-Variable-assign" class="headerlink" title="tf.Variable.assign()"></a>tf.Variable.assign()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(<span class="number">10</span>)</div><div class="line">W.assign(<span class="number">100</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(W.initializer)</div><div class="line">    print(W.eval()) <span class="comment"># &gt;&gt;10</span></div></pre></td></tr></table></figure>
<p>因为 W.assign(100) 只是创建了一个赋值操作，这个操作要被运行才能起作用，如下所示。并且我们并不需要初始化变量，因为assign_op已经为我们做了这个操作。实际上，初始化操作是赋值操作将变量的初始值赋给变量本身。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(<span class="number">10</span>)</div><div class="line">assign_op = W.assign(<span class="number">100</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(W.initializer)</div><div class="line">    sess.run(assign_op)</div><div class="line">print(W.eval())  <span class="comment"># &gt;&gt;100</span></div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">my_var = tf.Variable(<span class="number">2</span>, name=<span class="string">'my_var'</span>)</div><div class="line">my_var_times_two = my_var.assign(<span class="number">2</span> * my_var)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(my_var.initializer)</div><div class="line">    sess.run(my_var_times_two) <span class="comment"># &gt;&gt;4</span></div><div class="line">    sess.run(my_var_times_two) <span class="comment"># &gt;&gt;8</span></div><div class="line">    sess.run(my_var_times_two) <span class="comment"># &gt;&gt;16</span></div></pre></td></tr></table></figure>
<p>以上例子中，每运行一次，my_var都执行乘2操作。</p>
<h3 id="assign-add-和-assign-sub"><a href="#assign-add-和-assign-sub" class="headerlink" title="assign_add() 和 assign_sub()"></a>assign_add() 和 assign_sub()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">my_var = tf.Variable(<span class="number">10</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(my_var.initializer)</div><div class="line">    sess.run(my_var.assign_add(<span class="number">10</span>)) <span class="comment"># &gt;&gt;20</span></div><div class="line">    sess.run(my_var.assign_sub(<span class="number">2</span>)) <span class="comment"># &gt;&gt;18</span></div></pre></td></tr></table></figure>
<p>assign_add()和assign_sub()操作都不能帮我们初始化变量，因为这两个操作都需要参数的初始值。</p>
<h3 id="每个session都拥有它自己的变量的拷贝"><a href="#每个session都拥有它自己的变量的拷贝" class="headerlink" title="每个session都拥有它自己的变量的拷贝"></a>每个session都拥有它自己的变量的拷贝</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(<span class="number">10</span>)</div><div class="line">sess1 = tf.Session()</div><div class="line">sess2 = tf.Session()</div><div class="line">sess1.run(W.initializer)</div><div class="line">sess2.run(W.initializer)</div><div class="line"></div><div class="line">print(sess1.run(W.assign_add(<span class="number">10</span>))) <span class="comment"># &gt;&gt;20</span></div><div class="line">print(sess2.run(W.assign_sub(<span class="number">2</span>))) <span class="comment"># &gt;&gt;8</span></div><div class="line"></div><div class="line">print(sess1.run(W.assign_add(<span class="number">100</span>))) <span class="comment"># &gt;&gt;120</span></div><div class="line">print(sess2.run(W.assign_sub(<span class="number">50</span>))) <span class="comment"># &gt;&gt;-42</span></div><div class="line"></div><div class="line">sess1.close()</div><div class="line">sess2.close()</div></pre></td></tr></table></figure>
<h3 id="用一个变量初始化另一个变量"><a href="#用一个变量初始化另一个变量" class="headerlink" title="用一个变量初始化另一个变量"></a>用一个变量初始化另一个变量</h3><p>下面这种方法比较常见，但是不够安全。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.truncated_normal([<span class="number">700</span>,<span class="number">10</span>]))</div><div class="line">U = tf.Variable(<span class="number">2</span> * W)</div></pre></td></tr></table></figure></p>
<p>下面这种方法保证了保证了在用W初始化U之前，W的值已经被初始化,所以更加安全。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.truncated_normal([<span class="number">700</span>,<span class="number">10</span>]))</div><div class="line">U = tf.Variable(<span class="number">2</span> * W.initialized_value())</div></pre></td></tr></table></figure></p>
<h2 id="Session-和-InteractiveSesssion"><a href="#Session-和-InteractiveSesssion" class="headerlink" title="Session 和 InteractiveSesssion"></a>Session 和 InteractiveSesssion</h2><p>InteractiveSession 和 Session的唯一区别就是InteractiveSession使其成为默认设置。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sess = tf.InteractiveSession()</div><div class="line">a = tf.constant(<span class="number">5.0</span>)</div><div class="line">b = tf.constant(<span class="number">6.0</span>)</div><div class="line">c = a * b</div><div class="line"><span class="comment"># 我们可以只使用'c.eval（）'而不指定上下文'sess'</span></div><div class="line">print(c.eval())</div><div class="line">sess.close()</div></pre></td></tr></table></figure></p>
<h2 id="Control-Dependencies"><a href="#Control-Dependencies" class="headerlink" title="Control Dependencies"></a>Control Dependencies</h2><p>API: tf.Graph.control_dependencies(control_inputs)<br>用来定义哪个操作先被执行。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># graph g 有 5个操作：a, b ,c ,d ,e</span></div><div class="line"><span class="keyword">with</span> g.control_dependencies([a,b,c]):</div><div class="line">    <span class="comment"># 操作d 和 操作e 只在 a,b,c都执行过了之后再执行。</span></div><div class="line">    d = ...</div><div class="line">    e = ...</div></pre></td></tr></table></figure></p>
<h2 id="Placeholder"><a href="#Placeholder" class="headerlink" title="Placeholder"></a>Placeholder</h2><p>一个tensorflow写的程序通常有两个部分：<br>1、构建图 2、使用会话执行图中的操作<br>也就是说我们可以在不知道需要的计算参数的具体数值的前提下构建图。<br>我们可以在不知道x和y的具体数值的前提下定义函数 f(x,y) = x*2 +y，x和y只是具体数值的占位符。我们可以构建好计算图之后再对变量赋值进行计算。<br>API: tf.placeholder(dtype, shape=None, name=None)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">a = tf.placeholder(tf.float32, shape=[<span class="number">3</span>])</div><div class="line">b = tf.constant([<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>],tf.float32)</div><div class="line">c = a + b</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c)) <span class="comment"># 因为a并没有任何具体数值，所以会出错。</span></div></pre></td></tr></table></figure>
<p>我们需要使用dictionary将值提供给占位符。<br>如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(c,&#123;a: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;))</div><div class="line"><span class="comment"># &gt;&gt; [6,7,8]</span></div></pre></td></tr></table></figure></p>
<p>也可以给占位符多次赋值，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="keyword">for</span> a_value <span class="keyword">in</span> list_of_values_for_a:</div><div class="line">        print(sess.run(c, &#123;a: a_value&#125;))</div></pre></td></tr></table></figure></p>
<p>其实我们可以通过feed_dict给任何feedable的张量，占位符只是一些必须被feed的量的一种表示。<br>可以通过 tf.Graph.is_feedable(tensor)判断张量能否被feed。</p>
<h3 id="Feeding-values-to-TF-ops"><a href="#Feeding-values-to-TF-ops" class="headerlink" title="Feeding values to TF ops"></a>Feeding values to TF ops</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">a = tf.add(<span class="number">2</span>, <span class="number">5</span>)</div><div class="line">b = tf.mul(a, <span class="number">3</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    replace_dict=&#123;a: <span class="number">15</span>&#125;</div><div class="line">    sess.run(b,feed_dict= replace_dict) <span class="comment"># returns 45</span></div></pre></td></tr></table></figure>
<h2 id="Lazy-Loading"><a href="#Lazy-Loading" class="headerlink" title="Lazy Loading"></a>Lazy Loading</h2><p>lazy loading的意思是尽量推迟创建或者初始化对象的时间，直到其需要的时候再创建或者初始化。</p>
<p>非lazy loading<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">x = tf.Variable(<span class="number">10</span>, name=<span class="string">'x'</span>)</div><div class="line">y = tf.Variable(<span class="number">20</span>, name=<span class="string">'y'</span>)</div><div class="line">z = tf.add(x, y)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    writer = tf.summary.FileWriter(<span class="string">'./my_graph'</span>,sess.graph)</div><div class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        sess.run(z)</div><div class="line">    writer.close()</div></pre></td></tr></table></figure></p>
<p>lazy loading<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">x = tf.Variable(<span class="number">10</span>, name=<span class="string">'x'</span>)</div><div class="line">y = tf.Variable(<span class="number">20</span>, name=<span class="string">'y'</span>)</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    writer = tf.summary.FileWriter(<span class="string">'./my_graph'</span>,sess.graph)</div><div class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        sess.run(tf.add(x,y))</div><div class="line">    writer.close()</div></pre></td></tr></table></figure></p>
<p>lazy loading和非lazy loading得到的结果是一样的。但是它们的区别在哪儿呢？<br>以上例子中普通的加载方法 add操作只执行一次，而lazy loading的方法add操作要执行10次，当操作更复杂时，lazy loading的弊端就显现出来了。这是tensorflow最常见的一个non-bug bugs。<br>解决方法：<br>1、从计算/运行操作单独定义操作<br>2、使用Python属性来确保函数在第一次被调用时也被加载。？？具体怎么实现<br><a href="https://danijar.com/structuring-your-tensorflow-models/" target="_blank" rel="external">Structuring Your Tensorflow Models</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://web.stanford.edu/class/cs20si/2017/lectures/slides_02.pdf" target="_blank" rel="external">Tensorflow Ops Slides</a><br><a href="https://web.stanford.edu/class/cs20si/2017/lectures/notes_02.pdf" target="_blank" rel="external">Tensorflow Ops Notes</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/tensorflow//" class="article-tag-list-link color1">tensorflow</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/18/tensorflow-programming-basic/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-design-pattern-links" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/18/design-pattern-links/">一些讲解设计模式的链接</a>
    </h1>
  

        
        <a href="/2018/01/18/design-pattern-links/" class="archive-article-date">
  	<time datetime="2018-01-17T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一些讲解设计模式的链接"><span class="toc-text">一些讲解设计模式的链接</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#设计模式"><span class="toc-text">设计模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、单例模式"><span class="toc-text">1、单例模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#主要关注点"><span class="toc-text">主要关注点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#links"><span class="toc-text">links</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、建造者模式"><span class="toc-text">2、建造者模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#应用场合"><span class="toc-text">应用场合</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#links-1"><span class="toc-text">links</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、工厂模式"><span class="toc-text">3、工厂模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#主要关注点-1"><span class="toc-text">主要关注点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#links-2"><span class="toc-text">links</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4、原型模式"><span class="toc-text">4、原型模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#关注点"><span class="toc-text">关注点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#links-3"><span class="toc-text">links</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5、适配器模式"><span class="toc-text">5、适配器模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#关注点-1"><span class="toc-text">关注点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#links-4"><span class="toc-text">links</span></a></li></ol></li></ol></li></ol></li></ol>
</div>

        <h1 id="一些讲解设计模式的链接"><a href="#一些讲解设计模式的链接" class="headerlink" title="一些讲解设计模式的链接"></a>一些讲解设计模式的链接</h1><h2 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h2><h3 id="1、单例模式"><a href="#1、单例模式" class="headerlink" title="1、单例模式"></a>1、单例模式</h3><h4 id="主要关注点"><a href="#主要关注点" class="headerlink" title="主要关注点"></a>主要关注点</h4><p>1、懒汉模式与饿汉模式的区别<br>2、如何保证线程安全</p>
<h4 id="links"><a href="#links" class="headerlink" title="links"></a>links</h4><p><a href="https://yq.aliyun.com/articles/11333" target="_blank" rel="external">Java设计模式(一)——单例模式</a><br><a href="https://www.journaldev.com/1377/java-singleton-design-pattern-best-practices-examples" target="_blank" rel="external">Java Singleton Pattern</a></p>
<h3 id="2、建造者模式"><a href="#2、建造者模式" class="headerlink" title="2、建造者模式"></a>2、建造者模式</h3><h4 id="应用场合"><a href="#应用场合" class="headerlink" title="应用场合"></a>应用场合</h4><p>1、构造器有多个参数时可以考虑使用Builder模式。<br>2、当创建复杂对象的算法应该独立于该对象的组成部分及他们的装配方式时。<br>3、创建一些复杂的对象时，这些对象的内部组成构件间的建造顺序是稳定的，但是对象的内部组成构件面临着复杂的变化。</p>
<h4 id="links-1"><a href="#links-1" class="headerlink" title="links"></a>links</h4><p><a href="https://yq.aliyun.com/articles/11334" target="_blank" rel="external">Java设计模式（二）——建造者模式</a><br><a href="https://howtodoinjava.com/design-patterns/creational/builder-pattern-in-java/" target="_blank" rel="external">Builder Pattern in Java</a><br><a href="http://wwdguu.github.io/2018/01/16/effective-java-creating-and-destroying-objects/">effective java creating and destroying objects</a></p>
<h3 id="3、工厂模式"><a href="#3、工厂模式" class="headerlink" title="3、工厂模式"></a>3、工厂模式</h3><h4 id="主要关注点-1"><a href="#主要关注点-1" class="headerlink" title="主要关注点"></a>主要关注点</h4><p>1、工厂方法模式相比简单工厂模式的优势<br>2、工厂方法模式的组成结构包括：抽象工厂、具体工厂、抽象产品、具体产品。<br>3、工厂方法模式和抽象工厂模式的区别</p>
<h4 id="links-2"><a href="#links-2" class="headerlink" title="links"></a>links</h4><p><a href="https://yq.aliyun.com/articles/11335" target="_blank" rel="external">Java 设计模式——工厂模式</a><br><a href="https://howtodoinjava.com/design-patterns/creational/implementing-factory-design-pattern-in-java/" target="_blank" rel="external">Factory Design Pattern in Java</a><br><a href="https://howtodoinjava.com/design-patterns/creational/abstract-factory-pattern-in-java/" target="_blank" rel="external">Abstract Factory Design Pattern in Java</a></p>
<h3 id="4、原型模式"><a href="#4、原型模式" class="headerlink" title="4、原型模式"></a>4、原型模式</h3><h4 id="关注点"><a href="#关注点" class="headerlink" title="关注点"></a>关注点</h4><p>1、原型模式组成部分：原型、原型注册表、客户。<br>2、浅度复制和深度复制的区别</p>
<h4 id="links-3"><a href="#links-3" class="headerlink" title="links"></a>links</h4><p><a href="https://yq.aliyun.com/articles/11336?spm=5176.100239.blogrightarea11335.25.2b2b35ebzmwCH5" target="_blank" rel="external">Java设计模式（五）——原型模式</a><br><a href="https://howtodoinjava.com/design-patterns/creational/prototype-design-pattern-in-java/" target="_blank" rel="external">Prototype Design Pattern in Java</a></p>
<h3 id="5、适配器模式"><a href="#5、适配器模式" class="headerlink" title="5、适配器模式"></a>5、适配器模式</h3><h4 id="关注点-1"><a href="#关注点-1" class="headerlink" title="关注点"></a>关注点</h4><p>1、类适配器和对象适配器的区别：建议尽量使用对象适配器的实现方式，多用合成/聚合、少用继承。<br>2、适配器模式的优缺点<br>3、缺省适配模式</p>
<h4 id="links-4"><a href="#links-4" class="headerlink" title="links"></a>links</h4><p><a href="https://yq.aliyun.com/articles/11337" target="_blank" rel="external">Java设计模式（六）——适配器模式</a><br><a href="https://howtodoinjava.com/design-patterns/structural/adapter-design-pattern-in-java/" target="_blank" rel="external">Adapter Design Pattern in Java</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/18/design-pattern-links/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-effective-java-creating-and-destroying-objects" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/17/effective-java-creating-and-destroying-objects/">Effective Java-- Creating and Destroying Objects</a>
    </h1>
  

        
        <a href="/2018/01/17/effective-java-creating-and-destroying-objects/" class="archive-article-date">
  	<time datetime="2018-01-17T11:17:08.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-17</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Java-Items-about-Creating-and-Destroying-Objects"><span class="toc-text">Effective Java Items about Creating and Destroying Objects</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Item1-Consider-static-factory-methods-instead-of-constructors"><span class="toc-text">Item1: Consider static factory methods instead of constructors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item2-Consider-a-builder-when-faced-with-many-constructor-parameters"><span class="toc-text">Item2: Consider a builder when faced with many constructor parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item3-Enforce-the-singleton-property-with-a-private-constructor-or-an-enum"><span class="toc-text">Item3: Enforce the singleton property with a private constructor or an enum</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item4-Enforce-noninstantiability-with-a-private-constructor"><span class="toc-text">Item4: Enforce noninstantiability with a private constructor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item5-Prefer-dependency-injection-to-hardwiring-resources"><span class="toc-text">Item5: Prefer dependency injection to hardwiring resources</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item6-Avoid-creating-unnecessary-objects"><span class="toc-text">Item6: Avoid creating unnecessary objects</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item7-Eliminate-obsolete-object-references"><span class="toc-text">Item7: Eliminate obsolete object references</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item8-Avoid-finalizers-and-cleaners"><span class="toc-text">Item8: Avoid finalizers and cleaners</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item9-Prefer-try-with-resources-to-try-finally"><span class="toc-text">Item9: Prefer try-with-resources to try-finally</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a>
</div>

        <h2 id="Effective-Java-Items-about-Creating-and-Destroying-Objects"><a href="#Effective-Java-Items-about-Creating-and-Destroying-Objects" class="headerlink" title="Effective Java Items about Creating and Destroying Objects"></a>Effective Java Items about Creating and Destroying Objects</h2><p>Effective Java 书籍的这一章节主要讲了一些关于何时及如何创建对象，何时及如何避免创建对象，如何确保对象能够适时地被销毁及如何管理对象销毁之前必须进行的各种清理动作的建议。</p>
<h3 id="Item1-Consider-static-factory-methods-instead-of-constructors"><a href="#Item1-Consider-static-factory-methods-instead-of-constructors" class="headerlink" title="Item1: Consider static factory methods instead of constructors"></a>Item1: Consider static factory methods instead of constructors</h3><p>静态工厂方法相比构造器方法的几大优势如下：<br>1、静态工厂方法有名称，使得产生的客户端代码更容易阅读。<br>2、使用工厂方法不必在每次调用它们的时候都创建一个新对象。<br>3、静态工厂方法可以返回原返回类型的任何子类型的对象。这使得在选择返回的对象的类时有了更大的灵活性。<br>4、创建参数化类型实例的时候，静态工厂方法使得代码更加简洁。<br>然而静态工厂方法也有以下缺点需要注意：<br>1、类如果不含有public或者protected的构造器，其就不能被子类化。<br>2、静态工厂方法相对其他的静态方法实际上并没有任何区别。这使得对于提供了静态工厂方法而不是构造器的类来说，要想查明如何实例化一个类比较困难。<br>关于静态工厂方法可参考：<br><a href="https://yq.aliyun.com/articles/11335" target="_blank" rel="external">Java 设计模式——工厂模式</a></p>
<h3 id="Item2-Consider-a-builder-when-faced-with-many-constructor-parameters"><a href="#Item2-Consider-a-builder-when-faced-with-many-constructor-parameters" class="headerlink" title="Item2: Consider a builder when faced with many constructor parameters"></a>Item2: Consider a builder when faced with many constructor parameters</h3><p>如果类的构造器或者静态工厂中具有多个参数，设计这种类时，Builder模式就是种不错的选择，特别是当大多数参数都是可以选择的时候。与使用传统的重叠构造器模式相比，使用Builder模式的客户端代码将更易于阅读和编写，构建器也更加安全。<br>关于Builder模式可参考：<br><a href="https://yq.aliyun.com/articles/11334" target="_blank" rel="external">Java设计模式（二）——建造者模式</a><br><a href="https://howtodoinjava.com/design-patterns/creational/builder-pattern-in-java/" target="_blank" rel="external">Builder Pattern in Java</a><br><a href="http://wwdguu.github.io/2018/01/16/effective-java-creating-and-destroying-objects/">effective java creating and destroying objects</a></p>
<h3 id="Item3-Enforce-the-singleton-property-with-a-private-constructor-or-an-enum"><a href="#Item3-Enforce-the-singleton-property-with-a-private-constructor-or-an-enum" class="headerlink" title="Item3: Enforce the singleton property with a private constructor or an enum"></a>Item3: Enforce the singleton property with a private constructor or an enum</h3><p>可以利用私有属性或者枚举类型来强化单例属性。其中单元素的枚举类型已经成为实现单例模式的最佳方法，需要注意的是，当单例类必须继承自一个非枚举类型时，不能使用这种方法。<br>有关单例模式可参考：<br><a href="https://yq.aliyun.com/articles/11333" target="_blank" rel="external">Java设计模式(一)——单例模式</a><br><a href="https://www.journaldev.com/1377/java-singleton-design-pattern-best-practices-examples" target="_blank" rel="external">Java Singleton Pattern</a></p>
<h3 id="Item4-Enforce-noninstantiability-with-a-private-constructor"><a href="#Item4-Enforce-noninstantiability-with-a-private-constructor" class="headerlink" title="Item4: Enforce noninstantiability with a private constructor"></a>Item4: Enforce noninstantiability with a private constructor</h3><p>对于一些只包含静态方法和静态域的类，我们不希望其被实例化，可以通过私有构造方法使得其不能被实例化。当然这种方法也有一定副作用，其使得一个类不能被子类化。因为子类需要调用超类的构造函数，而超类的构造函数却是私有的，并不能被子类调用。</p>
<h3 id="Item5-Prefer-dependency-injection-to-hardwiring-resources"><a href="#Item5-Prefer-dependency-injection-to-hardwiring-resources" class="headerlink" title="Item5: Prefer dependency injection to hardwiring resources"></a>Item5: Prefer dependency injection to hardwiring resources</h3><p>不要使用单例或静态的实用类来实现一个类，该类依赖于一个或多个底层资源，这些资源的行为会影响类的行为，并且不让类直接创建这些资源。相反，将资源或工厂传递给构造方法(或静态工厂或builder模式)。这种称为依赖注入的实践将极大地增强类的灵活性、可重用性和可测试性。</p>
<h3 id="Item6-Avoid-creating-unnecessary-objects"><a href="#Item6-Avoid-creating-unnecessary-objects" class="headerlink" title="Item6: Avoid creating unnecessary objects"></a>Item6: Avoid creating unnecessary objects</h3><p>可以通过以下一些方法来避免创建不必要的对象：<br>1、重用不可变对象而不是每次需要的时候创建一个相同功能的新对象。<br>2、对于同时提供了静态工厂方法和构造器的不可变类，通常可以使用静态工厂方法而不是构造器并以此来避免创建不必要的对象。<br>3、也可以重用那些已知不会被修改的可变对象。<br>4、优先使用基本类型而不是装箱基本类型，要当心无意识的自动装箱。<br>5、避免创建不必要的对象并不是意味着“创建对象的代价很昂贵，而我们要尽可能避免创建对象”。事实上，针对小对象的创建和回收是非常廉价的。有时候，可以通过创建附加的对象从而使得程序更清晰简洁。</p>
<h3 id="Item7-Eliminate-obsolete-object-references"><a href="#Item7-Eliminate-obsolete-object-references" class="headerlink" title="Item7: Eliminate obsolete object references"></a>Item7: Eliminate obsolete object references</h3><p>过期引用指的是永远也不会再被解除的引用。在Java这类支持垃圾回收的语言中，如果一个对象引用被无意识地保留起来了，那么垃圾回收机制不仅不会处理这个对象，而且连被这个对象所引用的其它对象也不会被处理。这样即便只有少量的几个对象引用被无意识保留下来，也会有许多对象被排除在垃圾回收机制之外，对性能造成潜在的重大影响。那如何解决这类问题？只需要在知道对象引用过期时，及时清空引用。只要是自己管理内存，就应该时时警惕内存泄漏问题。<br>内存泄漏的常见来源有：无意识的对象保持；缓存；监听器和其他回调。</p>
<h3 id="Item8-Avoid-finalizers-and-cleaners"><a href="#Item8-Avoid-finalizers-and-cleaners" class="headerlink" title="Item8: Avoid finalizers and cleaners"></a>Item8: Avoid finalizers and cleaners</h3><p>终结方法是不可预测的，常常是危险而且不必要的。Java9已经弃用了终结方法，但是许多Java库中还用着这种方法。Java9中用Cleaners代替了终结方法。Cleaners比终结方法稍安全，但是仍然不可预测，慢和不必要。<br>Finalizers和cleaners的缺点之一是它们不能保证被及时执行。注重时间的任务不应该由终结方法和清理方法来完成。不但不能保证终结方法和清理方法能够及时执行，甚至其能不能执行也不会有保证。所以，永远不能依赖终结方法和清理方法来更新持久状态。<br>使用终结方法和清理方法会有严重的性能损失。显式的终结方法通常与try-finally 结构结合起来使用，以确保及时终止。重要的准则是：除非是作为安全网，或者是为了终止非关键的本地资源，否则请不要使用终结方法和清理方法。</p>
<h3 id="Item9-Prefer-try-with-resources-to-try-finally"><a href="#Item9-Prefer-try-with-resources-to-try-finally" class="headerlink" title="Item9: Prefer try-with-resources to try-finally"></a>Item9: Prefer try-with-resources to try-finally</h3><p>操作一些必须被关闭的资源时，最好使用try-with-resources块而不是try-finally代码块，这样代码更短更清晰，而且生成的异常更有用。try-with-resources块使得正确编写操作必须关闭的资源的代码更加容易。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p> Effective Java, Third Edition -Bloch-2017<br> <a href="http://www.cnblogs.com/IcanFixIt/tag/Effective%20Java%20Third%20Edition/" target="_blank" rel="external">林本托的博客</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/17/effective-java-creating-and-destroying-objects/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-useful-links" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/17/useful-links/">Useful Links</a>
    </h1>
  

        
        <a href="/2018/01/17/useful-links/" class="archive-article-date">
  	<time datetime="2018-01-16T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-17</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#综合"><span class="toc-text">综合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linux"><span class="toc-text">Linux</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Programming-Language"><span class="toc-text">Programming Language</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#C"><span class="toc-text">C++</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#python"><span class="toc-text">python</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Java"><span class="toc-text">Java</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SQL"><span class="toc-text">SQL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Machine-Learning"><span class="toc-text">Machine Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Learning"><span class="toc-text">Deep Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Computer-Vision"><span class="toc-text">Computer Vision</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Object-Detection"><span class="toc-text">Object Detection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OpenCV"><span class="toc-text">OpenCV</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Courses"><span class="toc-text">Courses</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Github-Repo"><span class="toc-text">Github Repo</span></a></li></ol>
</div>

        <h2 id="综合"><a href="#综合" class="headerlink" title="综合"></a>综合</h2><p><a href="https://stackoverflow.com/" target="_blank" rel="external">Stackoverflow</a><br><a href="http://blog.csdn.net/golden1314521/article/details/45500843" target="_blank" rel="external">VirtualBox安装增强功能包实现资源共享</a><br><a href="https://mirrors.tuna.tsinghua.edu.cn/" target="_blank" rel="external">清华大学开源软件镜像站</a></p>
<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p><a href="https://github.com/QMonkey/wsl-tutorial" target="_blank" rel="external">wsl-tutorial</a><br><a href="https://superuser.com/questions/1111591/how-can-i-ssh-into-bash-on-ubuntu-on-windows-10/1114162#1114162" target="_blank" rel="external">ssh into wsl</a><br><a href="https://medium.com/@zoomyale/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E7%9A%84%E7%BB%88%E6%9E%81%E5%A7%BF%E5%8A%BF-%E5%9C%A8-vultr-vps-%E4%B8%8A%E6%90%AD%E5%BB%BA-shadowsocks-fd57c807d97e" target="_blank" rel="external">ss科学上网</a></p>
<h2 id="Programming-Language"><a href="#Programming-Language" class="headerlink" title="Programming Language"></a>Programming Language</h2><h3 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h3><p><a href="http://en.cppreference.com/w/" target="_blank" rel="external">cppreference</a><br><a href="https://google.github.io/styleguide/cppguide.html" target="_blank" rel="external">google cpp guide</a></p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p><a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy" target="_blank" rel="external">Python Extension Packages for Windows</a></p>
<h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><p><a href="https://docs.oracle.com/javase/8/docs/api/" target="_blank" rel="external">JavaSE API</a></p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p><a href="http://blog.csdn.net/wengengeng/article/details/52013650" target="_blank" rel="external">windows安装mysql-5.7压缩版详细教程</a></p>
<h2 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h2><h3 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h3><p><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="external">cs231n spring2017</a><br><a href="https://www.tensorflow.org/" target="_blank" rel="external">tensorflow</a><br><a href="http://pytorch.org/" target="_blank" rel="external">pytorch</a><br><a href="https://github.com/kjw0612/awesome-deep-vision" target="_blank" rel="external">Awesome Deep Vision</a><br><a href="https://github.com/tensorflow/models" target="_blank" rel="external">tensorflow model</a></p>
<h2 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h2><h3 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h3><p><a href="https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html" target="_blank" rel="external">Handong1587 Object Detection</a><br><a href="https://github.com/amusi/awesome-object-detection" target="_blank" rel="external">Awesome Object Detection</a></p>
<h3 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h3><p><a href="http://blog.csdn.net/youngpan1101/article/details/58027049" target="_blank" rel="external">Ubuntu 14.04 安装 OpenCV-3.2.0</a><br><a href="http://blog.csdn.net/column/details/photoshop-algorithm.html" target="_blank" rel="external">Photoshop图像处理算法</a></p>
<h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><p><a href="http://vision.stanford.edu/teaching/cs131_fall1718/syllabus.html" target="_blank" rel="external">CS131 Computer Vision: Foundations and Applications</a><br><a href="https://web.stanford.edu/class/cs20si/index.html" target="_blank" rel="external">CS 20: Tensorflow for Deep Learning Research</a><br><a href="http://courses.cms.caltech.edu/cs179/" target="_blank" rel="external">CS179 GPU Programming</a></p>
<h2 id="Github-Repo"><a href="#Github-Repo" class="headerlink" title="Github Repo"></a>Github Repo</h2><p><a href="https://github.com/ShuangXieIrene/ssds.pytorch" target="_blank" rel="external">ssds.pytorch</a><br><a href="https://github.com/QSCTech/zju-icicles" target="_blank" rel="external">浙江大学课程攻略共享计划</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">link</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/link//" class="article-tag-list-link color5">link</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/17/useful-links/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-effective-java-lambdas-and-streams" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/13/effective-java-lambdas-and-streams/">Effective Java-- Lambdas and Streams</a>
    </h1>
  

        
        <a href="/2018/01/13/effective-java-lambdas-and-streams/" class="archive-article-date">
  	<time datetime="2018-01-13T14:48:22.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-13</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Lambdas-in-Java"><span class="toc-text">Lambdas in Java</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduce"><span class="toc-text">Introduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Lambada-Expressions"><span class="toc-text">Lambada Expressions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method-References"><span class="toc-text">Method References</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Functional-Interfaces"><span class="toc-text">Functional Interfaces</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Java-Items-about-Lambdas"><span class="toc-text">Effective Java Items about Lambdas</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Item42-Prefer-lambdas-to-anonymous-classes"><span class="toc-text">Item42: Prefer lambdas to anonymous classes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item43-Prefer-method-references-to-lambdas"><span class="toc-text">Item43: Prefer method references to lambdas</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item44-Favor-the-use-of-standard-functional-interfaces"><span class="toc-text">Item44: Favor the use of standard functional interfaces</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Streams-in-Java"><span class="toc-text">Streams in Java</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduce-1"><span class="toc-text">Introduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Streams"><span class="toc-text">Streams</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#示例"><span class="toc-text">示例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Java-Items-about-Streams"><span class="toc-text">Effective Java Items about Streams</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Item45-Use-streams-judiciously"><span class="toc-text">Item45: Use streams judiciously</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item46-Prefer-side-effect-free-functions-in-streams"><span class="toc-text">Item46: Prefer side-effect-free functions in streams</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item47-Prefer-Collections-to-Streams-as-a-return-type"><span class="toc-text">Item47: Prefer Collections to Streams as a return type</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Item48-Use-caution-when-making-streams-parallel"><span class="toc-text">Item48: Use caution when making streams parallel</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <h1 id="Lambdas-in-Java"><a href="#Lambdas-in-Java" class="headerlink" title="Lambdas in Java"></a>Lambdas in Java</h1><h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><h3 id="Lambada-Expressions"><a href="#Lambada-Expressions" class="headerlink" title="Lambada Expressions"></a>Lambada Expressions</h3><p>lambda表达式的固定格式如下： parameter -&gt; expression body<br>一个lambda表达式有如下特点：可不声明参数类型，编译器会自动推导；单个参数无需加括号，多个参数必须加括号；单条语句无需加花括号；return关键词可省略。<br>参考：<br><a href="https://www.tutorialspoint.com/java8/java8_lambda_expressions.htm" target="_blank" rel="external">Lambda Expressions</a></p>
<h3 id="Method-References"><a href="#Method-References" class="headerlink" title="Method References"></a>Method References</h3><p>方法引用有助于按照名称指向方法。其使用“::”符号描述方法引用。方法引用可以用来指出以下类型的方法：静态方法;实例方法；使用new运算符的构造器方法。<br>大多数引用的是静态方法，但是也有一些其它情况，主要有以下几种类型的方法引用：<br><img src="method_ref_type.JPG" alt=""></p>
<p>参考：<br><a href="https://www.tutorialspoint.com/java8/java8_method_references.htm" target="_blank" rel="external">Method References</a></p>
<h3 id="Functional-Interfaces"><a href="#Functional-Interfaces" class="headerlink" title="Functional Interfaces"></a>Functional Interfaces</h3><p>functional interfaces有着一个特定的功能展示的作用。例如：使用单个方法 compareTo 的 Comparable接口来用于比较。<br>参考：<br><a href="https://www.tutorialspoint.com/java8/java8_functional_interfaces.htm" target="_blank" rel="external">Function Interfaces</a></p>
<h2 id="Effective-Java-Items-about-Lambdas"><a href="#Effective-Java-Items-about-Lambdas" class="headerlink" title="Effective Java Items about Lambdas"></a>Effective Java Items about Lambdas</h2><h3 id="Item42-Prefer-lambdas-to-anonymous-classes"><a href="#Item42-Prefer-lambdas-to-anonymous-classes" class="headerlink" title="Item42: Prefer lambdas to anonymous classes"></a>Item42: Prefer lambdas to anonymous classes</h3><pre><code>在支持lambda之前，Java中一般用匿名函数来实现函数对象这样的功能。比如：
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Anonymous class instance as a function object</span></div><div class="line"><span class="comment">//List&lt;String&gt; words=new ArrayList&lt;&gt;();</span></div><div class="line"><span class="comment">//words.add("JDIFA");</span></div><div class="line"><span class="comment">//words.add("fjiafja8fjiasfjias");</span></div><div class="line"><span class="comment">//words.add("jiaffjiafjiasf");</span></div><div class="line"><span class="comment">//words.add("jifaif3");</span></div><div class="line">words.sort(<span class="keyword">new</span> Comparator&lt;String&gt;() &#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(String s1,String s2)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> Integer.compare(s1.length(),s2.length());</div><div class="line">    &#125;</div><div class="line">&#125;);</div></pre></td></tr></table></figure>
<pre><code>而用lambda表达式可以这样写比较简洁：
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">words.sort((s1,s2)-&gt;Integer.compare(s1.length(),s2.length()));</div></pre></td></tr></table></figure>
<p>使用lambda表达式时，一般会省略参数的类型，因为编译器会进行自动推导类型。当编译器不能推导出类型时，需要我们显式指定。一个重要的原则就是：为了让lambda表达式更简洁，尽量省略参数类型。有时需要对返回值进行类型转换或者对整个lambda表达式进行类型转换，但是这比较少见。<br>和方法及类不同，lambda缺少名称和文档，如果一个运算不是很容易理解或者行数太多，那么就不要使用lambda表达式。<br>总而言之，目前而言，lambda表达式是表示小型函数对象的最佳方法。除非必须要创建非函数接口的类型实例，否则不要使用匿名类。</p>
<h3 id="Item43-Prefer-method-references-to-lambdas"><a href="#Item43-Prefer-method-references-to-lambdas" class="headerlink" title="Item43: Prefer method references to lambdas"></a>Item43: Prefer method references to lambdas</h3><p>lambda表达式相较于匿名类的主要优势就是其更简洁。然而Java提供了一种比lambda表达式更为简洁的生成函数对象的方法：方法引用(method references)。使用方法引用通常会生成更短更清晰的代码。但是也有例外的情况，使用的时候可以根据具体情况选择使用lambda还是方法引用。<br>一般而言，方法引用提供了一种比lambda表达式更为简洁的方法。总的使用原则就是：方法引用更为简洁时就使用它，否则使用lambda。</p>
<h3 id="Item44-Favor-the-use-of-standard-functional-interfaces"><a href="#Item44-Favor-the-use-of-standard-functional-interfaces" class="headerlink" title="Item44: Favor the use of standard functional interfaces"></a>Item44: Favor the use of standard functional interfaces</h3><p>Java有了lambda之后，我们在设计API的时候就有必要随时考虑lambda。既能接受functional interface类型作为输入也要能将其作为输出。通常情况下，最好使用java.util.function.Function中的标准接口，但是极少数情况下可能还是需要我们自己设计functional interfaces。<br>主要有如下一些使用原则：<br>1、优先使用标准functional interface<br>2、java.util.function中有43种接口类型，比较常用的有以下6种：<br><img src="interface_type.JPG" alt=""></p>
<p>3、多数标准functional interfaces只提供了对于基本类型的支持。不要试图用包装的基本类型来替代基本类型的functional interfaces。<br>4、使用 @FunctionalInterface注解来定义函数接口。</p>
<h1 id="Streams-in-Java"><a href="#Streams-in-Java" class="headerlink" title="Streams in Java"></a>Streams in Java</h1><h2 id="Introduce-1"><a href="#Introduce-1" class="headerlink" title="Introduce"></a>Introduce</h2><h3 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h3><p>streams表示来自源的一系列对象，其支持聚合操作，有以下特征：<br>1、元素序列：stream以顺序的方式提供一组特定类型的元素。其按需获取或者计算元素。其从不存储元素。<br>2、源：其将Collection, Array或者IO资源作为输入。<br>3、聚合操作：其支持聚合操作，如filter, map, limit, reduce, find, match等。<br>4、流水线：大多数stream操作本身返回stream，以使得其操作可以流水线话。collect()方法是在流水线操作结束时通常存在的终端操作，用于标记流的结束。<br>5、自动迭代：stream通过所提供的源元素在内部执行迭代，与需要显式迭代的集合相反。</p>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>可以用stream()或者parallelStream()方法生成Stream。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">List&lt;String&gt; strings = Arrays.asList(<span class="string">"abc"</span>, <span class="string">""</span>, <span class="string">"bc"</span>, <span class="string">"efg"</span>, <span class="string">"abcd"</span>,<span class="string">""</span>, <span class="string">"jkl"</span>);</div><div class="line">List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList());</div></pre></td></tr></table></figure></p>
<p>更多示例可参考：<br><a href="https://www.tutorialspoint.com/java8/java8_streams.htm" target="_blank" rel="external">Streams</a></p>
<h2 id="Effective-Java-Items-about-Streams"><a href="#Effective-Java-Items-about-Streams" class="headerlink" title="Effective Java Items about Streams"></a>Effective Java Items about Streams</h2><h3 id="Item45-Use-streams-judiciously"><a href="#Item45-Use-streams-judiciously" class="headerlink" title="Item45: Use streams judiciously"></a>Item45: Use streams judiciously</h3><p>Stream API用起来非常流畅，其就是设计来将一连串的方法调用连成一个管道作为一条语句。使用得当的话，streams能将程序变得更短更清晰，而使用不当会导致程序 很难阅读和理解。<br>总的来说，有些任务用stream的方法完成较好，有些任务用iteration的方式完成较好。许多任务可以用两种方式的组合来更好地完成。对于两种方式之间的选择，并没有特定的方法，还是需要根据实际情况决定。如果不能确定用哪种方式更好，索性两种方式都试一下并比较再做决定。<br>更多具体例子可参考书籍 Effective Java 3rd edition</p>
<h3 id="Item46-Prefer-side-effect-free-functions-in-streams"><a href="#Item46-Prefer-side-effect-free-functions-in-streams" class="headerlink" title="Item46: Prefer side-effect-free functions in streams"></a>Item46: Prefer side-effect-free functions in streams</h3><p>stream的本质是无副作用的函数对象，这适用于传递给stream的所有许多函数对象和相关的对象。每个终端操作只能用于报告由stream执行的计算的结果，而不执行计算。为了正确使用stream，我们必须熟悉collectors。最重要的收集器工厂是toList, toSet, toMap, groupingBy和joining。<br>一些使用原则：<br>1、forEach操作应该被用于报告stream的计算结果而不是执行计算。<br>2、为了使得使用stream的代码更具可读性，比较明智的做法是静态导入Collectors。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.util.stream.Collectors.*;</div></pre></td></tr></table></figure></p>
<h3 id="Item47-Prefer-Collections-to-Streams-as-a-return-type"><a href="#Item47-Prefer-Collections-to-Streams-as-a-return-type" class="headerlink" title="Item47: Prefer Collections to Streams as a return type"></a>Item47: Prefer Collections to Streams as a return type</h3><h3 id="Item48-Use-caution-when-making-streams-parallel"><a href="#Item48-Use-caution-when-making-streams-parallel" class="headerlink" title="Item48: Use caution when making streams parallel"></a>Item48: Use caution when making streams parallel</h3><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/" target="_blank" rel="external">Stream详解</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/13/effective-java-lambdas-and-streams/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-effective-java-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/13/effective-java-notes/">一些Java编码规范条款</a>
    </h1>
  

        
        <a href="/2018/01/13/effective-java-notes/" class="archive-article-date">
  	<time datetime="2018-01-13T02:22:21.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-13</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#记录一些Java编码条款，方便查看"><span class="toc-text">记录一些Java编码条款，方便查看</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Effective-Java（3rd-Edition）中的编码条款"><span class="toc-text">Effective Java（3rd Edition）中的编码条款</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Create-and-Destroying-Objects"><span class="toc-text">Create and Destroying Objects</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Mothods-Common-to-All-Objects"><span class="toc-text">Mothods Common to All Objects</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Classes-and-Interfaces"><span class="toc-text">Classes and Interfaces</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Generics"><span class="toc-text">Generics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Enums-and-Annotations"><span class="toc-text">Enums and Annotations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lambdas-and-Streams"><span class="toc-text">Lambdas and Streams</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Methods"><span class="toc-text">Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#General-Programming"><span class="toc-text">General Programming</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Exceptions"><span class="toc-text">Exceptions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Concurrency"><span class="toc-text">Concurrency</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Serialization"><span class="toc-text">Serialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol></li></ol></li></ol>
</div>

        <h1 id="记录一些Java编码条款，方便查看"><a href="#记录一些Java编码条款，方便查看" class="headerlink" title="记录一些Java编码条款，方便查看"></a>记录一些Java编码条款，方便查看</h1><h2 id="Effective-Java（3rd-Edition）中的编码条款"><a href="#Effective-Java（3rd-Edition）中的编码条款" class="headerlink" title="Effective Java（3rd Edition）中的编码条款"></a>Effective Java（3rd Edition）中的编码条款</h2><h3 id="Create-and-Destroying-Objects"><a href="#Create-and-Destroying-Objects" class="headerlink" title="Create and Destroying Objects"></a>Create and Destroying Objects</h3><p><a href="">Item1: Consider static factory methods instead of constructors</a><br><a href="">Item2: Consider a builder when faced with many constructors</a><br><a href="">Item3: Enforce the singleton property with a private constructor or an enum type</a><br><a href="">Item4: Enforce noninstantiability with a private constructor</a><br><a href="">Item5: Prefer dependency injection to hardwiring resources</a><br><a href="">Item6: Avoid creating unnecessary objects</a><br><a href="">Item7: Eliminate absolete object references</a><br><a href="">Item8: Avoid finalizers and cleaners</a><br><a href="">Item9: Prefer try-with-resources to try-finally</a></p>
<h3 id="Mothods-Common-to-All-Objects"><a href="#Mothods-Common-to-All-Objects" class="headerlink" title="Mothods Common to All Objects"></a>Mothods Common to All Objects</h3><p><a href="">Item10: Obey the general construct when overriding equals</a><br><a href="">Item11: Always override hashCode when you override equals</a><br><a href="">Item12: Always override toString</a><br><a href="">Item13: Override clone judiciously</a><br><a href="">Item14: Consider implementing Comparable</a></p>
<h3 id="Classes-and-Interfaces"><a href="#Classes-and-Interfaces" class="headerlink" title="Classes and Interfaces"></a>Classes and Interfaces</h3><p><a href="">Item15: Minimize the accessibility of classes and members</a><br><a href="">Item16: In public classes, use accessor methods, not public fields</a><br><a href="">Item17: Minimize mutability</a><br><a href="">Item18: Favor composition over inheritance</a><br><a href="">Item19: Design and document for inheritance or else prohibit it</a><br><a href="">Item20: Prefer interfaces to abstract classes</a><br><a href="">Item21: Design interfaces for posterity</a><br><a href="">Item22: Use interfaces only to define types</a><br><a href="">Item23: Prefer class hierarchies to tagged classes</a><br><a href="">Item24: Favor static member classes over nonstatic</a><br><a href="">Item25: Limit source fields to a single top-level class</a></p>
<h3 id="Generics"><a href="#Generics" class="headerlink" title="Generics"></a>Generics</h3><p><a href="">Item26: Don’t use raw types</a><br><a href="">Item27: Eliminate unchecked warnings</a><br><a href="">Item28: Prefer lists to arrays</a><br><a href="">Item29: Favor generic types</a><br><a href="">Item30: Favor generic methods</a><br><a href="">Item31: Use bounded wildcards to increase API flexibility</a><br><a href="">Item32: Combine generics and varargs judiciously</a><br><a href="">Item33: Consider typesafe heterogeneous containers</a></p>
<h3 id="Enums-and-Annotations"><a href="#Enums-and-Annotations" class="headerlink" title="Enums and Annotations"></a>Enums and Annotations</h3><p><a href="">Item34: Use enums instead of int constants</a><br><a href="">Item35: Use instance fields instead of ordinals</a><br><a href="">Item36: Use EnumSet instead of bit fields</a><br><a href="">Item37: Use EnumMap instead of ordinal indexing</a><br><a href="">Item38: Emulate extensible enums with interfaces</a><br><a href="">Item39: Prefer annotations to naming patterns</a><br><a href="">Item40: Consistently use the Override annotation</a><br><a href="">Item41: Use marker interfaces to define types</a></p>
<h3 id="Lambdas-and-Streams"><a href="#Lambdas-and-Streams" class="headerlink" title="Lambdas and Streams"></a>Lambdas and Streams</h3><p><a href="">Item42: Prefer lambdas to anonymous classes</a><br><a href="">Item43: Prefer method reference to lambdas</a><br><a href="">Item44: Favor the use of standard functional interfaces</a><br><a href="">Item45: Use streams judiciously</a><br><a href="">Item46: Prefer side-effect-free functions in streams</a><br><a href="">Item47: Prefer Collections to Stream as a return type</a><br><a href="">Item48: Use caution when making streams parallel</a></p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p><a href="">Item49: Check parameters for validity</a><br><a href="">Item50: Make defensive copies when needed</a><br><a href="">Item51: Design method signatures carefully</a><br><a href="">Item52: Use overloading judiciously</a><br><a href="">Item53: Use varargs</a><br><a href="">Item54: Return empty collections or arrays, not nulls</a><br><a href="">Item55: Return optionals judiciously</a><br><a href="">Item56: Write doc comments for all exposed API elements</a></p>
<h3 id="General-Programming"><a href="#General-Programming" class="headerlink" title="General Programming"></a>General Programming</h3><p><a href="">Item57: Minimize the scope of local variables</a><br><a href="">Item58: Prefer for-each loops to traditional for loops</a><br><a href="">Item59: Know and use the libraries</a><br><a href="">Item60: Avoid float and double if exact answers are required</a><br><a href="">Item61: Prefer primitive types to boxed primitives</a><br><a href="">Item62: Avoid strings where other types are more appropriate</a><br><a href="">Item63: Beware the performance of string concatenation</a><br><a href="">Item64: Refer to objects by their interfaces</a><br><a href="">Item65: Prefer interfaces to reflection</a><br><a href="">Item66: Use native methods judiciously</a><br><a href="">Item67: Optimize judiciously</a><br><a href="">Item68: Adhere to generally accepted naming conventions</a></p>
<h3 id="Exceptions"><a href="#Exceptions" class="headerlink" title="Exceptions"></a>Exceptions</h3><p><a href="">Item69: Use exceptions only for exceptional conditions</a><br><a href="">Item70: Use checked exceptions for recoverable conditions and runtime exceptions for programming errors</a><br><a href="">Item71: Avoid unnecessary use of checked exceptions</a><br><a href="">Item72: Favor the use of standard exceptions</a><br><a href="">Item73: Throw exceptions appropriate to the abstraction</a><br><a href="">Item74: Document all exceptions thrown by each method</a><br><a href="">Item75: Include failure-capture information in detail messages</a><br><a href="">Item76: Strive for failure atomicity</a><br><a href="">Item77: Don’t ignore exceptions</a></p>
<h3 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h3><p><a href="">Item78: Synchronize access to shared mutable data</a><br><a href="">Item79: Avoid excessive synchronization</a><br><a href="">Item80: Prefer executors, tasks, and streams to threads</a><br><a href="">Item81: Prefer concurrency utilities to wait and notify</a><br><a href="">Item82: Document thread safety</a><br><a href="">Item83: Use lazy initialization judiciously</a><br><a href="">Item84: Don’t depend on the thread scheduler</a></p>
<h3 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h3><p><a href="">Item85: Prefer alternatives to Java serialization</a><br><a href="">Item86: Implement Serializable with great caution</a><br><a href="">Item87: Consider using a custom serialized form</a><br><a href="">Item88: Write readObject methods defensively</a><br><a href="">Item89: For instance control, prefer enum types to readResolve</a><br><a href="">Item90: Consider serialization proxies instead of serialized instances</a></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><pre><code>Effective Java, Third Edition
</code></pre>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/13/effective-java-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-java-settings" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/10/java-settings/">java-settings</a>
    </h1>
  

        
        <a href="/2018/01/10/java-settings/" class="archive-article-date">
  	<time datetime="2018-01-10T02:09:08.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-10</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#配置Java项目时的一些方法"><span class="toc-text">配置Java项目时的一些方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#maven指定JDK版本"><span class="toc-text">maven指定JDK版本</span></a></li></ol></li></ol>
</div>

        <h1 id="配置Java项目时的一些方法"><a href="#配置Java项目时的一些方法" class="headerlink" title="配置Java项目时的一些方法"></a>配置Java项目时的一些方法</h1><h2 id="maven指定JDK版本"><a href="#maven指定JDK版本" class="headerlink" title="maven指定JDK版本"></a>maven指定JDK版本</h2><p>在pom.xml中如下配置<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.9<span class="tag">&lt;/<span class="name">source</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.9<span class="tag">&lt;/<span class="name">target</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></div></pre></td></tr></table></figure></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/10/java-settings/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-java-programming-language-notes" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/01/09/java-programming-language-notes/">Java语言程序设计-第10版notes</a>
    </h1>
  

        
        <a href="/2018/01/09/java-programming-language-notes/" class="archive-article-date">
  	<time datetime="2018-01-09T12:25:35.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-01-09</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Java语言程序设计第10版notes"><span class="toc-text">Java语言程序设计第10版notes</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#第1章-计算机、程序和Java概述"><span class="toc-text">第1章 计算机、程序和Java概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第2章-基本程序设计"><span class="toc-text">第2章 基本程序设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-1"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第3章-选择"><span class="toc-text">第3章 选择</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-2"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第4章-数学函数、字符和字符串"><span class="toc-text">第4章 数学函数、字符和字符串</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-3"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第6章-方法"><span class="toc-text">第6章 方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-4"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第7章-一维数组"><span class="toc-text">第7章 一维数组</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-5"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第9章-对象和类"><span class="toc-text">第9章 对象和类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-6"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第10章-面向对象思考"><span class="toc-text">第10章 面向对象思考</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-7"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第11章-继承和多态"><span class="toc-text">第11章 继承和多态</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-8"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第12章-异常处理和文本IO"><span class="toc-text">第12章 异常处理和文本IO</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-9"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第13章-抽象类和接口"><span class="toc-text">第13章 抽象类和接口</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-10"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第19章-泛型"><span class="toc-text">第19章 泛型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-11"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第30章-多线程和并行程序设计"><span class="toc-text">第30章 多线程和并行程序设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-12"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#第31章-网络"><span class="toc-text">第31章 网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#部分章节小结-13"><span class="toc-text">部分章节小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=434052443&auto=1&height=66"></iframe></p>
<h1 id="Java语言程序设计第10版notes"><a href="#Java语言程序设计第10版notes" class="headerlink" title="Java语言程序设计第10版notes"></a>Java语言程序设计第10版notes</h1><h2 id="第1章-计算机、程序和Java概述"><a href="#第1章-计算机、程序和Java概述" class="headerlink" title="第1章 计算机、程序和Java概述"></a>第1章 计算机、程序和Java概述</h2><h3 id="部分章节小结"><a href="#部分章节小结" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、编程错误可以分为三类：语法错误、运行时错误和逻辑错误。编译器报告的错误称为语法错误或者编译错误；运行时错误指引起程序非正常结束的错误；而当一个程序没有按照预期的方式执行时，产生逻辑错误 。</p>
<h2 id="第2章-基本程序设计"><a href="#第2章-基本程序设计" class="headerlink" title="第2章 基本程序设计"></a>第2章 基本程序设计</h2><h3 id="部分章节小结-1"><a href="#部分章节小结-1" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、拓宽类型不需要显式转换，缩窄类型必须显式完成。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//拓宽类型转换</span></div><div class="line"><span class="keyword">int</span> i=<span class="number">9</span>;</div><div class="line"><span class="keyword">double</span> d=i;</div><div class="line"><span class="comment">//缩窄类型转换</span></div><div class="line"><span class="keyword">double</span> d=<span class="number">9.0</span>;</div><div class="line"><span class="keyword">int</span> i=(<span class="keyword">int</span>)d;</div></pre></td></tr></table></figure></p>
<p>2、计算机科学中，1970年1月1日午夜零点为UNIX时间戳。</p>
<h2 id="第3章-选择"><a href="#第3章-选择" class="headerlink" title="第3章 选择"></a>第3章 选择</h2><h3 id="部分章节小结-2"><a href="#部分章节小结-2" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、除开赋值操作符的所有二元操作符都是左结合的，赋值操作符是右结合的。(此处的结合指的是结合律)<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//以下两个表达等价</span></div><div class="line">a-b+c-d</div><div class="line">((a-b)+c)-d</div><div class="line"><span class="comment">//以下两个表达等价</span></div><div class="line">a=b+=c=<span class="number">5</span></div><div class="line">a=(b+=(c=<span class="number">5</span>))</div></pre></td></tr></table></figure></p>
<h2 id="第4章-数学函数、字符和字符串"><a href="#第4章-数学函数、字符和字符串" class="headerlink" title="第4章 数学函数、字符和字符串"></a>第4章 数学函数、字符和字符串</h2><h3 id="部分章节小结-3"><a href="#部分章节小结-3" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、字符 ‘ ‘ 、\t、 \f、 \r 和 \n 都称为空白字符。<br>2、字符可以基于它们的Unicode码使用关系操作符进行比较。</p>
<h2 id="第6章-方法"><a href="#第6章-方法" class="headerlink" title="第6章 方法"></a>第6章 方法</h2><h3 id="部分章节小结-4"><a href="#部分章节小结-4" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、程序模块化和可重用性是软件工程的中心目标之一。<br>2、方法可以重载，这意味着两个方法可以拥有相同的方法名，只要它们的参数列表不同即可。<br>3、方法抽象是把方法的应用和实现分离，用户可以在不知道方法是如何实现的情况下使用方法。方法的实现细节封装在方法内，对调用该方法的用户隐藏。这称为信息隐藏或封装。<br>4、方法抽象将程序模块化为整齐、层次分明的形式。将程序写成简洁的方法构成的集合会比其他方式更容易编写、调试、维护和修改。这种编写风格也会提高方法的可重用性。<br>5、当实现一个大型程序时，可以使用自顶向下或者自底向上的编码方法。不要一次性编写完整个程序。这种方式似乎浪费了更多的编码时间(因为要反复编译和运行这个程序)，但实际上，它会节省时间并使得调试更为容易。</p>
<h2 id="第7章-一维数组"><a href="#第7章-一维数组" class="headerlink" title="第7章 一维数组"></a>第7章 一维数组</h2><h3 id="部分章节小结-5"><a href="#部分章节小结-5" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、创建数组时推荐使用 elementType[] arrayRefVar风格<br>2、不同于基本数据类型变量的声明，声明数组变量并不会给数组分配任何空间。数组变量不是基本数据类型变量。数组变量包含的是对数组的引用。<br>3、将数组参数传递给方法时，实际上传递的是数组的引用；更准确地说，被调用的方法可以修改调用者的原始数组的元素。<br>4、数组初始化语法：<br>        elementType[] arrayRefVar={value0,value1,…,valuek};</p>
<h2 id="第9章-对象和类"><a href="#第9章-对象和类" class="headerlink" title="第9章 对象和类"></a>第9章 对象和类</h2><h3 id="部分章节小结-6"><a href="#部分章节小结-6" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、类是一种数据类型。可以用它声明对象引用变量。对象引用变量中似乎存放了一个对象，但是事实上，它包含的只是对该对象的引用。严格来说，对象引用变量和对象是不同的，但是大多数情况下，它们的区别是可以忽略的。<br>2、所有传递给方法的参数都是值传递的，对于基本类型的参数，传递的是实际值；而如果参数是引用数据类型，则传递的是对象的引用。</p>
<h2 id="第10章-面向对象思考"><a href="#第10章-面向对象思考" class="headerlink" title="第10章 面向对象思考"></a>第10章 面向对象思考</h2><h3 id="部分章节小结-7"><a href="#部分章节小结-7" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、面向过程范式重在设计方法。面向对象范式将数据和方法耦合在对象中。使用面向对象范式的软件设计重在对象和对象的操作。面向对象方法结合了面向过程范式的功能以及将数据和操作集成在对象中的特点。<br>2、许多Java方法要求使用对象作为参数。Java提供了一个便捷的方法，将基本数据类型合并或包装到一个对象中。<br>3、Java可以根据上下文自动地将基本类型值转换到对应的包装对象，反之亦然。</p>
<h2 id="第11章-继承和多态"><a href="#第11章-继承和多态" class="headerlink" title="第11章 继承和多态"></a>第11章 继承和多态</h2><h3 id="部分章节小结-8"><a href="#部分章节小结-8" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、构造方法可以调用重载的构造方法或者它的父类的构造方法。这种调用必须是构造方法的第一条语句。如果没有显示地调用它们中的任何一个，编译器就会把super()作为构造方法的第一条语句，它调用的是父类的无参构造方法。<br>2、实例方法只有在可访问时才能重写。这样，私有方法是不能重写的，因为它是不能在类本身之外访问的。如果子类中定义的方法在父类中是私有的，那么这两个方法是完全没有关系的。<br>3、Java中的每个类都继承自java.lang.Object类。<br>4、如果一个方法的参数类型是父类,可以向该方法的参数传递任何子类的对象。这称为多态。<br>5、因为子类的实例总是它的父类的实例。所以，总是可以将一个子类的实例转化成一个父类的变量。当把父类实例转换成它的子类变量时，必须使用转换记号(子类名)进行显式转换，向编译器表明你的意图。<br>6、当从引用变量调用实例方法时，该变量的实际类型在运行时决定使用该方法的哪个实现。这称为动态绑定。</p>
<h2 id="第12章-异常处理和文本IO"><a href="#第12章-异常处理和文本IO" class="headerlink" title="第12章 异常处理和文本IO"></a>第12章 异常处理和文本IO</h2><h3 id="部分章节小结-9"><a href="#部分章节小结-9" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、Java异常是扩展自java.lang.Throwable的类的实例。Java本身提供大量预定义的异常类，当然也可以通过扩展Exception类来定义自己的异常类。<br>2、异常发生在一个方法的执行过程中。RuntimeException和Error都是免检异常，所有其他的异常都是必检的。<br>3、声明异常的关键字是throws,而抛出异常的关键字是throw。<br>4、如果调用声明了必检异常的方法，必须将该方法调用放在try语句中。在方法执行过程中出现异常时，catch块会捕获并处理异常。<br>5、如果一个异常没有被当前方法捕获，则该异常被传给调用者。这个过程不断重复直到异常被捕获或者传递给main方法。<br>6、在catch块中，异常的指定顺序是非常重要的。如果在指定一个类的异常对象之前，指定了这个异常类的父类的异常对象，就会导致一个编译错误。<br>7、当方法中发生异常时，如果异常没有被捕获，方法将会立刻退出。如果想在方法退出前执行一些任务，可以在方法中捕获这个异常，然后再重新抛给它的调用者。<br>8、任何情况下都会执行finally块中的代码，不管try块中是否出现了异常，或者出现后是否捕获了该异常。</p>
<h2 id="第13章-抽象类和接口"><a href="#第13章-抽象类和接口" class="headerlink" title="第13章 抽象类和接口"></a>第13章 抽象类和接口</h2><h3 id="部分章节小结-10"><a href="#部分章节小结-10" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、抽象类和常规类一样，都有数据和方法，但是不能用new操作符创建抽象类的实例。<br>2、非抽象类中不能包含抽象方法。如果抽象类的子类中没有实现所有被继承的父类抽象方法，就必须将该子类也定义为抽象类。<br>3、包含抽象方法的类必须是抽象类。但是抽象类可以不包含抽象的方法。<br>4、即使父类是具体的，子类也可以是抽象的。<br>5、接口是一种与类相似的结构，只包含常量和抽象方法。接口在许多方面与抽象类很相近，但抽象类除了包含常量和抽象方法外，还可以包含变量和具体方法。<br>6、在 Java 中，接口被认为是一种特殊的类。就像常规类一样，每个接口都被编译为独立的字节码文件。<br>7、接口java.lang.Comparable定义了compareTo方法。Java类库中的许多类都实现了 Comparable。<br>8、接口 java.lang.Cloneable 是一个标记接口。实现Cloneable接口的类的对象是可克隆的。<br>9、个类仅能继承一个父类，但一个类却可以实现一个或多个接口。<br>10、一个接口可以继承一个或多个接口。</p>
<h2 id="第19章-泛型"><a href="#第19章-泛型" class="headerlink" title="第19章 泛型"></a>第19章 泛型</h2><h3 id="部分章节小结-11"><a href="#部分章节小结-11" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、泛型具有参数化类型的能力。可以定义使用泛型类型的类或方法，编译器会用具体类型来替代泛型类型。<br>2、泛型的主要优势是能够在编译时而不是运行时检测错误。<br>3、泛型类或者方法允许指定这个类或者方法可以带有的对象类型。如果试图使用带有不兼容对象的类或者方法，编译器会检测出这个错误。<br>4、定义在类、接口或者静态方法中的泛型称为形式泛型类型，随后可以用一个实际具体类型来替换它。替换泛型类型的过程称为泛型实例化。<br>5、不使用类型参数的泛型类称为原始类型，例如ArrayList。使用原始类型是为了向后兼容Java较早的版本。<br>6、通配泛型类型有三种形式：?、? extends T 和 ? super T,这里的T代表一个泛型类型。第一种形式?称为非受限通配，它和 ? extends Object是一样的。第二种形式 ? extends T 称为受限通配，代表T 或者T的一个子类型。第三种类型 ? super T 称为下限通配，表示T或者T的一个父类型。<br>7、使用称为类型消除的方法来实现泛型。编译器使用泛型类型信息来编译代码，但是随后消除它。因此，泛型信息在运行时是不可用的。这个方法能够使泛型代码向后兼容使用原始类型的遗留代码。<br>8、不能使用泛型类型参数来创建实例。<br>9、不能使用泛型类型参数来创建数组。<br>10、不能再静态环境中使用类的泛型类型参数。<br>11、在异常类中不能使用泛型类型参数。</p>
<h2 id="第30章-多线程和并行程序设计"><a href="#第30章-多线程和并行程序设计" class="headerlink" title="第30章 多线程和并行程序设计"></a>第30章 多线程和并行程序设计</h2><h3 id="部分章节小结-12"><a href="#部分章节小结-12" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、每个任务都是Runnable接口的实例。线程就是一个便于任务执行的对象。可以通过实现Runnable接口来定义任务类，通过使用Thread构造方法包住一个任务来创建线程。<br>2、一个线程对象被创建后，可以使用start()方法启动线程，可以使用sleep(long)方法将线程转入休眠状态，以便其它线程获得运行的机会。<br>3、线程对象从来不会直接调用run方法。到了执行某个线程的时候，Java虚拟机调用run方法。类必须覆盖run方法，告诉系统线程运行时将会做什么。<br>4、为了避免线程破坏共享资源，可以使用同步的方法或块。同步方法在执行前需要获得一个锁。当同步方法是实例方法时，锁是 在调用方法的对象上；当同步方法是静态(类)方法时，锁是在方法所在的类上。<br>5、在执行方法中某个代码块时，可以使用同步语句获得任何对象上的锁，而不仅是this对象上的锁。这个代码称为同步块。<br>6、可以使用显式锁和条件，以及对象的内置监视器来便于进程之间的通信。<br>7、Java集合框架提供的阻塞队列(ArrayBlockingQueue,LinkedBlockingQueue,PriorityBlockingQueue)自动地同步对队列的访问。<br>8、可以使用信号量来限制访问共享资源的并行任务数量。<br>9、如果两个或更多的线程获取多个对象上的锁时，每个线程都有一个对象上的锁并等待另一个对象上的锁，这时就有可能发生死锁现象。使用资源排序技术可以避免死锁。<br>10、JDK7的Fork/Join框架被设计用于开发并行程序。可以定义一个继承自RecursiveAction或者RecursiveTask的任务类，在ForkJoinPool中并行执行任务类，并在所有任务执行完后得到整体的解答。</p>
<h2 id="第31章-网络"><a href="#第31章-网络" class="headerlink" title="第31章 网络"></a>第31章 网络</h2><h3 id="部分章节小结-13"><a href="#部分章节小结-13" class="headerlink" title="部分章节小结"></a>部分章节小结</h3><p>1、Java支持流套接字和数据报套接字。流套接字用TCP(传输控制协议)来进行数据传输，而数据报套接字用UDP(用户数据报协议)。由于TCP协议检测丢失的传输并且重新提交它们，所以，传输是无损和可靠的。相反地，UDP不能保证传输是无损的。<br>2、要创建一个服务器，必须先使用语句new ServerSocket(port)获取一个服务器套接字。在创建服务器套接字后，可以启动服务器，使用服务器套接字上的accept()方法监听连接请求。客户端使用new Socket(serverName,port)来创建一个客户端套接字，用于向服务器发送连接请求。<br>3、当服务器与客户端的连接建立后，流套接字通信与输入输出流通信非常相似。可以通过套接字上的getInputStream() 方法获得一个输入流，通过getOutputStream()方法获得一个输出流。<br>4、一个服务器经常同时与多个客户端协同工作。通过为每个连接创建一个线程，可以利用线程同时处理服务器的多个客户端。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>Java语言程序设计（基础篇 原书第10版）<br>Java语言程序设计（进阶篇 原书第10版）<br><img src="javadev.png" alt=""></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/01/09/java-programming-language-notes/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-SQL" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/07/SQL/">SQL使用</a>
    </h1>
  

        
        <a href="/2017/12/07/SQL/" class="archive-article-date">
  	<time datetime="2017-12-07T13:43:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-12-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Windows下MySQL配置"><span class="toc-text">Windows下MySQL配置</span></a></li></ol>
</div>

        <h2 id="Windows下MySQL配置"><a href="#Windows下MySQL配置" class="headerlink" title="Windows下MySQL配置"></a>Windows下MySQL配置</h2><p><a href="http://blog.csdn.net/wengengeng/article/details/52013650" target="_blank" rel="external">MySQL配置</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">sql</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/sql//" class="article-tag-list-link color4">sql</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/12/07/SQL/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-yolo_details" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/01/yolo_details/">YOLO Object Detection</a>
    </h1>
  

        
        <a href="/2017/12/01/yolo_details/" class="archive-article-date">
  	<time datetime="2017-11-30T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-12-01</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#YOLO"><span class="toc-text">YOLO</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#论文链接"><span class="toc-text">论文链接</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分析"><span class="toc-text">分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#YOLO-1"><span class="toc-text">YOLO</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#YOLO9000-YOLOv2"><span class="toc-text">YOLO9000(YOLOv2)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Better"><span class="toc-text">Better</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#传统YOLO缺陷"><span class="toc-text">传统YOLO缺陷</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YOLOv2相对YOLO的改进"><span class="toc-text">YOLOv2相对YOLO的改进</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Batch-Normalization"><span class="toc-text">Batch Normalization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#High-Resolution-Classifier"><span class="toc-text">High Resolution Classifier</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Convolutional-With-Anchor-Boxes"><span class="toc-text">Convolutional With Anchor Boxes</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#和YOLO相比的性能"><span class="toc-text">和YOLO相比的性能</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Dimension-Clusters"><span class="toc-text">Dimension Clusters</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Direct-Location-Prediction"><span class="toc-text">Direct Location Prediction</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Fine-Grained-Features"><span class="toc-text">Fine-Grained Features</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Multi-Scale-Training"><span class="toc-text">Multi-Scale Training</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Further-Experiments"><span class="toc-text">Further Experiments</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Faster"><span class="toc-text">Faster</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stronger"><span class="toc-text">Stronger</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#YOLOv3"><span class="toc-text">YOLOv3</span></a></li></ol></li></ol>
</div>

        <h1 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h1><h2 id="论文链接"><a href="#论文链接" class="headerlink" title="论文链接"></a>论文链接</h2><p><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100173" target="_blank" rel="external">YOLO9000:Better, Faster, Stronger</a><br><a href="https://arxiv.org/pdf/1709.05943.pdf" target="_blank" rel="external">Fast YOLO: A Fast You Only Look Once System for Real-time Embedded Object Detection in Video</a><br><a href="https://pjreddie.com/media/files/papers/yolo.pdf" target="_blank" rel="external">You Only Look Once:Unified, Real-Time Object Detection</a><br><a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="external">YOLOv3</a></p>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><h2 id="YOLO-1"><a href="#YOLO-1" class="headerlink" title="YOLO"></a>YOLO</h2><p><a href="https://zhuanlan.zhihu.com/p/25045711" target="_blank" rel="external">YOLO论文解读</a></p>
<h2 id="YOLO9000-YOLOv2"><a href="#YOLO9000-YOLOv2" class="headerlink" title="YOLO9000(YOLOv2)"></a>YOLO9000(YOLOv2)</h2><p><a href="https://zhuanlan.zhihu.com/p/25052190" target="_blank" rel="external">YOLO9000论文解读</a></p>
<h3 id="Better"><a href="#Better" class="headerlink" title="Better"></a>Better</h3><h4 id="传统YOLO缺陷"><a href="#传统YOLO缺陷" class="headerlink" title="传统YOLO缺陷"></a>传统YOLO缺陷</h4><p>Significant number of localization errors compared to Fast-RCNN<br>Low recall compared to region proposal-based mothods</p>
<h4 id="YOLOv2相对YOLO的改进"><a href="#YOLOv2相对YOLO的改进" class="headerlink" title="YOLOv2相对YOLO的改进"></a>YOLOv2相对YOLO的改进</h4><h5 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h5><p>adding  batch normalization on all of the convolutional layers in YOLO<br>2% improvement in mAP<br>then we can remove dropout without overfitting</p>
<h5 id="High-Resolution-Classifier"><a href="#High-Resolution-Classifier" class="headerlink" title="High Resolution Classifier"></a>High Resolution Classifier</h5><p>increase of almost 4% mAP</p>
<h5 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a>Convolutional With Anchor Boxes</h5><p>remove fully connected layers from YOLO and use anchor boxes to predict bounding boxes.<br>eliminate one pooling layer to make the output of the network’s convolutional layers higher resolution.<br>shrink the network to operate on 416x416 input images instead of 448x448。这样使得输出的feature map大小为13x13,代替原来的14x14使得中心只有一个。</p>
<h6 id="和YOLO相比的性能"><a href="#和YOLO相比的性能" class="headerlink" title="和YOLO相比的性能"></a>和YOLO相比的性能</h6><p>mAP: 69.5-&gt;69.2<br>recall: 81%-&gt;88%</p>
<h5 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a>Dimension Clusters</h5><p>使用k-means自动挑选box的尺寸代替原来YOLO方案的手动挑选尺寸。</p>
<h5 id="Direct-Location-Prediction"><a href="#Direct-Location-Prediction" class="headerlink" title="Direct Location Prediction"></a>Direct Location Prediction</h5><p>YOLO使用anchor boxes的过程中会遇到模型不稳定的问题。通过改变预测box位置的方法改进。<br>Using dimension clusters along with directly predicting the bounding box center location improves YOLO by almost 5% over the version with anchor boxes.</p>
<h5 id="Fine-Grained-Features"><a href="#Fine-Grained-Features" class="headerlink" title="Fine-Grained Features"></a>Fine-Grained Features</h5><p>This gives a modest 1% performance increase.</p>
<h5 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h5><p>由于模型只有卷积层和池化层，我们可以随意调整大小。 Every 10 batches our network randomly chooses new image dimensions。</p>
<h5 id="Further-Experiments"><a href="#Further-Experiments" class="headerlink" title="Further Experiments"></a>Further Experiments</h5><p><img src="compare.png" alt="The path from YOLO to YOLOv2"></p>
<h3 id="Faster"><a href="#Faster" class="headerlink" title="Faster"></a>Faster</h3><h3 id="Stronger"><a href="#Stronger" class="headerlink" title="Stronger"></a>Stronger</h3><h2 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cv//" class="article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/12/01/yolo_details/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cs179notes-1" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/23/cs179notes-1/">cs179notes_1</a>
    </h1>
  

        
        <a href="/2017/11/23/cs179notes-1/" class="archive-article-date">
  	<time datetime="2017-11-23T14:32:31.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-11-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#useful-links"><span class="toc-text">useful links</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture1"><span class="toc-text">lecture1</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU-Central-Processing-Unit"><span class="toc-text">CPU(Central Processing Unit)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU-Graphics-Processing-Unit"><span class="toc-text">GPU(Graphics Processing Unit)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么要用GPU-GPU的优势"><span class="toc-text">为什么要用GPU?(GPU的优势)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GPU与CPU在上下文切换上的差异"><span class="toc-text">GPU与CPU在上下文切换上的差异</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#在GPU上可以这样实现"><span class="toc-text">在GPU上可以这样实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GPU的计算步骤"><span class="toc-text">GPU的计算步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#编程举例"><span class="toc-text">编程举例</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#内核代码"><span class="toc-text">内核代码</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CPU上调用内核的代码"><span class="toc-text">CPU上调用内核的代码</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GPU的历史"><span class="toc-text">GPU的历史</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture2-More-Basics"><span class="toc-text">lecture2 More Basics</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#线程组织形式-Thread-Organization"><span class="toc-text">线程组织形式(Thread Organization)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#关键词"><span class="toc-text">关键词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU内部构造"><span class="toc-text">GPU内部构造</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture3"><span class="toc-text">lecture3</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#并行问题"><span class="toc-text">并行问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非并行问题"><span class="toc-text">非并行问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture4-GPU-Memory-Systems"><span class="toc-text">lecture4 GPU Memory Systems</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NVIDIA-Architecture-Names"><span class="toc-text">NVIDIA Architecture Names</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#延迟和吞吐量-Latency-and-Throughput"><span class="toc-text">延迟和吞吐量(Latency and Throughput)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#计算和IO吞吐量-Compute-and-IO-Throughput"><span class="toc-text">计算和IO吞吐量(Compute and IO Throughput)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#缓存-Cache"><span class="toc-text">缓存(Cache)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU内存"><span class="toc-text">GPU内存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Registers"><span class="toc-text">Registers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Local-Memory"><span class="toc-text">Local Memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Global-Memory"><span class="toc-text">Global Memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shared-Memory"><span class="toc-text">Shared Memory</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#静态方式"><span class="toc-text">静态方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#动态方式"><span class="toc-text">动态方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#案例分析"><span class="toc-text">案例分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#计算强度-Computational-Intensity"><span class="toc-text">计算强度(Computational Intensity)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#内核中的常见模式"><span class="toc-text">内核中的常见模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Bank-Conflicts"><span class="toc-text">Bank Conflicts</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Register-spilling"><span class="toc-text">Register spilling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#"><span class="toc-text"> </span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#L1-Cache"><span class="toc-text">L1 Cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#L2-Cache"><span class="toc-text">L2 Cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Constant-Memory"><span class="toc-text">Constant Memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Texture-Memory"><span class="toc-text">Texture Memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Read-Only-Cache-CC-3-5"><span class="toc-text">Read-Only Cache(CC 3.5)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture5-GPU-Compute-Programming"><span class="toc-text">lecture5 GPU Compute Programming</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Warp调度"><span class="toc-text">Warp调度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GK110-Kepler-numbers"><span class="toc-text">GK110(Kepler) numbers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#占用率"><span class="toc-text">占用率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#同步"><span class="toc-text">同步</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#lecture6-同步、共享内存、矩阵转置"><span class="toc-text">lecture6 同步、共享内存、矩阵转置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#同步-1"><span class="toc-text">同步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#需要同步的例子"><span class="toc-text">需要同步的例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#syncthreads"><span class="toc-text">__syncthreads()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#原子指令：动机"><span class="toc-text">原子指令：动机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用建议"><span class="toc-text">使用建议</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#warp-synchronous-programming"><span class="toc-text">warp-synchronous programming</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Warp-shuffle"><span class="toc-text">Warp shuffle</span></a></li></ol></li></ol></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=439915614&auto=1&height=66"></iframe></p>
<h1 id="useful-links"><a href="#useful-links" class="headerlink" title="useful links"></a>useful links</h1><p><a href="http://courses.cms.caltech.edu/cs179/" target="_blank" rel="external">cs179</a><br><a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" target="_blank" rel="external">cuda c programming guide</a></p>
<h1 id="lecture1"><a href="#lecture1" class="headerlink" title="lecture1"></a>lecture1</h1><h2 id="CPU-Central-Processing-Unit"><a href="#CPU-Central-Processing-Unit" class="headerlink" title="CPU(Central Processing Unit)"></a>CPU(Central Processing Unit)</h2><p>传统上，应用程序使用CPU作为主服务器计算，它有如下特点：<br>•通用功能<br>•建立技术<br>•通常配备8个或更少的强大的核心<br>•对于并发进程是最佳的，但不是大规模的并行计算</p>
<h2 id="GPU-Graphics-Processing-Unit"><a href="#GPU-Graphics-Processing-Unit" class="headerlink" title="GPU(Graphics Processing Unit)"></a>GPU(Graphics Processing Unit)</h2><p>为并行化问题设计的相对较新的技术。<br>•最初专为图形创建<br>•成为更有能力的一般计算</p>
<h3 id="为什么要用GPU-GPU的优势"><a href="#为什么要用GPU-GPU的优势" class="headerlink" title="为什么要用GPU?(GPU的优势)"></a>为什么要用GPU?(GPU的优势)</h3><p>举例，对于两个数组相加的操作。在CPU上这样实现：</p>
<p>串行实现<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">float</span> *C=<span class="built_in">malloc</span>(N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;N;++i)&#123;</div><div class="line">    C[i]=A[i]+B[i];</div><div class="line">&#125;</div><div class="line"><span class="keyword">return</span> C;</div></pre></td></tr></table></figure></p>
<p>更好一点可以使用并行实现。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">(allocate memory for C)</div><div class="line">Create # of threads equal to number of cores on processor</div><div class="line">(around 2, 4, perhaps 8)</div><div class="line">(Indicate portions of A, B, C to each thread...)</div><div class="line">...</div><div class="line">In each thread,</div><div class="line">For (i from beginning region of thread)</div><div class="line">C[i] &lt;- A[i] + B[i]</div><div class="line">//lots of waiting involved for memory reads, writes, ...</div><div class="line">Wait for threads to synchronize...</div><div class="line">This is slightly faster – 2-8x (slightly more with other tricks)</div></pre></td></tr></table></figure>
<p>但是这带来一些问题：能用多少个线程？如何扩展程序性能？实际上，在CPU上允许的最大线程数量比较少。</p>
<h4 id="GPU与CPU在上下文切换上的差异"><a href="#GPU与CPU在上下文切换上的差异" class="headerlink" title="GPU与CPU在上下文切换上的差异"></a>GPU与CPU在上下文切换上的差异</h4><p>CPU与GPU架构的一个主要区别就是CPU与GPU映射寄存器的方式。CPU通过使用寄存器重命名和栈来执行多线程。为了运行一个新任务，CPU需要进行上下文切换，当前所有寄存器的状态保存到栈上，然后从栈中恢复当前需要执行的新线程上次的执行状态。而这些操作通常要花费上百个CPU时钟周期，所以如果在CPU中开启过多的线程，时间几乎都将花在上下文切换过程中寄存器内容的换进换出上。<br>然而，GPU却恰恰相反，GPU利用多线程隐藏了内存获取与指令执行带来的延迟，因此，在GPU上开启过少的线程反而会因为等待内存事务而使得GPU处于闲置状态。另外，GPU也不实用寄存器重命名的机制，而是致力于为每一个线程都分配真实的寄存器，因此，当需要上下文切换时，所需要的操作就是将指向当前寄存器组的选择器(或者指针)更新，以指向下一个执行的线程束的寄存器组，因此几乎就是零开销。</p>
<h4 id="在GPU上可以这样实现"><a href="#在GPU上可以这样实现" class="headerlink" title="在GPU上可以这样实现"></a>在GPU上可以这样实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">(allocate memory <span class="keyword">for</span> A, B, C on GPU)</div><div class="line">Create the “kernel” – <span class="function">each thread will perform <span class="title">one</span> <span class="params">(<span class="keyword">or</span> a few)</span></span></div><div class="line"><span class="function">additions</span></div><div class="line">Specify the following kernel operation:</div><div class="line">For all i‘s (indices) assigned to <span class="keyword">this</span> thread:</div><div class="line">C[i] &lt;- A[i] + B[i]</div><div class="line">Start ~<span class="number">20000</span> (!) threads</div><div class="line">Wait <span class="keyword">for</span> threads to synchronize...</div></pre></td></tr></table></figure>
<p>GPU的优势在于：强调并行性意味着我们有很多核心。这允许我们同时运行多个线程而没有上下文切换。</p>
<h4 id="GPU的计算步骤"><a href="#GPU的计算步骤" class="headerlink" title="GPU的计算步骤"></a>GPU的计算步骤</h4><p>• Setup inputs on the host (CPU-accessible memory)<br>• Allocate memory for outputs on the host<br>• Allocate memory for inputs on the GPU<br>• Allocate memory for outputs on the GPU<br>• Copy inputs from host to GPU<br>• Start GPU kernel<br>• Copy output from GPU to host</p>
<p>值得注意的是：数据的复制过程可以是异步的。</p>
<h4 id="编程举例"><a href="#编程举例" class="headerlink" title="编程举例"></a>编程举例</h4><h5 id="内核代码"><a href="#内核代码" class="headerlink" title="内核代码"></a>内核代码</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">cudaAddVectorsKernel</span><span class="params">(<span class="keyword">float</span>* a,<span class="keyword">float</span>* b,<span class="keyword">float</span>* c)</span></span>&#123;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> index=blockIdx.x*blockDim.x+threadIdx.x;</div><div class="line">    c[index]=a[index]+b[index];</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="CPU上调用内核的代码"><a href="#CPU上调用内核的代码" class="headerlink" title="CPU上调用内核的代码"></a>CPU上调用内核的代码</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">cudaAddVectors</span><span class="params">(<span class="keyword">const</span> <span class="keyword">float</span>* a,<span class="keyword">const</span> <span class="keyword">float</span>* b,<span class="keyword">float</span>* c,size)</span></span>&#123;</div><div class="line">    <span class="keyword">float</span>* dev_a;</div><div class="line">    <span class="keyword">float</span>* dev_b;</div><div class="line">    <span class="keyword">float</span>* dev_c;</div><div class="line"></div><div class="line">    cudaMalloc((<span class="keyword">void</span>**) &amp;dev_a,size*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</div><div class="line">    cudaMemcpy(dev_a,a,size*<span class="keyword">sizeof</span>(<span class="keyword">float</span>),cudaMemcpyHostToDevice);</div><div class="line"></div><div class="line">    cudaMalloc((<span class="keyword">void</span>**) &amp;dev_b,size*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</div><div class="line">    cudaMemcpy(dev_b,b,size*<span class="keyword">sizeof</span>(<span class="keyword">float</span>),cudaMemcpyHostToDevice);</div><div class="line"></div><div class="line">    cudaMalloc((<span class="keyword">void</span>**) &amp;dev_c,size*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</div><div class="line"></div><div class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> threadsPerBlock=<span class="number">512</span>;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> blocks=<span class="built_in">ceil</span>(size/<span class="keyword">float</span>(threadsPerBlock));</div><div class="line">    cudaAddVectorsKernel&lt;&lt;&lt;blocks,threadsPerBlock&gt;&gt;&gt;(dev_a,dev_b,dev_c);</div><div class="line"></div><div class="line">    cudaMemcpy(c,dev_c,size*<span class="keyword">sizeof</span>(<span class="keyword">float</span>),cudaMemcpyDeviceToHost);</div><div class="line"></div><div class="line">    cudaFree(dev_a);</div><div class="line">    cudaFree(dev_b);</div><div class="line">    cudaFree(dev_c);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="GPU的历史"><a href="#GPU的历史" class="headerlink" title="GPU的历史"></a>GPU的历史</h4><h1 id="lecture2-More-Basics"><a href="#lecture2-More-Basics" class="headerlink" title="lecture2 More Basics"></a>lecture2 More Basics</h1><h2 id="线程组织形式-Thread-Organization"><a href="#线程组织形式-Thread-Organization" class="headerlink" title="线程组织形式(Thread Organization)"></a>线程组织形式(Thread Organization)</h2><h3 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h3><p>线程(Thread)<br>块(Block)<br>网格(Grid)<br>流形多处理器(Streaming Multiprocessor)<br>Warp<br>Warp Divergence</p>
<h3 id="GPU内部构造"><a href="#GPU内部构造" class="headerlink" title="GPU内部构造"></a>GPU内部构造</h3><p>把Device Memory(也叫Global Memory)当做GPU里的RAM。它比实际的RAM快速，而且还可以更快。<br>GPU有着许多SMs,其中每一个SM有多个处理器，但是只有一个指令单元(instruction unit)。SM中的一个处理器组在一定时间内必须运行完全相同的指令。<br>当内核被调用时，一个任务被分为多个线程，每个线程控制整个任务的某个部分。这些线程被分成一个个网格块(a Grid of Blocks)。Grids和Blocks都有三个维度。然而我们经常使用一个维度的Grids和Blocks。</p>
<p>每个block的最大线程数量是512或者1024，具体取决于机器型号。每个Grid的Block数目通常是65525个。当超过了这些限制之后会使得GPU出现问题。</p>
<p>每个block和一个SM对应。在SM内部，block被分成线程的Warps。每个Warp包含32个线程，这里面的每个线程在同一时刻必须执行完全相同的指令(因为这里只有一个指令单元)。一个SM中的Warps是并行的。如果想要在一个Warp中的线程运行不同的指令，这两个任务将会按照顺序执行，这种现象叫做Warp Divergence。</p>
<h1 id="lecture3"><a href="#lecture3" class="headerlink" title="lecture3"></a>lecture3</h1><h2 id="并行问题"><a href="#并行问题" class="headerlink" title="并行问题"></a>并行问题</h2><h2 id="非并行问题"><a href="#非并行问题" class="headerlink" title="非并行问题"></a>非并行问题</h2><p>并不是所有的问题都是并行问题。GPU用来计算并行问题，对于非并行问题，直接用CPU计算。</p>
<h1 id="lecture4-GPU-Memory-Systems"><a href="#lecture4-GPU-Memory-Systems" class="headerlink" title="lecture4 GPU Memory Systems"></a>lecture4 GPU Memory Systems</h1><h2 id="NVIDIA-Architecture-Names"><a href="#NVIDIA-Architecture-Names" class="headerlink" title="NVIDIA Architecture Names"></a>NVIDIA Architecture Names</h2><p><a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="external">cuda-gpus</a></p>
<h2 id="延迟和吞吐量-Latency-and-Throughput"><a href="#延迟和吞吐量-Latency-and-Throughput" class="headerlink" title="延迟和吞吐量(Latency and Throughput)"></a>延迟和吞吐量(Latency and Throughput)</h2><p>延迟是由硬件的物理速度造成的延迟。<br>CPU有着低延迟低吞吐量。CPU clock 3GHz,main memory latency:~100ns,arithmetic instruction latency:~1+ns</p>
<p>GPU有着高延迟和高吞吐量。GPU clock 1GHz,main memory latency:~300+ns,arithmetic instruction latency:~10+ns。这些参数针对 Kepler GPUs(例如GTX 700)。对于 Fermi,吞吐量大概是其两倍。</p>
<h2 id="计算和IO吞吐量-Compute-and-IO-Throughput"><a href="#计算和IO吞吐量-Compute-and-IO-Throughput" class="headerlink" title="计算和IO吞吐量(Compute and IO Throughput)"></a>计算和IO吞吐量(Compute and IO Throughput)</h2><p>IO往往是吞吐量的性能瓶颈，所以需要好的IO策略。如果象牙超过900GFLOPS,则需要执行多个FLOP共享内存负载。</p>
<h2 id="缓存-Cache"><a href="#缓存-Cache" class="headerlink" title="缓存(Cache)"></a>缓存(Cache)</h2><p>缓存是位于更大的内存池和处理器之间的一块内存,它通常在硬件级别实现，具有比它更大的内存池更快的访问速度。当请求内存时，请求的内存附近的额外内存被读入一个缓存，读取的数量是缓存和内存池特定的。始终缓存在一起的内存区域称为缓存行，这使未来访问可能在缓存中找到。这种访问被称为缓存命中并允许更快的访问，如果在在缓存中找不到访问，则称为缓存未命中（显然没有性能增益）。</p>
<h2 id="GPU内存"><a href="#GPU内存" class="headerlink" title="GPU内存"></a>GPU内存</h2><h3 id="Registers"><a href="#Registers" class="headerlink" title="Registers"></a>Registers</h3><p>寄存器是处理器直接使用的一块内存。我们希望尽可能使用最快的内存，寄存器的速度大概是共享内存的10倍。每个SM中有着数以万计的寄存器。通常每个线程最多可以有32或者64个32位的寄存器。在内核中声明的大多数堆栈变量都存储在寄存器中。存储在堆栈中的静态索引数组有时被放入寄存器中。</p>
<h3 id="Local-Memory"><a href="#Local-Memory" class="headerlink" title="Local Memory"></a>Local Memory</h3><p>本地内存是堆栈中不能被寄存器容纳的所有内容。本地内存的范围只是线程，本地内存存储在全局内存中，比寄存器慢得多。</p>
<h3 id="Global-Memory"><a href="#Global-Memory" class="headerlink" title="Global Memory"></a>Global Memory</h3><p>Global Memory是独立于GPU内核的硬件(包含SM，高速缓存，等)。GPU上绝大部分内存都是全局内存，如果数据不适合全局内存，则将以块处理它使得它适合全局内存。GPU有着0.5-24GB的全局内存，现在的设备大多在2GB左右。全局内存的延时在Kepler上大约300ns,在Fermi上大约600ns。<br>全局内存的IO是GPU上的IO中最慢的(当然对主机内存的通信IO更慢)。由于这个原因，我们希望能够尽可能少访问全局内存。与GPU硬件搭配得很好的访问模式被称为合并内存访问。合并内存访问能够最大限度减少读入的缓存行数量。GPU高速缓存线是128字节并对齐。内存合并在现实中其实复杂得多。</p>
<h3 id="Shared-Memory"><a href="#Shared-Memory" class="headerlink" title="Shared Memory"></a>Shared Memory</h3><p>共享内存是SM中非常快的内存。和L1级缓存的硬件相同，大概5ns的延迟。最大容量为48KB，是用户可配置的。共享内存的范围是block。<br>共享内存的分配可以通过静态和动态两种方式进行。</p>
<h4 id="静态方式"><a href="#静态方式" class="headerlink" title="静态方式"></a>静态方式</h4><p><strong>shared</strong>  float data[1024];<br>在内核中定义，在主机代码中不用做任何处理。</p>
<h4 id="动态方式"><a href="#动态方式" class="headerlink" title="动态方式"></a>动态方式</h4><p>Host:<br>kernel&lt;&lt;<grid_dim,block_dim,numbytesshmem>&gt;&gt;(args);<br>Device:<br>extern <strong>shared</strong> float s[];<br>定义多个动态大小的变量可以参考<br><a href="https://devblogs.nvidia.com/parallelforall/using-shared-memory-cuda-cc/" target="_blank" rel="external">using shared memory cuda cc</a></grid_dim,block_dim,numbytesshmem></p>
<h4 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h4><p>任务：计算字节频率计数<br>输入：长度为n的字节数组<br>输出：存储每个数字出现次数的长度为256的数组</p>
<p>简单方法：在全局内存建立输出，n个全局存储空间。<br>聪明方法：在共享内存中构建输出，并复制到全局内存中，最终需要256个全局存储空间。</p>
<h4 id="计算强度-Computational-Intensity"><a href="#计算强度-Computational-Intensity" class="headerlink" title="计算强度(Computational Intensity)"></a>计算强度(Computational Intensity)</h4><p>计算强度是必须在单个数据点（FLOPs / IO）上完成的操作数的一种表示。通常和复杂度的大O表示方法一致。<br>如果计算强度大于1，那么相同的数据不止用来计算一次。实践中我们需要尽可能多的共享负载和尽可能少的全局负载。</p>
<h4 id="内核中的常见模式"><a href="#内核中的常见模式" class="headerlink" title="内核中的常见模式"></a>内核中的常见模式</h4><p>1、将数据从全局内存拷贝到共享内存<br>2、__syncthreads()<br>3、运行计算，并递增地将运行结果存储在共享内存中，如果必要还需进行线程同步。<br>4、将输出从共享内存拷贝到全局内存。</p>
<h4 id="Bank-Conflicts"><a href="#Bank-Conflicts" class="headerlink" title="Bank Conflicts"></a>Bank Conflicts</h4><p>共享内存被设置为32个bank,如果将共享内存划分为4个字节长的元素，则元素i的位置将在第i%32个bank。当同一个Warp中的两个线程访问同一个bank中的不同元素时将发生bank conflicts。这种冲突将导致串行存储器访问而不是并行访问。在GPU编程中串行任何内容都对性能不利。</p>
<h3 id="Register-spilling"><a href="#Register-spilling" class="headerlink" title="Register spilling"></a>Register spilling</h3><p>It costs:<br>1 extra load<br>1 extra store<br>2 extra pairs of consecutive dependent instructions</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h3 id="L1-Cache"><a href="#L1-Cache" class="headerlink" title="L1 Cache"></a>L1 Cache</h3><p>Fermi-caches local&amp; global memory<br>Kepler,Maxwell -only caches local momory<br>same hardware as shared momory<br>configurale size(16,32,48KB)<br>each SM has its own L1 cache</p>
<h3 id="L2-Cache"><a href="#L2-Cache" class="headerlink" title="L2 Cache"></a>L2 Cache</h3><p>caches all global and local memory accesses<br>about 1MB in size<br>shared by all SMs</p>
<h3 id="Constant-Memory"><a href="#Constant-Memory" class="headerlink" title="Constant Memory"></a>Constant Memory</h3><p>常量内存是具有特殊缓存的全局内存，用于不能编译成程序的常量，运行内核之前必须从主机设置常量，用户为64KB，编译器为64KB,内核参数通过常量内存传递。<br>用法：<br>在全局范围内(内核之外，程序的顶层)：<br><strong>constant</strong> in foo[1024];<br>主机代码：<br>cudaMemcpyToSymbol(foo,h_src,sizeof(int)*1024);</p>
<h3 id="Texture-Memory"><a href="#Texture-Memory" class="headerlink" title="Texture Memory"></a>Texture Memory</h3><p>对于通用计算来说，复杂而且只有很小的用处<br>有用的特点：<br>●通过“CUDA阵列”进行缓存的二维或三维数据位置,进入特殊的纹理缓存。<br>●在1D，2D或3D阵列上进行快速插补<br>●将整数转换为“单位”浮点数<br>用例：<br>(1)通过纹理缓存和CUDA数组读取输入数据来利用空间缓存,这是最常见的用例。<br>(2)通过纹理缓存和CUDA数组读取输入数据来利用。<br>(3)利用数字纹理功能。<br>(4)与OpenGL和一般计算机图形学的交互。</p>
<h3 id="Read-Only-Cache-CC-3-5"><a href="#Read-Only-Cache-CC-3-5" class="headerlink" title="Read-Only Cache(CC 3.5)"></a>Read-Only Cache(CC 3.5)</h3><p>许多CUDA程序不使用纹理，但是我们应该利用纹理缓存硬件。CC&gt;=3.5 使得使用纹理缓存更加容易。许多const限制变量将自动通过纹理缓存加载(也称为只读缓存)。也可以使用__ldg内部函数强制加载缓存。其和常量内存不同，因为不需要静态索引。</p>
<h1 id="lecture5-GPU-Compute-Programming"><a href="#lecture5-GPU-Compute-Programming" class="headerlink" title="lecture5 GPU Compute Programming"></a>lecture5 GPU Compute Programming</h1><h2 id="Warp调度"><a href="#Warp调度" class="headerlink" title="Warp调度"></a>Warp调度</h2><p>warp调度程序找到一个准备好执行下一个指令和可执行的warp核心，然后开始执行<br>GK110：每个SM中有4个调度程序，2个调度程序每个时钟最多4次启动指令，并在每个经纱中启动最多2条指令。</p>
<h2 id="GK110-Kepler-numbers"><a href="#GK110-Kepler-numbers" class="headerlink" title="GK110(Kepler) numbers"></a>GK110(Kepler) numbers</h2><p>max threads/SM=2048(64warps)<br>max threads/block=1024(32warps)<br>32bit registers /SM=64KB<br>max shared memory /SM=48KB<br>值得注意的是：在一个SM上同时运行的块的数量取决于该资源的需求块。</p>
<h2 id="占用率"><a href="#占用率" class="headerlink" title="占用率"></a>占用率</h2><p>occupancy=warps per SM / max warps per SM<br>max warps /SM depends only on GPU<br>warps /SM depends on warps /block, registers/block, shared momory/block。</p>
<h2 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h2><p>在CPU上，可以使用锁，信号量，条件变量等来解决同步问题。在GPU上，这些解决方案引入了太多的内存和处理开销。其实我们有更简单的解决方案更适合并行程序。我们使用__syncthreads()函数来同步块内的线程◦但是只能在块级别运行，因为SMs是彼此分开的，所以做不到比这更好。类似于C/C++中的barrier()函数。</p>
<h1 id="lecture6-同步、共享内存、矩阵转置"><a href="#lecture6-同步、共享内存、矩阵转置" class="headerlink" title="lecture6 同步、共享内存、矩阵转置"></a>lecture6 同步、共享内存、矩阵转置</h1><h2 id="同步-1"><a href="#同步-1" class="headerlink" title="同步"></a>同步</h2><p>并行的理想状态：线程之间无资源共享，无通讯。许多只需要一点点共享资源的算法仍然能够通过大规模的并行计算来实现。</p>
<h3 id="需要同步的例子"><a href="#需要同步的例子" class="headerlink" title="需要同步的例子"></a>需要同步的例子</h3><p>1、并行BFS<br>2、计算列表之和<br>3、向GPU的共享内存载入数据</p>
<h3 id="syncthreads"><a href="#syncthreads" class="headerlink" title="__syncthreads()"></a>__syncthreads()</h3><p>作用是同步一个block中的所有线程。值得注意的是：共享内存是在每个block之内共享。Every block that is launched will have to allocate shared memory for its own itself on its resident SM。__synchthreads()方法对于内核共享内存很有用。</p>
<h3 id="原子指令：动机"><a href="#原子指令：动机" class="headerlink" title="原子指令：动机"></a>原子指令：动机</h3><p>一个原子指令作为一个基本单元，不能被打断。序列化访问。<br>CUDA上的原子指令：<br>atomic{Add, Sub, Exch, Min, Max, Inc, Dec, CAS, And, Or, Xor}<br>Syntax: atomicAdd(float* address, float val)<br>在全局内存和共享内存都起作用。</p>
<h3 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h3><p>做更多的便宜操作和做更少的复杂操作。<br>举例：计算列表的和。<br>Naive方法：每个线程以原子方式递增每个数字到全局内存中的累加器。<br>更聪明的方法是：<br>.每个线程在寄存器中计算自己那部分的和。<br>.利用warp shuffle来计算跨越warp的和。<br>.每个warp以原子方式递增和到全局内存中的累加器。<br>.将原子操作的数量减少32倍。(32为每个warp的线程数)。</p>
<h3 id="warp-synchronous-programming"><a href="#warp-synchronous-programming" class="headerlink" title="warp-synchronous programming"></a>warp-synchronous programming</h3><p>怎样能够使得warp中的各个线程同步呢？实际上，warp中的各个线程已经是同步的。这样可以减少__syncthreads()方法的调用次数。</p>
<h3 id="Warp-shuffle"><a href="#Warp-shuffle" class="headerlink" title="Warp shuffle"></a>Warp shuffle</h3><p>从warp中的另一个线程读取寄存器的值。<br>int __shfl(int val,int srcLane, int width=warpSize)<br>对于计算整个warp的和极其有用。First avalible on Kepler(no Fermi, only CC&gt;=3.0)</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">cuda</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cuda//" class="article-tag-list-link color5">cuda</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/11/23/cs179notes-1/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-motion-detection" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/27/motion-detection/">motion-detection</a>
    </h1>
  

        
        <a href="/2017/10/27/motion-detection/" class="archive-article-date">
  	<time datetime="2017-10-27T11:10:02.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-27</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Background-Subtraction"><span class="toc-text">Background Subtraction</span></a></li></ol>
</div>

        <pre><code>主要介绍一些关于运动物体检测的算法。
</code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、<a href="http://developex.com/blog/motion-detection-and-objects-tracking-algorithm-implementation/" target="_blank" rel="external">blog:Motion detection and objects tracking algorithm implementation</a><br>2、<a href="https://en.wikipedia.org/wiki/Background_subtraction#cite_note-Bouwmans1-10" target="_blank" rel="external">wiki:Background_subtraction</a><br>3、<a href="https://en.wikipedia.org/wiki/Optical_flow" target="_blank" rel="external">wiki:Optical_flow</a></p>
<h1 id="Background-Subtraction"><a href="#Background-Subtraction" class="headerlink" title="Background Subtraction"></a>Background Subtraction</h1><p>1、<a href="https://arxiv.org/abs/1702.01731" target="_blank" rel="external">paper: A Deep Convolutional Neural Network for Background Subtraction</a><br>2、<a href="https://github.com/SaoYan/bgsCNN" target="_blank" rel="external">bgsCNN</a><br>3、<a href="https://github.com/andrewssobral/bgslibrary" target="_blank" rel="external">bgslibrary</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cv//" class="article-tag-list-link color3">cv</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/27/motion-detection/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-software-installation" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/18/software-installation/">常用软件安装及配置</a>
    </h1>
  

        
        <a href="/2017/10/18/software-installation/" class="archive-article-date">
  	<time datetime="2017-10-18T08:02:30.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  
</div>

        <p>1、<strong>cmder安装及配置</strong><br><a href="http://xiaogliu.github.io/2017/04/07/install-and-configure-cmder/" target="_blank" rel="external">cmder安装及配置教程</a><br>2、<strong>Virtual Box安装</strong><br><a href="http://blog.csdn.net/u012732259/article/details/70172704" target="_blank" rel="external">virtual box 安装教程</a><br>3、<strong>腾讯视频qlv格式转mp4</strong><br>打开缓存文件夹，管理员方式运行cmd，到tdl文件目录下，输入 copy/b *.tdl videoname.mp4 即可得到mp4格式视频文件。<br>4、<strong>tensorboard不能正常使用</strong><br>tensorboard —logdir=”dir” —host=127.0.0.1 即可正常使用<br>5、<strong>ssh into wsl</strong><br>使用ssh登录本机wsl。<br><a href="https://superuser.com/questions/1111591/how-can-i-ssh-into-bash-on-ubuntu-on-windows-10/1114162#1114162" target="_blank" rel="external"></a><br>6、<strong>使用LaTex添加公式到Hexo博客里</strong><br><a href="https://www.jianshu.com/p/68e6f82d88b7" target="_blank" rel="external">配置链接</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/18/software-installation/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-RNN" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/18/RNN/">RNN</a>
    </h1>
  

        
        <a href="/2017/10/18/RNN/" class="archive-article-date">
  	<time datetime="2017-10-18T02:46:11.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#主要介绍一些关于RNN的知识"><span class="toc-text">主要介绍一些关于RNN的知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一些教程链接"><span class="toc-text">一些教程链接</span></a></li></ol></li></ol>
</div>

        <h1 id="主要介绍一些关于RNN的知识"><a href="#主要介绍一些关于RNN的知识" class="headerlink" title="主要介绍一些关于RNN的知识"></a>主要介绍一些关于RNN的知识</h1><h2 id="一些教程链接"><a href="#一些教程链接" class="headerlink" title="一些教程链接"></a>一些教程链接</h2><p><a href="https://zybuluo.com/hanbingtao/note/541458" target="_blank" rel="external">零基础入门深度学习-循环神经网络</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/18/RNN/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-Object-Detection" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/11/Object-Detection/">Object Detection with CNN</a>
    </h1>
  

        
        <a href="/2017/10/11/Object-Detection/" class="archive-article-date">
  	<time datetime="2017-10-10T16:00:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-11</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  
</div>

        <p>主要介绍一些利用卷积神经网络的方法进行目标检测的方法。<br>网上有很多关于这些方法的详细介绍。以下是一些blog或者slide的链接。<br><a href="https://zhuanlan.zhihu.com/p/21412911" target="_blank" rel="external">基于深度学习的目标检测研究进展</a><br><a href="http://deeplearning.csail.mit.edu/instance_ross.pdf" target="_blank" rel="external">slide1</a><br><a href="http://blog.csdn.net/myarrow/article/details/51878004" target="_blank" rel="external">cs231n学习笔记-CNN-目标检测、定位、分割</a><br><a href="https://www.zhihu.com/question/57403701" target="_blank" rel="external">知乎 如何评价Mask-RCNN</a><br><a href="http://www.yuthon.com/2017/04/27/Notes-From-Faster-R-CNN-to-Mask-R-CNN/" target="_blank" rel="external">Notes: From Faster R-CNN to Mask R-CNN</a><br><a href="https://zhuanlan.zhihu.com/p/26655034" target="_blank" rel="external">CNN图像分割进化史：三年从R-CNN到Mask R-CNN</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/11/Object-Detection/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cnn-architecture" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/09/cnn-architecture/">常用卷积神经网络结构</a>
    </h1>
  

        
        <a href="/2017/10/09/cnn-architecture/" class="archive-article-date">
  	<time datetime="2017-10-09T05:52:17.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-09</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AlexNet"><span class="toc-text">AlexNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#VGGNet"><span class="toc-text">VGGNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GoogleNet"><span class="toc-text">GoogleNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ResNet"><span class="toc-text">ResNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#代码实现"><span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=423104954&auto=1&height=66"></iframe><br>主要介绍几种当前常见的卷积网络结构。包括AlexNet,VGGNet,GoogleNet,ResNet等。</p>
<h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p>AlexNet结构获得了2012年ILSVRC的冠军。其主要结构如下,这是cs231n的课件做的一个总结：<br><img src="alex_net.jpg" alt=""></p>
<h1 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h1><p>VGGNet是2014年ILSVRC的分类第二名，和AlexNet相比的改进是滤波器的尺寸更小，只用3x3的滤波器；还有就是更深的网络结果。具体如下；<br><img src="vgg_net.jpg" alt=""></p>
<p>用3x3的滤波器的原因：3个3x3的卷积层的组合的effective of field和一个7x7的卷积层是一致的。并且还有以下两个优点：1、网络更深，引入更多非线性；<br>2、引入更少的参数，对于每层C个通道的结构，3层3x3的参数个数为 3<em>3</em>3<em>C</em>C=27<em>C</em>C,而1个7x7的参数为7<em>7</em>C<em>C=49</em>C*C。<br>下面是对参数的一个分析,可见占用内存最多的层是在前面的卷积层，而拥有参数最多的层在最后的全连接层：<br><img src="vgg16_parameters.jpg" alt=""></p>
<h1 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h1><p>GoogleNet结构获得2014年ILSVRC的分类第一名。它具有更深的网络结构，达到22层，但是采用了更高效的计算。<br><img src="google_net.jpg" alt=""><br>它的最大的一个亮点是采用Inception module的结构。<br><img src="naive_inception_module.jpg" alt=""><br>从前一层开始并行计算4种不同类型和参数的网络层，在depth上叠加得到输出。但是这带来一个比较大的问题就是计算量太大，因为卷积层和池化层都会保留depth,所以每个并行的层都会带来整个输出的depth的增加。这个问题的一个解决方法就是使用更小深度的1x1的卷积层来减少深度。<br><img src="naive_inception_computation.jpg" alt=""><br><img src="1x1_conv.jpg" alt=""><br>最后得到的优化的Inception module结构如下：<br><img src="inception_dimension_reduction.jpg" alt=""><br>于是整个GoogleNet就以多个Inception小模块为基础搭建而成。GoogleNet还有另外一个亮点是摒弃了计算量巨大的FC层。<br><img src="full_googlenet.jpg" alt=""></p>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p>ResNet结构获得了2015年ILSVRC的第一名。它的最大亮点就是采用了残差学习的新思想。它将输入的结果加到通过普通网络层的输出上形成新的输出。这样使得训练很深的网络结构变得有效。<br><img src="resnet.jpg" alt=""><br>这个方法解决了之前的一个很大的问题，事实上，在这之前，如果我们将网络层数增加到特别深的情况下，其性能是会变差的，但是并不是由过拟合造成的，而是因为太深的网络结构难以优化。<br>而这个残差网络就能很好解决难以优化的问题。<br><img src="compare.jpg" alt=""><br>这样一来整个网络结构就如下所示：<br><img src="full_resnet.jpg" alt=""><br>对于比较深的网络，还应采用类似GoogleNet的1x1的”bottleneck” layer来提高网络的计算效率。<br><img src="resnet_bottlelayer.jpg" alt=""></p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>主要是基于tensorflow的一些实现。<br><a href="https://github.com/tensorflow/models" target="_blank" rel="external">tensorflow models</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf" target="_blank" rel="external">cs231n spring2017 lecture9 slides</a><br><a href="http://deeplearning.csail.mit.edu/cvpr2017_tutorial_kaiminghe.pdf" target="_blank" rel="external">cvpr2017_tutorial_kaiminghe</a><br><a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="external">AlexNet</a><br><a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="external">GoogleNet</a><br><a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="external">VGGNet</a><br><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">ResNet</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/09/cnn-architecture/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-python" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/08/python/">Python使用问题</a>
    </h1>
  

        
        <a href="/2017/10/08/python/" class="archive-article-date">
  	<time datetime="2017-10-08T02:28:53.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-08</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Python3"><span class="toc-text">Python3</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#cPickle"><span class="toc-text">cPickle</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ubuntu下为python3-5安装pip3-5"><span class="toc-text">ubuntu下为python3.5安装pip3.5</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#在linux下可以通过设置PYTHONPATH的方法指定python工程目录"><span class="toc-text">在linux下可以通过设置PYTHONPATH的方法指定python工程目录</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#UnicodeDecodeError-‘utf-8’-codec-can’t-decode-byte-0xff-in-position-0-invalid-start-byte"><span class="toc-text">UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#在windows下编译pyc文件时，运行setup-py文件提示找不到cl-exe文件。"><span class="toc-text">在windows下编译pyc文件时，运行setup.py文件提示找不到cl.exe文件。</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pycharm切换python版本"><span class="toc-text">pycharm切换python版本</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用cx-Freeze-打包python程序成exe文件"><span class="toc-text">使用cx_Freeze 打包python程序成exe文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#python3-中的一些编码问题一定要注意"><span class="toc-text">python3 中的一些编码问题一定要注意</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#opencv读图片Premature-end-of-JPEG-file？"><span class="toc-text">opencv读图片Premature end of JPEG file？</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pyconfig-h-can’t-find"><span class="toc-text">pyconfig.h can’t find</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#import-win32file-时出现-dll缺失，系统找不到指定文件问题"><span class="toc-text">import win32file 时出现  dll缺失，系统找不到指定文件问题</span></a></li></ol>
</div>

        <p>整理一些使用Python过程中遇到的问题和解决方法。</p>
<h1 id="Python3"><a href="#Python3" class="headerlink" title="Python3"></a>Python3</h1><h2 id="cPickle"><a href="#cPickle" class="headerlink" title="cPickle"></a>cPickle</h2><p>python3中没有cPickle模块，和pickle合并了，所以在python3中使用pickle。在使用load的过程中，需要指定encoding,否则可能会出现问题。</p>
<h1 id="ubuntu下为python3-5安装pip3-5"><a href="#ubuntu下为python3-5安装pip3-5" class="headerlink" title="ubuntu下为python3.5安装pip3.5"></a>ubuntu下为python3.5安装pip3.5</h1><p>1、下载setuptools,easy_install安装包<br>    wget <a href="https://bootstrap.pypa.io/ez_setup.py" target="_blank" rel="external">https://bootstrap.pypa.io/ez_setup.py</a><br>2、安装easy_install-3.5<br>    python3.5 ez_setup.py<br>3、安装pip3.5<br>    easy_install-3.5 pip<br>4、升级pip3.5版本<br>    pip3.5 install —upgrade pip<br>5、注意：遇到失败情况时可能是由于没有权限，可以尝试在命令前加sudo</p>
<h1 id="在linux下可以通过设置PYTHONPATH的方法指定python工程目录"><a href="#在linux下可以通过设置PYTHONPATH的方法指定python工程目录" class="headerlink" title="在linux下可以通过设置PYTHONPATH的方法指定python工程目录"></a>在linux下可以通过设置PYTHONPATH的方法指定python工程目录</h1><p>命令如下：也可在 ~/.bashrc 中 添加以下命令达到永久指定的效果<br>    export PYTHONPATH=”${PYTHONPATH}:/my/other/path”<br>遇到不能为root添加PYTHONPATH的情况，用了一下方法解决：<br>    sudo visudo(which open the /etc/sudoers file in a safe way)<br>然后添加：<br>    Default env_keep+=”PYTHONPATH”<br>保存之后生效</p>
<h1 id="UnicodeDecodeError-‘utf-8’-codec-can’t-decode-byte-0xff-in-position-0-invalid-start-byte"><a href="#UnicodeDecodeError-‘utf-8’-codec-can’t-decode-byte-0xff-in-position-0-invalid-start-byte" class="headerlink" title="UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte"></a>UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xff in position 0: invalid start byte</h1><p>image_data = tf.gfile.FastGFile(filenames[i], ‘r’).read()<br>我使用的是python3,后来在python2下就没有出现这个问题。</p>
<h1 id="在windows下编译pyc文件时，运行setup-py文件提示找不到cl-exe文件。"><a href="#在windows下编译pyc文件时，运行setup-py文件提示找不到cl-exe文件。" class="headerlink" title="在windows下编译pyc文件时，运行setup.py文件提示找不到cl.exe文件。"></a>在windows下编译pyc文件时，运行setup.py文件提示找不到cl.exe文件。</h1><p>解决方法是打开vs自带的Command Prompt工具运行setup.py文件</p>
<h1 id="pycharm切换python版本"><a href="#pycharm切换python版本" class="headerlink" title="pycharm切换python版本"></a>pycharm切换python版本</h1><p>settings-&gt;project-&gt;project interpreter </p>
<h1 id="使用cx-Freeze-打包python程序成exe文件"><a href="#使用cx-Freeze-打包python程序成exe文件" class="headerlink" title="使用cx_Freeze 打包python程序成exe文件"></a>使用cx_Freeze 打包python程序成exe文件</h1><p>期间遇到了一些坑，最后顺利解决。主要就是在要打包的脚本文件夹内编写以下脚本，并执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># setup.py</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> cx_Freeze <span class="keyword">import</span> setup, Executable</div><div class="line"><span class="keyword">import</span> os</div><div class="line"></div><div class="line">os.environ[<span class="string">'TCL_LIBRARY'</span>] = <span class="string">r'C:\Users\ThinkPad\AppData\Local\Programs\Python\Python36\tcl\tcl8.6'</span></div><div class="line">os.environ[<span class="string">'TK_LIBRARY'</span>] = <span class="string">r'C:\Users\ThinkPad\AppData\Local\Programs\Python\Python36\tcl\tk8.6'</span></div><div class="line"></div><div class="line">Base=<span class="keyword">None</span></div><div class="line">setup(name = <span class="string">'labelme'</span>,</div><div class="line">      version = <span class="string">'0.0.1'</span>,</div><div class="line">      executables = [Executable(<span class="string">'app.py'</span>,base=Base)],</div><div class="line">      options = &#123;<span class="string">'build_exe'</span>: &#123;<span class="string">'includes'</span>: [<span class="string">'atexit'</span>]&#125;&#125;)</div></pre></td></tr></table></figure></p>
<p>然后 python setup.py build 运行此脚本即可在 build 找到打包好的程序。<br>注意python的根目录应该是包含此脚本的文件夹。之前因为不是这样导致打包的程序不能正确运行。<br>这样打包出来的程序运行起来会有黑框，如果不想要那个黑框，可以把Base=None改为<br>Base=’Win32GUI’</p>
<h1 id="python3-中的一些编码问题一定要注意"><a href="#python3-中的一些编码问题一定要注意" class="headerlink" title="python3 中的一些编码问题一定要注意"></a>python3 中的一些编码问题一定要注意</h1><p>with open(filename, ‘w’) as f<br>with open(filename, ‘wb’) as f<br>b64encode(imageData.encode(‘utf-8’))<br>b64encode(imageData).encode(‘ascii’)</p>
<h1 id="opencv读图片Premature-end-of-JPEG-file？"><a href="#opencv读图片Premature-end-of-JPEG-file？" class="headerlink" title="opencv读图片Premature end of JPEG file？"></a>opencv读图片Premature end of JPEG file？</h1><p>主要是由于图片不完整造成的，可以用以下脚本检验图片是否有效。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_pic</span><span class="params">(path)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        Image.open(path).load() </div><div class="line">    <span class="keyword">except</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">'ERROR: %s'</span> % path</div><div class="line">        <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div></pre></td></tr></table></figure></p>
<p><a href="https://www.zhihu.com/question/30372655/answer/157762216" target="_blank" rel="external">知乎回答</a></p>
<h1 id="pyconfig-h-can’t-find"><a href="#pyconfig-h-can’t-find" class="headerlink" title="pyconfig.h can’t find"></a>pyconfig.h can’t find</h1><p>解决方法：sudo apt-get install python-dev (或者python3.5-dev等相应版本)</p>
<h1 id="import-win32file-时出现-dll缺失，系统找不到指定文件问题"><a href="#import-win32file-时出现-dll缺失，系统找不到指定文件问题" class="headerlink" title="import win32file 时出现  dll缺失，系统找不到指定文件问题"></a>import win32file 时出现  dll缺失，系统找不到指定文件问题</h1><p>解决方法：site-package文件夹中pywin32_system32文件中的dll文件复制到C/windows/system32文件夹中。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/python//" class="article-tag-list-link color2">python</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/08/python/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-linux" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/08/linux/">Linux使用问题</a>
    </h1>
  

        
        <a href="/2017/10/08/linux/" class="archive-article-date">
  	<time datetime="2017-10-08T02:28:39.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-08</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#linux常用命令"><span class="toc-text">linux常用命令</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#查看及修改文件权限"><span class="toc-text">查看及修改文件权限</span></a></li></ol>
</div>

        <p>整理一些使用Linux中遇到的问题及解决方法。</p>
<h1 id="linux常用命令"><a href="#linux常用命令" class="headerlink" title="linux常用命令"></a>linux常用命令</h1><p>1、ctrl+z可以将正在执行的前台命令放到后台并暂停。<br>2、fg将后台命令调到前台继续执行。<br>3、htop可以实现监控<br>4、查看硬盘剩余空间 #df -h #df -H<br>5、查看目录占用空间 #du -hs 目录名</p>
<h1 id="查看及修改文件权限"><a href="#查看及修改文件权限" class="headerlink" title="查看及修改文件权限"></a>查看及修改文件权限</h1><p><a href="https://www.cnblogs.com/CgenJ/archive/2011/07/28/2119454.html" target="_blank" rel="external"></a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/linux//" class="article-tag-list-link color1">linux</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/08/linux/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cs231n-Trainning-Nerual-Networks" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/03/cs231n-Trainning-Nerual-Networks/">Trainning-Nerual-Networks</a>
    </h1>
  

        
        <a href="/2017/10/03/cs231n-Trainning-Nerual-Networks/" class="archive-article-date">
  	<time datetime="2017-10-03T02:44:38.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-10-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#激活函数"><span class="toc-text">激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sigmoid"><span class="toc-text">sigmoid</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tanh"><span class="toc-text">tanh</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ReLU"><span class="toc-text">ReLU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Leaky-ReLU"><span class="toc-text">Leaky ReLU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maxout"><span class="toc-text">Maxout</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用建议"><span class="toc-text">使用建议</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据预处理"><span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Mean-subtraction"><span class="toc-text">Mean subtraction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Normalization"><span class="toc-text">Normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA-and-Whitening"><span class="toc-text">PCA and Whitening</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#具体例子"><span class="toc-text">具体例子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实际使用"><span class="toc-text">实际使用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#权重初始化"><span class="toc-text">权重初始化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#陷阱：全部初始化为0"><span class="toc-text">陷阱：全部初始化为0</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机小数初始化"><span class="toc-text">随机小数初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用sqrt-N-校正"><span class="toc-text">用sqrt(N)校正</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#偏置量的初始化"><span class="toc-text">偏置量的初始化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Batch-Normalization"><span class="toc-text">Batch Normalization</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Regularization-正则化"><span class="toc-text">Regularization(正则化)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#L2-regularization"><span class="toc-text">L2 regularization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#L1-regularization"><span class="toc-text">L1 regularization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Max-norm-constraints"><span class="toc-text">Max norm constraints</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dropout"><span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#偏置正则化"><span class="toc-text">偏置正则化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实践技巧"><span class="toc-text">实践技巧</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Loss-Function"><span class="toc-text">Loss Function</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Classfication"><span class="toc-text">Classfication</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Attribute-classfication"><span class="toc-text">Attribute classfication</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Regression"><span class="toc-text">Regression</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Gradient-Checks"><span class="toc-text">Gradient Checks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sanity-checks"><span class="toc-text">sanity checks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Look-for-correct-loss-at-chance-performance"><span class="toc-text">Look for correct loss at chance performance</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#"><span class="toc-text">#</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overfitting-a-tiny-subset-of-data"><span class="toc-text">Overfitting a tiny subset of data</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#监视学习过程"><span class="toc-text">监视学习过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#loss-function"><span class="toc-text">loss function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Train-Val-accuracy"><span class="toc-text">Train/Val accuracy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ratio-of-weights-updates"><span class="toc-text">Ratio of weights:updates</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Activation-Gradient-distributions-per-layer"><span class="toc-text">Activation/Gradient distributions per layer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#First-layer-Visulization"><span class="toc-text">First-layer Visulization</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参数更新"><span class="toc-text">参数更新</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Vanilla-updata"><span class="toc-text">Vanilla updata</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Momentum-update"><span class="toc-text">Momentum update</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Nesterov-Momentum"><span class="toc-text">Nesterov Momentum</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adagrad"><span class="toc-text">Adagrad</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RMSprop"><span class="toc-text">RMSprop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adam"><span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实践技巧-1"><span class="toc-text">实践技巧</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#超参数优化"><span class="toc-text">超参数优化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#评估"><span class="toc-text">评估</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#模型组合-Model-Ensembles"><span class="toc-text">模型组合(Model Ensembles)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=482988834&auto=1&height=66"></iframe><br>主要介绍训练神经网络的一些技巧，是对cs231n spring 2017 课程 lecture 6、7两节内容的一个整理。</p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>激活函数的作用就是引入一个非线性变换，起到一个激活作用。常见的激活函数有sigmoid,tanh,ReLU,Leaky ReLU等。下面分别介绍。</p>
<h2 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h2><p>sigmoid的表达式是 σ(x)=1/(1+exp(-x))。其图像如下图所示：它有两个明显的缺点使得现在已经不适用了：<br>1、当x过大或者过小时，曲线趋于饱和，使得梯度很小，可能导致很少数据被激活。而且这也给参数初始化造成困难，参数初始化过大或者过小都不好。<br>2、它不过原点，一般来说我们希望激活函数能过原点。当然，这相比第一个缺点来说，负面影响会小一点。<br><img src="sigmoid.jpg" alt=""></p>
<h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><p>tanh其实就是将sigmoid函数变换到以0为中心，它和sigmoid函数一样有着饱和的问题，不过有所改进的是它没有sigmoid函数的第二个缺点。其表达式是：tanh(x)=2σ(2x)-1,图像如下所示：<br><img src="tanh.jpg" alt=""></p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p>过去几年比价流行的激活函数是ReLU,其表达式非常简单:f(x)=max(0,x),图像如图所示：<br><img src="relu.jpg" alt=""></p>
<p>相比之前的激活函数，ReLU函数有以下特点：<br>优点：计算简单快速，实现容易。而且没有趋于饱和的问题。<br>缺点：由于在x小于0时，其数值是0，这可能造成有些神经元会在训练过程中由于参数更新使得永久不能被激活。如果学习率设置得比较高，最后可能会有高达40%的神经元不会被激活。</p>
<h2 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h2><p>为了解决ReLU函数部分神经元不能起作用的问题，在x小于0的部分引入一个比较小的斜率(一般设置为0.01)。这在有些场合是比ReLU函数表现好的。</p>
<h2 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h2><p>另一种激活函数形式是这样的:<br><img src="maxout.jpg" alt=""></p>
<p>它是对ReLU和LeakyReLU的推广，它有着ReLU函数的优点，却不存在ReLU函数的缺点。不过相对而言，其参数个数会翻倍。</p>
<h2 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h2><p>优先选用ReLU,如果效果不好，可以尝试Leaky ReLU或者Maxout，也可以尝试tanh(但是它的效果在绝大多数情况会比ReLU/Maxout差)。sigmoid就千万别用了，已经被时代抛弃~</p>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>主要有3中常用的数据预处理方法，对于数据矩阵X,大小是[NxD],N是数据数量，D是维度。</p>
<h2 id="Mean-subtraction"><a href="#Mean-subtraction" class="headerlink" title="Mean subtraction"></a>Mean subtraction</h2><p>这是最常用的一种方法。就是做一个减去平均值的处理。在python中这样实现：<br>X-=np.mean(X,axis=0)</p>
<h2 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h2><p>做法是把数据维度规范化，一种做法是将所有数据除以标准差：X/=np.std(X,axis=0)；另一种做法是规范化使得最大值为1，最小值为-1。<br>下图中左边是原始数据，中间是做Mean subtraction处理，右边是做Normalization(具体方法是除以标准差的做法)处理。<br><img src="data_preprocessing1.jpg" alt=""></p>
<h2 id="PCA-and-Whitening"><a href="#PCA-and-Whitening" class="headerlink" title="PCA and Whitening"></a>PCA and Whitening</h2><p>PCA(主成分分析)和Whtening的做法都是先利用Mean subtraction方法将数据零对称，然后计算协方差矩阵，将协方差矩阵进行特征值分解之后再进一步处理。<br>它们相同的步骤是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Assume input data matrix X of size [N x D]</span></div><div class="line">X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># zero-center the data (important)</span></div><div class="line">cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>] <span class="comment"># get the data covariance matrix</span></div><div class="line"></div><div class="line">U,S,V = np.linalg.svd(cov)</div><div class="line">Xrot = np.dot(X, U) <span class="comment"># decorrelate the data</span></div></pre></td></tr></table></figure></p>
<p>之后，PCA的处理是用主成分代替整个数据已达到降维的目的，可以以最小的精度损失代价换取较快的计算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Xrot_reduced = np.dot(X, U[:,:<span class="number">100</span>]) <span class="comment"># Xrot_reduced becomes [N x 100]</span></div></pre></td></tr></table></figure></p>
<p>而Whitening的处理方式是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># whiten the data:</span></div><div class="line"><span class="comment"># divide by the eigenvalues (which are square roots of the singular values)</span></div><div class="line">Xwhite = Xrot / np.sqrt(S + <span class="number">1e-5</span>)</div></pre></td></tr></table></figure></p>
<p>值得注意的是：我们在实现的过程中为了防止除零，在分母加了一个小常数，这样带来了一个问题就是它放大了噪声的影响。这个问题可以通过将这个常数增大来减轻。下图中左边是原始数据，中间和右边分别是PCA和Whitening的处理结果。<br><img src="data_preprocessing2.jpg" alt=""></p>
<h2 id="具体例子"><a href="#具体例子" class="headerlink" title="具体例子"></a>具体例子</h2><p>下面是对CIFAR-10中的一些数据进行预处理结果。<br><img src="data_preprocessing3.jpg" alt=""></p>
<h2 id="实际使用"><a href="#实际使用" class="headerlink" title="实际使用"></a>实际使用</h2><p>实际上在卷积网络中，是不使用PCA和Whitening作为预处理的。而Mean subtraction和Normalization通常是必须要做的。另外值得注意的一点是：预处理步骤中的一些统计信息的计算，比如求均值等，只能在训练集上计算，然后应用到测试集上。</p>
<h1 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h1><p>训练神经网络的一个很重要的步骤是参数的初始化工作，理想的初始权重是满足高斯分布。主要有以下几种初始化的方法，下面将分别讨论。</p>
<h2 id="陷阱：全部初始化为0"><a href="#陷阱：全部初始化为0" class="headerlink" title="陷阱：全部初始化为0"></a>陷阱：全部初始化为0</h2><p>如果全部初始化为0的话，那么每个神经元都会有相同的输出，这样在反向传播的过程中它们也会有相同的梯度，最后就会执行相同的参数更新。那么最终的优化后的参数也会全部都是一样的，很明显这样的网络是没有价值的。所以这种初始化方式是错误的。</p>
<h2 id="随机小数初始化"><a href="#随机小数初始化" class="headerlink" title="随机小数初始化"></a>随机小数初始化</h2><p>另一种方式就是随机小数初始化，W=0.01*np.random.randn(D,H)。但是事实上这种初始化方式并没有更好的表现。因为如果一个神经网络层具有很小的权重，那么计算出的梯度也会逐渐。考虑一个10层的网络结果，有500个神经元，tanh作为激活函数。实验中出现，随着层数增加，最后就会出现绝大多数参数为0的情况，这又遇到了和全初始化为零一样的问题。有一种设想是改变随机数前面的系数从0.01改为1，这样在实践中又会造成几乎所有神经元的饱和，其值不是-1就是1，而梯度都为0。</p>
<h2 id="用sqrt-N-校正"><a href="#用sqrt-N-校正" class="headerlink" title="用sqrt(N)校正"></a>用sqrt(N)校正</h2><p>初始化为W=np.random.randn(n)/sqrt(n)，这在以tanh为激活函数的时候有比较好的效果，但是在以ReLU为激活函数的时候效果就不太好了。其实目前在实践中最推荐的初始化方式是W=np.random.randn(n)/sqrt(2/n),激活函数为ReLU。</p>
<h2 id="偏置量的初始化"><a href="#偏置量的初始化" class="headerlink" title="偏置量的初始化"></a>偏置量的初始化</h2><p>最常用的方式就是将偏置初始化为0，当然也有做法将偏置统一初始化为一个小数，比如0.01。</p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>参考<br><a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="external">batch normalization 论文</a><br><a href="https://www.quora.com/Why-does-batch-normalization-help" target="_blank" rel="external">quaro</a><br><a href="http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" target="_blank" rel="external">参考1</a><br><a href="http://jermmy.xyz/2017/09/02/2017-9-2-paper-notes-batch-normalization/" target="_blank" rel="external">论文笔记：Batch Normalization</a><br><a href="https://www.youtube.com/watch?v=BZh1ltr5Rkg&amp;t=21s" target="_blank" rel="external">视频讲解</a></p>
<h1 id="Regularization-正则化"><a href="#Regularization-正则化" class="headerlink" title="Regularization(正则化)"></a>Regularization(正则化)</h1><p>正则化的目的就是防止过拟合。主要有以下几种方式。</p>
<h2 id="L2-regularization"><a href="#L2-regularization" class="headerlink" title="L2 regularization"></a>L2 regularization</h2><p>这是一种比较常用的正则化方法，对每个权重的平方都进行正则化惩罚，常常设置为0.5<em>λ</em>W<em>W，λ是一个超参数，前面加一个0.5的系数是为了方便反向传播的时候求导为λ</em>W。</p>
<h2 id="L1-regularization"><a href="#L1-regularization" class="headerlink" title="L1 regularization"></a>L1 regularization</h2><p>L1 regularization 也是常用的正则化方法，也可以同时使用这两种方法，设置惩罚项为<br>λ1<em>abs(W)+λ2</em>W*W。</p>
<h2 id="Max-norm-constraints"><a href="#Max-norm-constraints" class="headerlink" title="Max norm constraints"></a>Max norm constraints</h2><p>正则化的另一种形式是强制每个神经元的权重向量的绝对上限，并使用预测的梯度下降来强制约束。这种方法的好处就是即便学习率设置得很高，网络也不会出现问题，因为参数更新受到极大限制。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>这是一种比较新的防止过拟合的正则化的方法。通过每次执行参数更新时随机抛弃每一层的一定数量的神经元来达到防止过拟合的目的。决定神经元是否激活的概率p是一个超参数。具体实现的时候需要注意只是在训练的时候需要执行dropout，在测试的时候并不dropout,所以测试时还需要做一个尺度变换，乘上一个p。但是实践中是在训练时执行一次Inverted dropout，而在测试中不做任何处理。</p>
<h2 id="偏置正则化"><a href="#偏置正则化" class="headerlink" title="偏置正则化"></a>偏置正则化</h2><p>偏置的正则化是不常见的，因为它们不通过乘法相互作用与数据交互，对于最终的输出没有什么影响。然而，在实际应用中（通过适当的数据预处理），正则化偏差很少会导致性能显着降低。</p>
<h2 id="实践技巧"><a href="#实践技巧" class="headerlink" title="实践技巧"></a>实践技巧</h2><p>实践中常用的是L2 regularization，其系数λ通过交叉验证来设置。也可以将其和dropout相结合，dropout的概率p一般设置为0.5。</p>
<h1 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h1><p>loss function就是对ground truth和我们的预测结果之间差异的度量，我们在训练中做的事情就是使得其最小化。我们需要针对不同的场景选择适合的loss function以达到我们的目的。</p>
<h2 id="Classfication"><a href="#Classfication" class="headerlink" title="Classfication"></a>Classfication</h2><p>在分类任务中，我们常用的loss function有 SVM loss：<br>其形式如下：<br><img src="svm_loss.jpg" alt=""><br>实际应用中也有使用它的平方项达到较好效果的例子。<br>另外一种常见的是Softmax loss,如下所示：<br><img src="softmax_loss.jpg" alt=""><br>实际上当分类任务中标签太多时，更推荐使用Hierarchical Softmax loss的计算方法，具体细节见<br><a href="https://arxiv.org/pdf/1310.4546.pdf" target="_blank" rel="external">参考</a></p>
<h2 id="Attribute-classfication"><a href="#Attribute-classfication" class="headerlink" title="Attribute classfication"></a>Attribute classfication</h2><p>上面介绍的loss function都是针对一个物品只有一个标签的情况，对于一个物体有多个标签的情况，我们需要用另外一种度量方法。解决这种的一个比较好的方法是独立地为每个单独的属性构建一个二进制分类器。例如，每个类别的二进制分类器将独立采用以下形式：<br><img src="binary1.jpg" alt=""></p>
<p>其中y(ij)的值取决于第i个物体是否属于类别j,如果是，其值为1，否则为-1。<br>这种损失的替代方案是独立地为每个属性训练逻辑回归分类器。二元逻辑回归分类器只有两个类（0,1），并且将类1的概率计算为：<br><img src="binary2.jpg" alt=""></p>
<p>这可以最终简化得到<br><img src="binary3.jpg" alt=""></p>
<p>这种方法看起来麻烦，实际上它的梯度计算非常简单，为：<br><img src="binary4.jpg" alt=""></p>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>这类任务需要预测一个东西的准确值，比如预测房价等。常常使用L1 loss或者L2 loss。实际上，L2 loss相比softmax loss更难优化。除非绝对必要，否则不要使用回归任务，如果能够将这类任务转化为分类任务，那是再好不过的。</p>
<h1 id="Gradient-Checks"><a href="#Gradient-Checks" class="headerlink" title="Gradient Checks"></a>Gradient Checks</h1><p>梯度检查实际就是将analytic gradient 和 numerical gradient 进行比价，用numerical gradient检查 analytic gradient是否计算正确。这个过程很关键，而且容易出错，这里介绍一点处理的技巧。<br>1、Use teh centered formula<br><img src="gradient_check1.jpg" alt=""><br><img src="gradient_check2.jpg" alt=""></p>
<p>2、Use relative error for the comparison<br>比较两种梯度时，比较绝对误差是没有任何意义的，实践中是比较相对误差。<br><img src="gradient_check3.jpg" alt=""></p>
<p>通常情况下这个error&gt;1e-2说明梯度有问题，需要检查；1e-2&gt;error&gt;1e-4,勉强能够接受;1e-4&gt;error，在一般情况下算是比较好的;如果error&lt;1e-7,那么肯定是正确的了。但是这个误差与网络层数也有关系，网络越深，很明显这个误差会越大，比如对于一个10层的网络，这个error在1e-2的量级也许都是可以接受的，但是对于只有一层的网络这显然太高。所以还要根据实际情况尽心考虑。<br>3、Use double precision<br>进行梯度检查时应该使用double,用float精度不够。<br>4、Stick around active range of floating point<br>在运算过程中将中间数据浮点数控制在有效范围，太小的数据可能会造成一些数值问题(1e-10甚至更小的数据是没有意义的)。遇到这样的中间结果时，需要暂时进行一个缩放将数值扩大到一个适当的范围，比如到1e0量级。<br>5、Kinks in the objective<br>对于某些激活函数，比如ReLU,会出现梯度不连续的问题，在执行梯度检查的时候需要格外注意，否则可能造成意外的结果。<br>6、Use only few datapoints<br>解决上述问题的一个方法就是使用更少的数据点，这样既可以有效避免上述问题，还可以使得梯度检查更加快速，效率更高。<br>7、Be careful with the step size h<br>h并不是越小越好，如果h太小的话反而可能会造成一些数值问题。<br>8、Gradcheck during a “characteristic” mode of operation<br>9、Don’t let the regularization overwhelm the data<br>10、Remember to turn off dropout/augmentations<br>11、Check only few dimensions</p>
<h1 id="sanity-checks"><a href="#sanity-checks" class="headerlink" title="sanity checks"></a>sanity checks</h1><p>在开始进行训练之前，需要先对网络进行一些简单的健壮性检查。</p>
<h2 id="Look-for-correct-loss-at-chance-performance"><a href="#Look-for-correct-loss-at-chance-performance" class="headerlink" title="Look for correct loss at chance performance"></a>Look for correct loss at chance performance</h2><p>当进行参数初始化时，我们需要保证初始的loss达到我们的预期。所以需要我们单独检查loss(这时要忽略正则化项)。如果loss和我们的预期不符，这时需要检查是否初始化存在问题等。</p>
<h1 id=""><a href="#" class="headerlink" title="#"></a>#</h1><p>增加正则化项的权重会增加loss，也可以一次为标准进行检查。</p>
<h2 id="Overfitting-a-tiny-subset-of-data"><a href="#Overfitting-a-tiny-subset-of-data" class="headerlink" title="Overfitting a tiny subset of data"></a>Overfitting a tiny subset of data</h2><p>正式开始训练之前，可以用较小的数据集进行训练，看看能不能使得loss为0(注意这时不要考虑正则化项)。如果不能使得loss为0，那么这个网络应该是存在问题的。当然即便能够使得loss为0，也不代表网络是正确的，不排除有其他bug的情况。</p>
<h1 id="监视学习过程"><a href="#监视学习过程" class="headerlink" title="监视学习过程"></a>监视学习过程</h1><p>在训练神经网络时应该监视多种有用的数量。这些图是进入训练过程的窗口，应该被用来获得有关不同超级参数设置的直观性，以及如何改变它们以提高学习效率。下面的图的x轴总是以epoch为单位，其测量在期望的训练期间每个示例已经看到多少次（例如，一个时期意味着每个示例已经被看到一次),优选的是epoch而不是迭代次数，因为迭代次数取决于批量大小的任意设置。</p>
<h2 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h2><p>我们训练的目的就是使得loss最小化，所以loss是最需要跟踪的一个参数。如下图所示：损失曲线通常会出现摆动，这和batch size有关，如果batch size是1，那么这个摆动会很厉害，如果batch size是整个数据集，那么将不会出现摆动。<br><img src="loss1.jpg" alt=""></p>
<h2 id="Train-Val-accuracy"><a href="#Train-Val-accuracy" class="headerlink" title="Train/Val accuracy"></a>Train/Val accuracy</h2><p>训练分类器时跟踪的第二个重要数量是验证/训练准确性。这让我们更直观了解到过拟合现象。过拟合简单来说就是在训练集上表现好，但是在测试集上表现差的现象。从下图可以直观看出。<br><img src="overfitting1.jpg" alt=""></p>
<h2 id="Ratio-of-weights-updates"><a href="#Ratio-of-weights-updates" class="headerlink" title="Ratio of weights:updates"></a>Ratio of weights:updates</h2><p>最后一个需要关心的参数是更新幅度与整个值的幅度的比例。这个幅度最好在1e-3左右，如果这个值太小，说明学习率设置太低，反之则太高。我们需要对此作出调整。代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># assume parameter vector W and its gradient vector dW</span></div><div class="line">param_scale = np.linalg.norm(W.ravel())</div><div class="line">update = -learning_rate*dW <span class="comment"># simple SGD update</span></div><div class="line">update_scale = np.linalg.norm(update.ravel())</div><div class="line">W += update <span class="comment"># the actual update</span></div><div class="line"><span class="keyword">print</span> update_scale / param_scale <span class="comment"># want ~1e-3</span></div></pre></td></tr></table></figure></p>
<h2 id="Activation-Gradient-distributions-per-layer"><a href="#Activation-Gradient-distributions-per-layer" class="headerlink" title="Activation/Gradient distributions per layer"></a>Activation/Gradient distributions per layer</h2><p>初始化不正确可能会减慢甚至完全停止学习过程。幸运的是，这个问题可以比较容易地诊断出来。 一种方法是绘制网络的所有层的激活/梯度直方图。直观地看，看到任何奇怪的分布并不是一个好兆头。 如果是tanh神经元，我们希望在[-1,1]的全范围内看到神经元激活的分布，而不是看到所有神经元输出零，或者所有神经元在-1或1完全饱和。</p>
<h2 id="First-layer-Visulization"><a href="#First-layer-Visulization" class="headerlink" title="First-layer Visulization"></a>First-layer Visulization</h2><p>处理图像问题时，绘制第一层的特征还是很有用的，可以以此为根据判断参数好坏。<br><img src="visualization.jpg" alt=""></p>
<h1 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h1><p>当通过反向传播计算出analytic gradient后，我们可以以此进行参数更新。具体的更新方法下面将详细介绍。</p>
<h2 id="Vanilla-updata"><a href="#Vanilla-updata" class="headerlink" title="Vanilla updata"></a>Vanilla updata</h2><p>最简单常用的参数更新方式，直接沿着负梯度的方向更新：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x+=-learning_rate*dx</div></pre></td></tr></table></figure></p>
<h2 id="Momentum-update"><a href="#Momentum-update" class="headerlink" title="Momentum update"></a>Momentum update</h2><p>动态更新是另一种在深度网络上几乎总是具有更好的融合速率的方法。其实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">v=mu*v-learning_rate*dx</div><div class="line">x+=v</div><div class="line"><span class="comment">#其中v初始化为0，mu是一个超参数，典型的设置为0.9或者0.99。通过动量更新，参数矢</span></div><div class="line"><span class="comment">#量将在具有一致梯度的任何方向上建立速度。</span></div></pre></td></tr></table></figure>
<h2 id="Nesterov-Momentum"><a href="#Nesterov-Momentum" class="headerlink" title="Nesterov Momentum"></a>Nesterov Momentum</h2><p>Nesterov动量是一个稍微不同的动态更新的版本，最近越来越受欢迎。对凸函数有较强的理论收敛保证，实际上也比标准动量略好。其通常实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">v_prev = v <span class="comment"># back this up</span></div><div class="line">v = mu * v - learning_rate * dx <span class="comment"># velocity update stays the same</span></div><div class="line">x += -mu * v_prev + (<span class="number">1</span> + mu) * v <span class="comment"># position update changes form</span></div></pre></td></tr></table></figure>
<p><img src="compare_update.jpg" alt=""></p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Assume the gradient dx and parameter vector x</span></div><div class="line">cache += dx**<span class="number">2</span></div><div class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</div></pre></td></tr></table></figure>
<h2 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cache = decay_rate * cache + (<span class="number">1</span> - decay_rate) * dx**<span class="number">2</span></div><div class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</div></pre></td></tr></table></figure>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">m = beta1*m + (<span class="number">1</span>-beta1)*dx</div><div class="line">v = beta2*v + (<span class="number">1</span>-beta2)*(dx**<span class="number">2</span>)</div><div class="line">x += - learning_rate * m / (np.sqrt(v) + eps)</div><div class="line">``` </div><div class="line">通常设置eps=<span class="number">1e-8</span>,beta1=<span class="number">0.9</span>,beta2=<span class="number">0.999</span>。</div><div class="line">还有一种包括偏置的形式：</div><div class="line">``` Python</div><div class="line"><span class="comment"># t is your iteration counter going from 1 to infinity</span></div><div class="line">m = beta1*m + (<span class="number">1</span>-beta1)*dx</div><div class="line">mt = m / (<span class="number">1</span>-beta1**t)</div><div class="line">v = beta2*v + (<span class="number">1</span>-beta2)*(dx**<span class="number">2</span>)</div><div class="line">vt = v / (<span class="number">1</span>-beta2**t)</div><div class="line">x += - learning_rate * mt / (np.sqrt(vt) + eps)</div></pre></td></tr></table></figure>
<h2 id="实践技巧-1"><a href="#实践技巧-1" class="headerlink" title="实践技巧"></a>实践技巧</h2><p>推荐的参数更新方式是SGD+Nesterov Momentum或者Adam。</p>
<h1 id="超参数优化"><a href="#超参数优化" class="headerlink" title="超参数优化"></a>超参数优化</h1><p>训练神经网络之前需要许多超参数的设置。最常见的超参数有：<br>初始学习率，learning rate decay schedule(such as decay constant),正则化的一些参数(比如L2的系数，dropout的比例)。<br>在选择超参数时需要注意以下一些一些事情：<br>1、Prefer one validation fold to cross-validation:虽然常说需要用交叉验证的方式确定超参数，但是实际上只需要一个验证集就足够了。<br>2、Hyperparameter ranges:常常在log的尺度上搜索超参数，例如 learning_rate=10**uniform(-6,1)。但是对于一些特殊参数，比如dropout的比例，不需要也不能这样，通常的做法是：dropout=uniform(0,1)。<br>3、Prefer random search to grid search：实践证明，随机搜索的效率会比网格搜索的效率高。<br>4、Careful with best values on border：当我们确定的超参数在我们搜索的范围边界上时，我们要特别注意，有可能这个超参数并不是最好的，我们这时需要在这个边界上扩大搜索范围再进行超参数搜索。<br>5、Stage your search from coarse to fine：一种比较好的实践方式是先在一个大范围内搜索超参数，只需要一个epoch，可以排除一些明显不合适的超参数，这样缩小范围后再进行超参数的确定。<br>6、Bayesian Hyperparameter Optimization</p>
<h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><h2 id="模型组合-Model-Ensembles"><a href="#模型组合-Model-Ensembles" class="headerlink" title="模型组合(Model Ensembles)"></a>模型组合(Model Ensembles)</h2><p>通过一些模型的组合可能对网络效果有额外的一点提高。下面是一些模型组合的方法。<br>1、Same model,different initializaitons：先用交叉验证的方法确定超参数，然后用不同的初始化参数进行训练。<br>2、Top models discovered during cross-validation:用交叉验证的方法确定最好的几个参数。<br>3、Different checkpoints of a single model<br>4、Running average of parameters during training</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf" target="_blank" rel="external">cs231n lecture6 slides</a><br><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture7.pdf" target="_blank" rel="external">cs231n lecture7 slides</a><br><a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="external">cs231n neural network notes 1</a><br><a href="http://cs231n.github.io/neural-networks-2/" target="_blank" rel="external">cs231n neural network notes 2</a><br><a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="external">cs231n neural network notes 3</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/10/03/cs231n-Trainning-Nerual-Networks/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cs231n-Convolutional-Neural-Networks" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/30/cs231n-Convolutional-Neural-Networks/">Convolutional-Neural-Networks</a>
    </h1>
  

        
        <a href="/2017/09/30/cs231n-Convolutional-Neural-Networks/" class="archive-article-date">
  	<time datetime="2017-09-30T14:26:01.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-09-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络-Neural-Networks"><span class="toc-text">神经网络(Neural Networks)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络的结构"><span class="toc-text">神经网络的结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#卷积神经网络-Convolutional-Neural-Networks"><span class="toc-text">卷积神经网络(Convolutional Neural Networks)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#结构介绍"><span class="toc-text">结构介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积网络的层的种类"><span class="toc-text">卷积网络的层的种类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#举例"><span class="toc-text">举例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结-1"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结构细节"><span class="toc-text">结构细节</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#卷积层"><span class="toc-text">卷积层</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#不考虑神经元的分析"><span class="toc-text">不考虑神经元的分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#从神经元角度的分析"><span class="toc-text">从神经元角度的分析</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#局部联系"><span class="toc-text">局部联系</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#例1"><span class="toc-text">例1</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#例2"><span class="toc-text">例2</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#空间分布"><span class="toc-text">空间分布</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#depth"><span class="toc-text">depth</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#stride"><span class="toc-text">stride</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#zero-padding"><span class="toc-text">zero-padding</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#计算输出体积大小"><span class="toc-text">计算输出体积大小</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#一些注意事项"><span class="toc-text">一些注意事项</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#zero-padding的正确设置"><span class="toc-text">zero-padding的正确设置</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#strides的限制"><span class="toc-text">strides的限制</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#实际操作的一个例子"><span class="toc-text">实际操作的一个例子</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#参数共享"><span class="toc-text">参数共享</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#利用大矩阵乘法实现卷积层"><span class="toc-text">利用大矩阵乘法实现卷积层</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#反向传播"><span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1x1卷积"><span class="toc-text">1x1卷积</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#扩张卷积-Dilated-convolutions"><span class="toc-text">扩张卷积(Dilated convolutions)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#池化层"><span class="toc-text">池化层</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#常见的池化方式"><span class="toc-text">常见的池化方式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#池化操作的替代"><span class="toc-text">池化操作的替代</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#归一化层"><span class="toc-text">归一化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#全连接层"><span class="toc-text">全连接层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#转换全连接层到卷积层"><span class="toc-text">转换全连接层到卷积层</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积网络的架构"><span class="toc-text">卷积网络的架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Layer-Patterns"><span class="toc-text">Layer Patterns</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Layer-Sizing-Patterns"><span class="toc-text">Layer Sizing Patterns</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Input-Layer"><span class="toc-text">Input Layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Conv-Layer"><span class="toc-text">Conv Layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Pool-Layer"><span class="toc-text">Pool Layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CONV层为什么设置S-1？"><span class="toc-text">CONV层为什么设置S=1？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Padding的作用"><span class="toc-text">Padding的作用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#内存限制"><span class="toc-text">内存限制</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#常见的实例"><span class="toc-text">常见的实例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算的注意事项"><span class="toc-text">计算的注意事项</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <p>主要介绍神经网络和卷积神经网络的一些东西。</p>
<h1 id="神经网络-Neural-Networks"><a href="#神经网络-Neural-Networks" class="headerlink" title="神经网络(Neural Networks)"></a>神经网络(Neural Networks)</h1><p>之前的线性score function 是 f=Wx，现在扩展到2层的神经网络的表示是：f=W2<em>max(0,W1</em>x)。类似的，如果扩展到3层网络可以这样表示：f=W3<em>max(0,W2</em>max(0,W1*x))。<br><img src="2_layer.jpg" alt=""></p>
<p>一个简单的2层神经网络可以这样实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> n p</div><div class="line">form numpy.random <span class="keyword">import</span> randn</div><div class="line"></div><div class="line">N,D_in,H,D_out=<span class="number">64</span>,<span class="number">1000</span>,<span class="number">100</span>,<span class="number">10</span></div><div class="line">x,y=randn(N,D_in),randn(N,D_out)</div><div class="line">w1,w2=randn(D_in,H),randn(H,D_out)</div><div class="line"></div><div class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">2000</span>):</div><div class="line">    h=<span class="number">1</span>/(<span class="number">1</span>+np.exp(-x.dot(W1)))</div><div class="line">    y_pred=h.dot(W2)</div><div class="line">    loss=np.square(y_pred-y).sum()</div><div class="line">    print(t,loss)</div><div class="line"></div><div class="line">    grad_y_pred=<span class="number">2.0</span>*(y_pred-y)</div><div class="line">    grad_w2=h.T.dot(grad_y_pred)</div><div class="line">    grad_h=grad_y_pred.dot(W2.T)</div><div class="line">    grad_w1=x.T.dot(grad_h*h*(<span class="number">1</span>-h))</div><div class="line"></div><div class="line">    w1-=<span class="number">1e-4</span>*grad_w1</div><div class="line">    w2-=<span class="number">1e-4</span>*grad_w2</div></pre></td></tr></table></figure></p>
<h2 id="神经网络的结构"><a href="#神经网络的结构" class="headerlink" title="神经网络的结构"></a>神经网络的结构</h2><p>一个完整的神经网络应该包括1个输入层，若干隐藏层，1个输出层。<br><img src="network_architectures.jpg" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1、神经网络中把每一层的神经元做一个全连接。<br>2、对于每一层的计算都可以用高效的矢量计算来实现。<br>3、神经网络和真正的神经是不一样的，只是在某种程度上有些相似性。</p>
<h1 id="卷积神经网络-Convolutional-Neural-Networks"><a href="#卷积神经网络-Convolutional-Neural-Networks" class="headerlink" title="卷积神经网络(Convolutional Neural Networks)"></a>卷积神经网络(Convolutional Neural Networks)</h1><h2 id="结构介绍"><a href="#结构介绍" class="headerlink" title="结构介绍"></a>结构介绍</h2><p>卷积神经网络有着神经网络所有的特征：每一层由神经元组成，我们可以学习它的W和b;每一个神经元有一个输入，进行一个点积运算之后，可以紧接着一个非线性的操作；整个网络最后也是运算一个score function，输出scores;在最后一层全连接层仍然会计算一个损失函数；以及神经网络的一些其它性质和技巧在卷积神经网络中依然适用。</p>
<p>但是卷积神经网络和普通神经网络相比有以下区别：<br>卷积神经网络明确假设输入是图片，这允许我们将某些属性编码到架构中，使得前向网络能够更为有效地实现，并且大大减少了网络中的参数数量。</p>
<p>通常的神经网络接受一个输入（通常是一个一维向量），并通过中间的隐藏层对其进行一些变换，每一层隐藏层包含多个神经元，其中每一个神经元都和上一层的各个神经元全连接。同一层的神经元之间是相互独立，并不存在任何连接。最后一层全连接层叫做输出层，在分类问题中它就代表每个类的分数。</p>
<p>普通的神经网络不能直接对图片操作，而是将图像矩阵拉伸成一维向量，比如对于32x32x3的图片，这样对于一个神经元就会有3072个权重。对于更大的图片，权重的数量将会更多。关键的问题是，这样的神经元会有很多，这样的话参数的数量将会增长很快。这样使得全连接有些浪费，并且参数过多很容易造成过拟合。</p>
<p>对于卷积神经网络来说，每一层的神经元包括三个维度(width,height,depth),这样，每一层的神经元就只和前面一层的很小一部分区域有联系，这区别于普通神经网络的全连接层。另外，对于之前的CIFAR-10的例子，最后输出层的输出结果是一个1x1x10的矩阵。<br>如下图所示：左边是普通的神经网络，右边是一个卷积神经网络。卷积神经网络的每一层都有一个简单的API把一个形状的3维体积通过一个可微函数转换为另一个形状的3维体积。<br><img src="cnn.jgp" alt=""></p>
<h2 id="卷积网络的层的种类"><a href="#卷积网络的层的种类" class="headerlink" title="卷积网络的层的种类"></a>卷积网络的层的种类</h2><p>正如上面所说，一个简单的卷积神经网络由一系列层组成，每一层通过一个可微函数将一个三维体积转换成另一个不同形状的三维体积。主要使用一下三种类型的层来构建卷积神经网络：卷积层，池化层以及全连接层，把这三种类型的层组合在一起就可以构建一个完整的卷积神经网络。</p>
<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>对于CIFAR-10这个数据集的分类问题，我们可以构建这样一个卷积神经网络：<br>[INPUT-CONV-RELU-POOL-FC]。具体分析如下：<br>1、INPUT[32x32x3],即输入一张原始图片，大小为32x32,通道数为3<br>2、CONV(卷积层)计算连接到局部输入的神经元的输出，每次计算权重和局部输入的卷积，如果我们用12个滤波器的话，最后的输出将会是[32x32x12]。<br>3、RELU层就将执行一次激活函数，不改变输入大小，依然是[32x32x12]。<br>4、POOL层将在空间维度上进行一次下采样(downsample)，然后输出维数为[16x16x12]<br>5、FC层将计算一个得分函数(score function)，输出体积为[1x1x10]。这一层的神经元将和前一层的所有体积相关联。<br>这样，通过一层层的运算，卷积神经网络将输入的原始图像转换为得分向量。值得一提的是：其中有些层的操作是由参数的，而有些层的操作是没有参数的。比如CONV/FC层就包括神经元的W和b参数，而RELU/POOL层的操作则是不变的，不需要任何参数。COVN/FC层的参数将通过梯度下降的算法进行优化以便达到良好的识别效果。<br><img src="cnn_example.jpg" alt=""></p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>1、卷积神经网络的结构就是实现简单的从一个形状到另一个形状的转换。<br>2、它由不同类型的层组成，目前最常用的就是卷积层，池化层，激活层以及全连接层。<br>3、每层可以有参数(比如CONV、FC)也可以没有参数(比如RELU、POOL)，每层可以有超参数(比如CONV、FC、POOL)也可以没有超参数(比如RELU)。</p>
<h3 id="结构细节"><a href="#结构细节" class="headerlink" title="结构细节"></a>结构细节</h3><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>卷积层是一个卷积神经网络的核心，大部分的运算量都集中在卷积层。</p>
<h5 id="不考虑神经元的分析"><a href="#不考虑神经元的分析" class="headerlink" title="不考虑神经元的分析"></a>不考虑神经元的分析</h5><p>卷积层的参数包括一系列可以学习的滤波器。每个滤波器在空间上是小块的，但是在深度上是和输入一致的。例如，一个典型的在第一个卷积层的滤波器的尺寸是[5x5x3]。在前向计算的过程中，我们用滤波器的大小在输入体积上面滑动，然后在每个位置计算滤波器和其覆盖的输入部分的点积之和作为这个位置的计算结果。整个过程下来，我们将产生一个二维的激活图，其中每个点的结果表示输入的体积对于滤波器在该位置的响应。更直观地说，网络将学习当他们看到某种类型的视觉特征（例如某一方向的边缘或第一层上的一些颜色的斑点）或最终在网络的较高层上的整个蜂窝或轮状图案时激活的过滤器。 现在，我们将在每个CONV层中拥有一整套滤波器（例如12个滤波器），并且它们中的每一个将产生单独的二维激活图。 我们将沿深度维度堆叠这些激活图，并产生输出量。</p>
<h5 id="从神经元角度的分析"><a href="#从神经元角度的分析" class="headerlink" title="从神经元角度的分析"></a>从神经元角度的分析</h5><p>输出结果中的每个元素也可理解为神经元的输出，其只在输入中看到一个小区域，并和其左右的神经元在空间上共享参数。现在分别讨论神经元之间的联系，空间上的排布以及参数共享的一些细节。</p>
<h6 id="局部联系"><a href="#局部联系" class="headerlink" title="局部联系"></a>局部联系</h6><p>当处理诸如图像的高维输入时，将神经元连接到前一层的所有神经元是不切实际的。但是我们可以将每个神经元连接到前一层的局部区域。这种连通性的空间范围是神经元的超参数，称为接受场(receptive filed)，等价于滤波器大小。这里需要再一次强调我们处理空间尺寸和深度时的不一致性。这种连接在空间是局部的，但是在深度上是全连接的。</p>
<h6 id="例1"><a href="#例1" class="headerlink" title="例1"></a>例1</h6><p>假设输入尺寸是[32x32x3],滤波器大小是[5x5],这样的话每个神经元将对应于一个[5x5x3]的区域，这样就有5<em>5</em>3=75(再加1个偏置b)的weights。</p>
<h6 id="例2"><a href="#例2" class="headerlink" title="例2"></a>例2</h6><p>如果输入尺寸是[16x16x20],滤波器大小是[3x3],那么卷积层中的每个神经元将有3<em>3</em>20=180(再加上1个偏置b)的weights和输入体积相关联。<br><img src="local_connectivity.jpg" alt=""></p>
<h6 id="空间分布"><a href="#空间分布" class="headerlink" title="空间分布"></a>空间分布</h6><p>上面阐述了一层卷积层中的每个神经元和输入的体积之间的联系。但是没有说明在输出体积中有多少个神经元以及它们之间是怎么排布的。有以下三个超参数会影响神经元的空间分布：分别是depth,stride和zero-padding。下面分别讨论细节。</p>
<h6 id="depth"><a href="#depth" class="headerlink" title="depth"></a>depth</h6><p>depth和我们期望的滤波器的种类有关，每个滤波器会学习到输入中的一些不同特征。<br>例如，如果第一卷积层作为原始图像的输入，则沿着深度维度的不同神经元可以在存在各种定向边缘或颜色的斑点的情况下激活。我们将参考一组神经元，它们都是与输入的相同区域作为深度列。</p>
<h6 id="stride"><a href="#stride" class="headerlink" title="stride"></a>stride</h6><p>stride是指计算卷积时跳过的像素点数，如果是依次计算的话，则stride是1。stride越大，在相同输入情况下，输出的空间尺寸会越小。</p>
<h6 id="zero-padding"><a href="#zero-padding" class="headerlink" title="zero-padding"></a>zero-padding</h6><p>有时为了运算方便，会对输入图像进行边界的零填充，零填充的尺寸大小也是一个超参数。通过控制零填充的大小，我们可以方便控制输出体积的大小。</p>
<h6 id="计算输出体积大小"><a href="#计算输出体积大小" class="headerlink" title="计算输出体积大小"></a>计算输出体积大小</h6><p>了解了以上性质之后，我们可以计算输出的体积大小，假设输入体积大小是W，滤波器大小是F，stride大小是S,zero-padding大小是P，然后就可以计算出输出尺寸V是：<br>V=(W-F+2*P)/S+1。比如W=5，S=1，P=1，F=3，那么V=5，如果改变S=2，那么V=3。如下图所示：<br><img src="calculate.jpg" alt=""></p>
<h6 id="一些注意事项"><a href="#一些注意事项" class="headerlink" title="一些注意事项"></a>一些注意事项</h6><h6 id="zero-padding的正确设置"><a href="#zero-padding的正确设置" class="headerlink" title="zero-padding的正确设置"></a>zero-padding的正确设置</h6><p>当S为1时，一种常见的做法是设置P=（F-1)/2，这样使得V=W。使得输入和输出在空间大小上保持一致。</p>
<h6 id="strides的限制"><a href="#strides的限制" class="headerlink" title="strides的限制"></a>strides的限制</h6><p>不合适的设置S可能使得产生无效的结果。比如W=10，P=0，F=3，如果S=2，那么V=(W-F+2*P)/S+1=4.5将不是一个整数。如果出现这样的情况，我们将采用改变P或者裁剪输入等方法来避免这个问题。</p>
<h6 id="实际操作的一个例子"><a href="#实际操作的一个例子" class="headerlink" title="实际操作的一个例子"></a>实际操作的一个例子</h6><p><a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="external">Krizhevsky et al.</a></p>
<p>2012年ImageNet比赛的冠军的一个例子。输入图像是[227x227x3],F=11,S=4,P=0,计算得到V=(227-11)/4+1=55。而depth=96。最后得到的输出是[55x55x96]。这就表示输出体积中的55<em>55</em>96个神经元之一都和输入中的[11x11x3]大小的区域相关联。</p>
<h6 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h6><p>参数共享的目的是为了控制卷积层中参数的数目。考虑上面的那个例子。在第一层卷积层中有55<em>55</em>96=290400个神经元，每个神经元都有11<em>11</em>3=363个weights和1个bias，这样的话，在第一层中将会有290400<em>364=105705600个参数，显然，这个数目太大了。<br>事实证明，我们可以通过一个合理的假设大大减少参数数量：如果一个特征在某些空间位置（x，y）上计算有用，那么在不同的位置（x2,y2）计算也是有用的。换句话说，将深度的单个二维切片表示为深度切片（例如，尺寸[55×55×96]的体积具有96个深度切片，每个尺寸[55x55]），我们将限制每个深度切片中的神经元使用相同的权重和偏差。使用此参数共享方案，我们的示例中的第一个Conv Layer现在将只有96个唯一的权重集（每个深度片一个），总共96 </em> 11 <em> 11 </em> 3 = 34,848个唯一权重或34,944个参数（ +96偏置）。或者，每个深度切片中的所有55 * 55个神经元现在将使用相同的参数。在反向传播中的实践中，体积中的每个神经元将计算其权重的梯度，但是这些梯度将在每个深度切片上相加，并且仅更新每个切片的单个权重集合。<br>注意，如果单个深度切片中的所有神经元都使用相同的权重向量，则CONV层的前向可以在每个深度切片中计算为神经元权重与输入核的卷积（因此名称为卷积层）。 这就是为什么通常将权重集合称为与输入进行卷积的滤波器。<br>请注意，有时参数共享假设可能没有意义。 特别是当ConvNet的输入图像具有某些特定的居中结构时，我们期望在图像的一侧学习完全不同的特征。 一个实际的例子是当输入是一张位于图像中心的脸，我们可能会期望在不同的空间位置学习眼睛或头发的特征。在这种情况下，通常放松参数共享方案，简单地使用本地连接层(Locally-Connected Layer)。</p>
<h5 id="利用大矩阵乘法实现卷积层"><a href="#利用大矩阵乘法实现卷积层" class="headerlink" title="利用大矩阵乘法实现卷积层"></a>利用大矩阵乘法实现卷积层</h5><p>注意，卷积运算基本上在输入的滤波器和局部区域之间执行点积。 CONV层的常见实现模式是利用这一事实，并将卷积层的正向传递作为一个大矩阵乘法如下实现：<br>1、在通常称为im2col的操作中，输入图像中的局部区域被拉伸成列。 例如，如果输入是[227x227x3],并且要在步幅4中与11x11x3滤波器进行卷积，则我们将在输入中取出[11x11x3]个像素块，并将每个块拉伸为大小为11 <em> 11 </em> 3 =363.在步长4的输入中迭代该过程给出沿宽度和高度的（227-11）/ 4 + 1 = 55个位置，导致尺寸为[363×3025]的im2col的输出矩阵X_col，其中每列是一个伸展的接受场，总共有55 * 55 = 3025。请注意，由于接收字段重叠，输入卷中的每个数字可能会复制在多个不同的列中。<br>2、CONV层的权重同样伸展成行。 例如，如果有大小为[11x11x3]的96个滤波器，则这将产生大小为[96 x 363]的矩阵W_row。<br>3、卷积的结果现在相当于执行一个大的矩阵乘法np.dot（W_row，X_col），它计算每个过滤器和每个接收域位置之间的点积。 在我们的示例中，此操作的输出将为[96 x 3025]，给出每个位置上每个过滤器的点积的输出。<br>4、结果必须最终重新整理为正确的输出维度[55x55x96]。<br>这种方法仍然有缺点，它可能使用大量的内存，因为输入卷中的某些值在X_col中被复制多次。然而，好处是有许多非常有效的矩阵乘法实现。相同的im2col思想可以重用以执行池化操作，这将在之后讨论。</p>
<h5 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h5><p>卷积运算的反向传播（对于数据和权重）也是卷积（但是具有空间翻转的滤波器)。</p>
<h5 id="1x1卷积"><a href="#1x1卷积" class="headerlink" title="1x1卷积"></a>1x1卷积</h5><p>有些论文使用了1x1卷积，对于二维的信号，1x1卷积没有任何意义（只是点取向缩放）。 然而，在ConvNets中，情况并非如此，因为我们必须记住，我们操作三维体积，并且过滤器总是延伸到输入卷的整个深度。 例如，如果输入为[32x32x3],则进行1x1卷积将有效地进行三维点积（因为输入深度为3个通道）。</p>
<h5 id="扩张卷积-Dilated-convolutions"><a href="#扩张卷积-Dilated-convolutions" class="headerlink" title="扩张卷积(Dilated convolutions)"></a>扩张卷积(Dilated convolutions)</h5><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>在ConvNet体系结构中，通常在连续Conv层之间定期插入一个Pooling层。 其功能是逐步减少表示的空间大小，以减少网络中的参数和计算量，从而也可以控制过拟合。 汇集层在输入的每个深度层上独立运行，并使用MAX操作在空间上调整其大小。最常见的形式是一个大小为2x2的过滤器的池化层，每个深度切片在宽度和高度均为2，每个深度切片下降2个步长，丢弃75％的激活。在这种情况下，每个MAX操作将占用超过4个数字（一些深度片段中的2×2个区域),其深度维度保持不变。<br>常用的池化操作是设置F=3，S=2(也叫做重叠池)，更常见的是F=2，S=2。如果F太大的话，破坏性太强就不适用了。</p>
<h5 id="常见的池化方式"><a href="#常见的池化方式" class="headerlink" title="常见的池化方式"></a>常见的池化方式</h5><p>出了最大池化，池化单元还可以是其他形式，比如average pooling和L2-norm pooling。average pooling以前常用，但是现在实践证明max pooling的表现更好。<br>举例如下：<br><img src="pooling.jpg" alt=""></p>
<p>在池层的正向传递期间，通常要跟踪最大激活的索引（有时也称为交换机），以便使得反向传播期间梯度路径是有效的。</p>
<h5 id="池化操作的替代"><a href="#池化操作的替代" class="headerlink" title="池化操作的替代"></a>池化操作的替代</h5><p>有一种方法是为了追求简单性：所有卷积网络舍弃pooling 操作，而只支持重复CONV层的架构。为了减少输出的大小，可以在CONV层中使用更大的步幅。已经发现，丢弃池层(Discarding pooling layers)对于训练良好生成模型（如变分自动编码器（VAE）或生成对抗网络（GAN））很重要。 </p>
<h4 id="归一化层"><a href="#归一化层" class="headerlink" title="归一化层"></a>归一化层</h4><p>实践中归一化层的作用非常有限，往往不会被采用。</p>
<h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>完全连接层中的神经元与上一层中的所有激活具有完全连接，如常规神经网络所示。 因此，它们的激活可以用矩阵乘法后跟偏移偏移来计算。</p>
<h4 id="转换全连接层到卷积层"><a href="#转换全连接层到卷积层" class="headerlink" title="转换全连接层到卷积层"></a>转换全连接层到卷积层</h4><p>全连接层和卷积层的区别就是卷积层只和输入的部分区域相联系。但是，两种层中的神经元都是计算点积，于是实际上它们的函数形式是相同的，因此，将全连接层转换成卷积层是可能的。<br>1、对于每一个卷积层，都会有一个对应的全连接层和它实现相同的前向函数。它的权重矩阵将是一个大的矩阵，除了某些块（由于本地连接）之外，大部分都是零，其中许多块中的权重相等（由于参数共享）。<br>2、相反，任何FC层都可以转换为CONV层,例如，K=4096的FC层，其输入尺寸为7×7×512,这样的输入容积可以等效地表示为具有F=7，P = 0，S = 1，K=4096的CONV层。换句话说，我们将滤波器大小设置为输入的大小，因此输出将为1×1×4096，只有一个深度列“适合”输入体积，于是给出与初始FC层相同的结果。</p>
<p>以上两种转换中，实践中最为有用的还是从全连接层转换到卷积层。现在考虑这样一个网络结构：输入为224x224x3,通过5层池化层和一系列卷积层之后将其变为7x7x512的尺寸。在这个例子中，最后通过2层4096的全连接层和最后的有1000个神经元的全连接层计算得分函数，我们可以根据刚刚说的方法把这三层全连接层转换为卷积层。<br>1、对于第一层，改为用一个F=7的卷积层，输入为7x7x512，实现输出为1x1x4096。<br>2、第二层使用F=1的卷积层，使得输出仍然为1x1x4096。<br>3、最后一层仍替换为F=1的卷积层，最后使得输出为1x1x1000。</p>
<h2 id="卷积网络的架构"><a href="#卷积网络的架构" class="headerlink" title="卷积网络的架构"></a>卷积网络的架构</h2><p>前面介绍了卷积网络的主要类型的层，包括CONV,POOL,FC，RELU。下面介绍怎么将这些层结构组合成一个完整的卷积神经网络。</p>
<h3 id="Layer-Patterns"><a href="#Layer-Patterns" class="headerlink" title="Layer Patterns"></a>Layer Patterns</h3><p>最常见的卷积神经网络结构是堆砌几个CONV-RELU层，然后紧跟POOL层，重复这个结构直到输出的尺寸变为比较小。比较常见的结构是最后还加入一个全连接层作为输出层，其计算输出(比如得分函数)。最常见的卷积神经网络遵循以下的模式：<br>INPUT -&gt; [[CONV -&gt; RELU]<em>N -&gt; POOL?]</em>M -&gt; [FC -&gt; RELU]<em>K -&gt; FC<br>其中</em>表示重复次数,?表示可选，N&gt;=0,M&gt;=0,K&gt;=0，并且通常N&lt;=3，K&lt;3。<br>实际应用中，通常使用小的过滤器堆叠CONV层，而不是使用一个具有大过滤器的CONV层，这样使我们能够表达更强大的输入特征，并具有较少的参数。当然这也会带来一些缺点，如果我们打算进行反向传播，我们可能需要更多的内存来保存所有的中间CONV层结果。</p>
<h3 id="Layer-Sizing-Patterns"><a href="#Layer-Sizing-Patterns" class="headerlink" title="Layer Sizing Patterns"></a>Layer Sizing Patterns</h3><p>主要介绍一些关于尺寸的超参数设置技巧。</p>
<h4 id="Input-Layer"><a href="#Input-Layer" class="headerlink" title="Input Layer"></a>Input Layer</h4><p>通常设置为2的倍数。常见的有32，64,96,224,384,512。</p>
<h4 id="Conv-Layer"><a href="#Conv-Layer" class="headerlink" title="Conv Layer"></a>Conv Layer</h4><p>应该使用较小的滤波器尺寸，比如3x3或者5x5，S=1，设置P使得不改变输入尺寸，比如当F=3时，设置P=1。F=5，设置P=2。更一般化就是P=(F-1)/2使得输出尺寸不改变。更大的滤波器尺寸很少使用，通常是放在离输入层很近的位置。</p>
<h4 id="Pool-Layer"><a href="#Pool-Layer" class="headerlink" title="Pool Layer"></a>Pool Layer</h4><p>池化层的目的是进行降采样，通常的做法是使用F=2，S=2，使得输出为原来的1/4，这将会丢弃75%的激活。另一种不太常用的做法是F=3，S=2。更大的尺寸就不推荐了，这通常会导致更差的表现。</p>
<h4 id="CONV层为什么设置S-1？"><a href="#CONV层为什么设置S-1？" class="headerlink" title="CONV层为什么设置S=1？"></a>CONV层为什么设置S=1？</h4><p>实践中，S越小结果越好，所以设置S=1。另外，S=1使得我们仅在池化层实现下采样，在卷积层只改变深度。</p>
<h4 id="Padding的作用"><a href="#Padding的作用" class="headerlink" title="Padding的作用"></a>Padding的作用</h4><p>padding使得通过卷积层后尺寸不改变，这在实践中效果更好。如果不使用填充，这样输入每通过一个卷积层其尺寸都会减小一点，这样其边界信息会逐步丢失。</p>
<h4 id="内存限制"><a href="#内存限制" class="headerlink" title="内存限制"></a>内存限制</h4><p>有时由于内存限制，需要对网络结构进行一些折中。</p>
<h3 id="常见的实例"><a href="#常见的实例" class="headerlink" title="常见的实例"></a>常见的实例</h3><p><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_blank" rel="external">LeNet</a><br><a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="external">AlexNet</a><br><a href="http://arxiv.org/abs/1311.2901" target="_blank" rel="external">ZF Net</a><br><a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="external">GoogleNet</a><br><a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="external">VGGNet</a><br><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">ResNet</a></p>
<h3 id="计算的注意事项"><a href="#计算的注意事项" class="headerlink" title="计算的注意事项"></a>计算的注意事项</h3><p>构建ConvNet架构时要注意的最大瓶颈是内存瓶颈，GPU是有内存限制的。下面是三个主要的内存开销。<br>1、中间卷大小：这些是ConvNet每层激活的原始数量，以及它们的梯度（大小相等）。通常，大部分的激活都在ConvNet的早期层（即第一个Conv Layers）上。由于它们需要进行反向传播，因此它们将会保留下来，一个聪明的实现是只有在测试时间才能运行ConvNet，原则上可以通过将当前的激活存储在任何层上，并将以前的激活放在下面的层上。<br>2、参数大小：它们包括保存网络参数的数字，反向传播过程中的梯度，如果优化使用moemntum，Adagrad或RMSProp，通常也是一个缓存。因此，单独存储参数矢量的存储器通常必须乘以至少3个左右的系数。<br>3、每个ConvNet实现都必须维护杂项内存，例如图像数据批次，也可能是其扩充版本等。在出现内存不足的情况下，一个通常的做法是减小batch size的大小，因为大多数内存通常被激活所消耗。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、<a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">cs231n 2017 cnn notes</a><br>2、<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture5.pdf" target="_blank" rel="external">cs231n 2017 cnn slides</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/09/30/cs231n-Convolutional-Neural-Networks/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cs231n-Backpropagation" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/30/cs231n-Backpropagation/">Backpropagation</a>
    </h1>
  

        
        <a href="/2017/09/30/cs231n-Backpropagation/" class="archive-article-date">
  	<time datetime="2017-09-30T08:18:37.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-09-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#引言"><span class="toc-text">引言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#概念"><span class="toc-text">概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#简单的解释和举例"><span class="toc-text">简单的解释和举例</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模块化操作"><span class="toc-text">模块化操作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实践中的一些技巧"><span class="toc-text">实践中的一些技巧</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#扩展到矢量计算梯度"><span class="toc-text">扩展到矢量计算梯度</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#计算矩阵相乘的梯度"><span class="toc-text">计算矩阵相乘的梯度</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>主要介绍一些关于backpropagation(反向传播)的知识，反向传播主要就是利用chain rule(链式法则)计算关于weights的梯度，通过梯度计算的结果对网络进行梯度下降的优化。这对于我们设计和debug神经网络都很有用处。<br>值得注意的是，通常情况下我们计算对于W的梯度以便根据梯度下降进行参数更新，但是在一些特殊情况下，我们也有可能计算关于输入x的梯度，目的是解释和可视化神经网络的过程。</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>当我们使用前馈神经网络接收输入x并产生输出y时，信息通过网络向前流动。输入x提供初始信息，然后传播到每一层的隐藏单元，最后产生输出y。这叫做 前向传播(forward prapagation)。而在训练过程中，前向传播可以持续向前知道计算出代价函数。反向传播算法则允许来自代价函数的信息通过网络向后流动，以便于计算梯度。</p>
<h1 id="简单的解释和举例"><a href="#简单的解释和举例" class="headerlink" title="简单的解释和举例"></a>简单的解释和举例</h1><p>实际上，每个变量的导数反映了整个表达式对这个变量的变化的敏感程度。其定义如下：<br><img src="interpratation.jpg" alt=""><br>    比较常见的有以下3种函数。<br><img src="multiply.jpg" alt=""><br><img src="add.jpg" alt=""><br><img src="max.jpg" alt=""></p>
<p>以上这些是针对简单的情况，针对复杂的复合函数的情况，往往需要使用链式法则来求解梯度。</p>
<p>一种比较直观的理解是：反向传播可以看做一组彼此之间通过梯度信号通信的门，每个门可以选择让通过自己的信号增加或者减小，并且可以决定增加或者减小的幅度。最后的目的是通过改变输入，经过这一系列门之后使得总的输出最大或者最小。</p>
<h1 id="模块化操作"><a href="#模块化操作" class="headerlink" title="模块化操作"></a>模块化操作</h1><p>在实际计算反向传播的时候，我们可以通过一些模块化的操作使得计算和理解都更为简便直观。<br>如下面所示的一个例子：<br><img src="sigmoid.jpg" alt=""><br>通过将此函数分解为一系列函数的复合：<br><img src="sigmoid2.jpg" alt=""><br>最后的一个计算过程如下：<br><img src="sigmoid3.jpg" alt=""><br>可以看出这个流程还是比较复杂，但是通过将其中的一个sigmoid函数模块化之后，我们会得到更加简明的结果。<br><img src="sigmoid4.jpg" alt=""></p>
<p>最后编程实现如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">w = [<span class="number">2</span>,<span class="number">-3</span>,<span class="number">-3</span>] <span class="comment"># assume some random weights and data</span></div><div class="line">x = [<span class="number">-1</span>, <span class="number">-2</span>]</div><div class="line"></div><div class="line"><span class="comment"># forward pass</span></div><div class="line">dot = w[<span class="number">0</span>]*x[<span class="number">0</span>] + w[<span class="number">1</span>]*x[<span class="number">1</span>] + w[<span class="number">2</span>]</div><div class="line">f = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-dot)) <span class="comment"># sigmoid function</span></div><div class="line"></div><div class="line"><span class="comment"># backward pass through the neuron (backpropagation)</span></div><div class="line">ddot = (<span class="number">1</span> - f) * f <span class="comment"># gradient on dot variable, using the sigmoid gradient derivation</span></div><div class="line">dx = [w[<span class="number">0</span>] * ddot, w[<span class="number">1</span>] * ddot] <span class="comment"># backprop into x</span></div><div class="line">dw = [x[<span class="number">0</span>] * ddot, x[<span class="number">1</span>] * ddot, <span class="number">1.0</span> * ddot] <span class="comment"># backprop into w</span></div><div class="line"><span class="comment"># we're done! we have the gradients on the inputs to the circuit</span></div></pre></td></tr></table></figure></p>
<h1 id="实践中的一些技巧"><a href="#实践中的一些技巧" class="headerlink" title="实践中的一些技巧"></a>实践中的一些技巧</h1><p>1、在实践中，我们需要根据实际情况对整个函数进行拆分，分成便于计算梯度的函数的一个复合。<br>2、为了反向计算方便，通常在正向计算的时候需要保存一些中间结果，便于反向计算梯度的时候使用它们。<br>3、前向计算需要使用x,y变量多次，在反向传播的时候应该用+=而不是=来累加结果。</p>
<h1 id="扩展到矢量计算梯度"><a href="#扩展到矢量计算梯度" class="headerlink" title="扩展到矢量计算梯度"></a>扩展到矢量计算梯度</h1><p>对矢量计算梯度的方法和上面所提及的并无二致，但是在处理时可能需要加入转置运算以便维数匹配。</p>
<h2 id="计算矩阵相乘的梯度"><a href="#计算矩阵相乘的梯度" class="headerlink" title="计算矩阵相乘的梯度"></a>计算矩阵相乘的梯度</h2><p>下面这个例子里面就是根据维数匹配的原则对表达式加入一些转置的操作。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># forward pass</span></div><div class="line">W = np.random.randn(<span class="number">5</span>, <span class="number">10</span>)</div><div class="line">X = np.random.randn(<span class="number">10</span>, <span class="number">3</span>)</div><div class="line">D = W.dot(X)</div><div class="line"></div><div class="line"><span class="comment"># now suppose we had the gradient on D from above in the circuit</span></div><div class="line">dD = np.random.randn(*D.shape) <span class="comment"># same shape as D</span></div><div class="line">dW = dD.dot(X.T) <span class="comment">#.T gives the transpose of the matrix</span></div><div class="line">dX = W.T.dot(dD)</div></pre></td></tr></table></figure></p>
<p>而对于一些一时难以看出梯度表达式的情况，可以利用实际的比较小的矩阵手动演算，根据结果推理出合适的表达式。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>1、<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf" target="_blank" rel="external">cs231n 2017 lecture4 slides</a><br>2、<a href="http://cs231n.github.io/optimization-2/" target="_blank" rel="external">cs231n 2017 backpropagation notes</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/09/30/cs231n-Backpropagation/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-java-string" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/24/java-string/">String、StringBuider and StringBuffer</a>
    </h1>
  

        
        <a href="/2017/09/24/java-string/" class="archive-article-date">
  	<time datetime="2017-09-24T07:58:16.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-09-24</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#结构"><span class="toc-text">结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#一些简单的使用建议"><span class="toc-text">一些简单的使用建议</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#性能测试"><span class="toc-text">性能测试</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考资料"><span class="toc-text">参考资料</span></a></li></ol>
</div>

        <p>主要是对Java中的String,StringBuilder和StringBuffer类进行分析对比</p>
<h1 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h1><p>String,StringBuilder和StringBuffer都实现了CharSequence接口，用来进行字符串的相关操作，并且都定义为final class，意味着都不能够被继承，并且内部都是用char数组实现的。这里有一个显著的区别是：String的 char数组被定义为 final，意味着一旦确定是不可改变的，我们每当对字符串进行一些操作，比如得到substring,toLowerCase等时，最后都会new一个新的String对象；而 StringBuilder和StringBuffer的内部的char数组没有final修饰，它们都继承自AbstractStringBuilder，内部的char数组可以随时修改，动态扩容。其中StringBuilder和StringBuffer的一个显著区别是：StringBuffer的很多方法会用synchronized修饰，意味着StringBuffer是线程安全的，适合在多线程的时候使用。除了这个区别，StringBuilder和StringBuffer的其它一些方法基本上是一致的，感觉StringBuffer其实就是StringBuilder的一个多线程版本。</p>
<h1 id="一些简单的使用建议"><a href="#一些简单的使用建议" class="headerlink" title="一些简单的使用建议"></a>一些简单的使用建议</h1><p>1、当不需要改变字符串的内容时，尽量使用String类。因为它是不可变的。<br>2、当需要改变字符串的内容，比如说对大量字符串进行一些拼接操作，这时候如果用String的话就比较麻烦，每次都会生成一个新的String，这将浪费大量的内存空间，并且需要多次垃圾回收操作，严重影响速度。一般的情况下是选用StringBuilder类，可以原地进行一些操作，比较方便快速。多线程情况下选择线程安全的StringBuffer类。在不考虑多线程的情况下，StringBuilder的效率是比StringBuffer高的。</p>
<h1 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h1><p>简单测试了String,StringBuilder和StringBuffer的字符串拼接效率。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> N = <span class="number">100000</span>;</div><div class="line">        <span class="keyword">long</span> t;</div><div class="line">        &#123;</div><div class="line">            String s=<span class="keyword">new</span> String();</div><div class="line">            t=System.currentTimeMillis();</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i=N;i--&gt;<span class="number">0</span>;)&#123;</div><div class="line">                s+=<span class="string">"Test"</span>;</div><div class="line">            &#125;</div><div class="line">            System.out.println(<span class="string">"String Time:"</span>+(System.currentTimeMillis()-t)+<span class="string">"ms"</span>);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        &#123;</div><div class="line">            StringBuffer sb = <span class="keyword">new</span> StringBuffer();</div><div class="line">            t = System.currentTimeMillis();</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = N; i --&gt; <span class="number">0</span> ;) &#123;</div><div class="line">                sb.append(<span class="string">"Test"</span>);</div><div class="line">            &#125;</div><div class="line">            System.out.println(<span class="string">"StringBuffer Time:"</span>+(System.currentTimeMillis() - t)+<span class="string">"ms"</span>);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        &#123;</div><div class="line">            StringBuilder sb = <span class="keyword">new</span> StringBuilder();</div><div class="line">            t = System.currentTimeMillis();</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = N; i --&gt; <span class="number">0</span> ;) &#123;</div><div class="line">                sb.append(<span class="string">"Test"</span>);</div><div class="line">            &#125;</div><div class="line">            System.out.println(<span class="string">"StringBuilder Time:"</span>+(System.currentTimeMillis() - t)+<span class="string">"ms"</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行结果：<br><img src="compare.jpg" alt=""></p>
<p>拼接空字符串的结果：<br><img src="compare2.jpg" alt=""></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://stackoverflow.com/questions/2971315/string-stringbuffer-and-stringbuilder" target="_blank" rel="external">stackoverflow question</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/Java//" class="article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/09/24/java-string/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cs231n-lecture-2-and-3" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/24/cs231n-lecture-2-and-3/">Image Classfication(kNN and Linear Classfication)</a>
    </h1>
  

        
        <a href="/2017/09/24/cs231n-lecture-2-and-3/" class="archive-article-date">
  	<time datetime="2017-09-24T03:37:45.475Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-09-24</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#图像分类的几大挑战"><span class="toc-text">图像分类的几大挑战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#图像分类的任务"><span class="toc-text">图像分类的任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#具体分类方法"><span class="toc-text">具体分类方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#较为传统的方法"><span class="toc-text">较为传统的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据驱动的方法-Data-Driven-Approach"><span class="toc-text">数据驱动的方法(Data-Driven Approach)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Nearest-Neighbor（最近邻法）"><span class="toc-text">Nearest Neighbor（最近邻法）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#K-Nearest-Neighbors-K最近邻法"><span class="toc-text">K-Nearest Neighbors(K最近邻法)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#如何设置超参数？"><span class="toc-text">如何设置超参数？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#方法的缺陷"><span class="toc-text">方法的缺陷</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Linear-Classification-线性分类器"><span class="toc-text">Linear Classification(线性分类器)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Score-function"><span class="toc-text">Score function</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#注意事项"><span class="toc-text">注意事项</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#解释线性分类器"><span class="toc-text">解释线性分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#将图像作为高维点分析"><span class="toc-text">将图像作为高维点分析</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#将线性分类器解释为模板匹配"><span class="toc-text">将线性分类器解释为模板匹配</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#处理b参数的小技巧"><span class="toc-text">处理b参数的小技巧</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#图像预处理"><span class="toc-text">图像预处理</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Loss-Function-损失函数"><span class="toc-text">Loss Function(损失函数)</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Multiclass-Support-Vector-Machine-loss"><span class="toc-text">Multiclass Support Vector Machine loss</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Softmax-loss"><span class="toc-text">Softmax loss</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#SVM-loss-和-Softmax-loss-的比较"><span class="toc-text">SVM loss 和 Softmax loss 的比较</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Optimization-优化"><span class="toc-text">Optimization(优化)</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Random-Search-随机搜索"><span class="toc-text">Random Search(随机搜索)</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Random-Local-Search"><span class="toc-text">Random Local Search</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Following-the-Gradient"><span class="toc-text">Following the Gradient</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#如何计算梯度"><span class="toc-text">如何计算梯度</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Numerical-Gradient"><span class="toc-text">Numerical Gradient</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Computing-the-gradient-analytically-with-Calculus"><span class="toc-text">Computing the gradient analytically with Calculus</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Gradient-Descent"><span class="toc-text">Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Mini-batch-gradient-descent"><span class="toc-text">Mini-batch gradient descent</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Stochastic-Gradient-Descent-SGD"><span class="toc-text">Stochastic Gradient Descent(SGD)</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-text">参考资料</span></a></li></ol>
</div>

        <p>主要是对图像分类的流程的总体介绍,主要介绍了kNN和Linear Classfication算法。和cs231n的 lecture_2 和 lecture_3对应。</p>
<h2 id="图像分类的几大挑战"><a href="#图像分类的几大挑战" class="headerlink" title="图像分类的几大挑战"></a>图像分类的几大挑战</h2><p>1、Viewpoint Variation:相机移动会造成像素点发生改变。<br>2、Illumination:同一物体在不同光照条件下差别也比较大。<br>3、Deformation:同一物体的不同形变也会给分类造成较大影响。<br>4、Occlusion:遮挡问题，有时只能看见物体局部，难以分辨。<br>5、Background Clutter:背景干扰，比如动物保护色等让人难以分辨。<br>6、Intraclass Variation:同一物种个体之间差异也大。</p>
<h2 id="图像分类的任务"><a href="#图像分类的任务" class="headerlink" title="图像分类的任务"></a>图像分类的任务</h2><p>图像分类的任务就是输入一幅图像，返回其分类结果。此类任务是难以通过显示编程<br>制定一些规则来进行的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify_image</span><span class="params">(image)</span>:</span></div><div class="line">    <span class="comment">#do something</span></div><div class="line">    <span class="keyword">return</span> label</div></pre></td></tr></table></figure>
<h2 id="具体分类方法"><a href="#具体分类方法" class="headerlink" title="具体分类方法"></a>具体分类方法</h2><h3 id="较为传统的方法"><a href="#较为传统的方法" class="headerlink" title="较为传统的方法"></a>较为传统的方法</h3><p>通过边缘检测，角点检测等方法找出一些特征，然后对特征进行一些统计得出分类结果。</p>
<h3 id="数据驱动的方法-Data-Driven-Approach"><a href="#数据驱动的方法-Data-Driven-Approach" class="headerlink" title="数据驱动的方法(Data-Driven Approach)"></a>数据驱动的方法(Data-Driven Approach)</h3><p>大致的流程就是：<br>1、准备图像和标签一一对应的数据集。<br>2、通过机器学习的方法去训练一个分类的模型。<br>3、在另外的数据上去检验这个模型的准确性。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#train a model</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(images,labels)</span>:</span></div><div class="line">    <span class="comment">#Machine Learning</span></div><div class="line">    <span class="keyword">return</span> model</div><div class="line"></div><div class="line"><span class="comment">#predict the label</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(model,test_images)</span>:</span></div><div class="line">    <span class="comment">#Use trained model to predict labels</span></div><div class="line">    <span class="keyword">return</span> test_labels</div></pre></td></tr></table></figure></p>
<h4 id="Nearest-Neighbor（最近邻法）"><a href="#Nearest-Neighbor（最近邻法）" class="headerlink" title="Nearest Neighbor（最近邻法）"></a>Nearest Neighbor（最近邻法）</h4><p>1、在训练阶段只是将图片和标签载入内存，不做任何额外操作。<br>2、预测阶段，将待预测图片和之前载入的图片逐一比较，选取和待预测图片最相似的训练图片的标签作为预测结果。</p>
<p>如何判断相似性？<br>L1 Distance or L2 Distance or others?<br>这里简单使用 L1 distance</p>
<p>优点：思想简单，编程实现容易。<br>缺点：准确率较低，而且训练时只是读入数据，测试时需要逐一比较，耗时与数据集大小成线性关系，与我们的初衷不符。</p>
<h4 id="K-Nearest-Neighbors-K最近邻法"><a href="#K-Nearest-Neighbors-K最近邻法" class="headerlink" title="K-Nearest Neighbors(K最近邻法)"></a>K-Nearest Neighbors(K最近邻法)</h4><p>其基本思想与 Nearest Neighbor一致，只是我们需要保留前k个最相似的图片的结果，然后在这k个结果里面做一个决策。<br>这里就会出现两个问题：<br>1、如何选取合适的k值使得预测结果更准确？<br>2、如何选取distance的算法使得预测结果更准确？<br>其实这些都叫做 hyperparameters(超参数)，需要我们预先设置。</p>
<h5 id="如何设置超参数？"><a href="#如何设置超参数？" class="headerlink" title="如何设置超参数？"></a>如何设置超参数？</h5><p>方法1：选取超参数使得其在训练集上的效果最好。<br>这个方法存在的一个显著问题就是：k=1总是能够使得其在训练集上的效果最好。这种方法显然不可取。<br>方法2：将数据集分为训练集和测试集两选取超参数使得在测试集上的效果最好这种方法避免了前一个问题，但是又带来了一个新问题，就是它不能预判断算法在新的数据集上的表现情况。<br>方法3：分为训练集、验证集和测试集，以验证集选取超参数，在测试集上验证。这种方法比前两种方法都好一点。有效避免了之前的问题。<br>方法4：交叉验证。将数据集分为n份，分别以其中一份作为验证集，其他作为训练集，最后得到n个结果，再对结果做一个平均。这种方法是目前来说最好的。这种方法主要还是用于训练样本较小的情况下，对于较大的训练样本，其实方法3就能达到较好效果，用该方法会浪费不少时间。</p>
<h5 id="方法的缺陷"><a href="#方法的缺陷" class="headerlink" title="方法的缺陷"></a>方法的缺陷</h5><p>实际上k-Nearest Neighbor这种方法从来没有被实际采用过，主要有以下几个原因：<br>1、正如上面提及过的，时间效率太低。<br>2、通过像素差值判断相似性本身就有很大的问题。</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>1、在图像分类问题上，我们在训练集上训练，之后在测试集上验证结果。对于其他的机器学习问题也是如此。<br>2、距离度量方式和K的都是超参数，需要我们事先确定。<br>3、用验证集确定超参数，最后在测试集上测试结果。</p>
<h4 id="Linear-Classification-线性分类器"><a href="#Linear-Classification-线性分类器" class="headerlink" title="Linear Classification(线性分类器)"></a>Linear Classification(线性分类器)</h4><p>这种方法将比之前的方法都更有效，并且可以以此来引入之后的Neural Networks(神经网络)和Convolutional Neural Networks(卷积神经网络)。主要由两部分组成：<br>1、score function 实现从原始图像数据到各个标签的得分的一个映射。<br>2、loss function 用来定量比较分析预测的得分和实际的label的差距。<br>我们的最终目的就是通过优化，使得loss function最小，最后确定的score function 的参数作为最终的模型的参数，用来预测label。</p>
<h5 id="Score-function"><a href="#Score-function" class="headerlink" title="Score function"></a>Score function</h5><p>f(xi,W,b)=W*xi+b</p>
<h6 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h6><p>1、W*xi 的结果是一个向量，每个元素代表对应标签的一个预测得分。<br>2、我们的目标就是通过训练确定W和b，使得预测结果和真实结果最为接近。也就是使得对于一个输入图像xi，我们要使得其正确分类的得分大于错误分类的得分。<br>3、这种方法的好处在于训练集只是用于训练确定参数W和b，我们最后只需要保留W，b的值。之后对于每一幅输入图像，只需要带入确定的W和b值即可预测出其分类结果。所以这种方法的时间效率远大于之前的NN和kNN算法。<br>4、实际上，之后的神经网络和卷积神经网络的方法和线性分类器的思想是一致的，只是score function 和 loss function 是另外的函数形式。</p>
<h5 id="解释线性分类器"><a href="#解释线性分类器" class="headerlink" title="解释线性分类器"></a>解释线性分类器</h5><p>线性分类器实际上就是计算一个图像各个像素各个通道的加权和。加权的结果取决于我们设置的W，b的值。<br><img src="imagemap.jpg" alt=""></p>
<h6 id="将图像作为高维点分析"><a href="#将图像作为高维点分析" class="headerlink" title="将图像作为高维点分析"></a>将图像作为高维点分析</h6><p>一幅32x32x3的图像可以被拉伸为1x3072的高维点来表示。所以数据集中的图像可以看做一系列高维点。因为我们定义每个分类的score是所有像素点的加权和，实际上每个分类的分数就是这个高维点的线性函数。虽然无法可视化3072维的数据，但是当我们把3072维压缩成2维，就可以尝试着可视化线性分类器的操作。<br><img src="pixelspace.jpg" alt=""></p>
<h6 id="将线性分类器解释为模板匹配"><a href="#将线性分类器解释为模板匹配" class="headerlink" title="将线性分类器解释为模板匹配"></a>将线性分类器解释为模板匹配</h6><p>这种解释将W的每一行看做是对应的分类的一个模板，也就是对应的分类的一个原型。实际上每个分类的score就是将输入图像与模板进行比较(这里是通过点积的形式)，最后看输入图像和哪个模板最匹配。<br>这其实和最近邻算法类似，主要区别在：<br>1、最近邻算法是将输入图像和每幅图像作比较，而线性分类器是将输入图像和模板图像相比较。<br>2、最近邻算法通过L1或者L2距离判断相似性，线性分类器通过点积判断相似性。</p>
<p>下面是根据CIFAR-10训练得到的模板图像<br><img src="templates.jpg" alt=""></p>
<h6 id="处理b参数的小技巧"><a href="#处理b参数的小技巧" class="headerlink" title="处理b参数的小技巧"></a>处理b参数的小技巧</h6><p>实际上我们可以通过对W 矩阵增加1列，对xi增加1行的方法，将<br>f(xi,W,b)=W<em>xi+b ——&gt; f(xi,W)=W</em>xi<br>这样就只用训练一个参数W。<br>如下图所示：<br><img src="wb.jpg" alt=""></p>
<h6 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h6><p>在应用中常常需要对图像数据进行预处理，比如<br>[0,255]-&gt;[-127,127]-&gt;[-1,1],关键在于让零值居中，使得数据集中。</p>
<h5 id="Loss-Function-损失函数"><a href="#Loss-Function-损失函数" class="headerlink" title="Loss Function(损失函数)"></a>Loss Function(损失函数)</h5><p>损失函数的作用是来评价在训练集上分类结果的好坏，当分类结果接近真实结果时，损失函数自然就小，反之则大。损失函数有多种计算方法，下面分别从阐述。</p>
<h6 id="Multiclass-Support-Vector-Machine-loss"><a href="#Multiclass-Support-Vector-Machine-loss" class="headerlink" title="Multiclass Support Vector Machine loss"></a>Multiclass Support Vector Machine loss</h6><p>设置 SVM loss的目的是为了让正确分类的得分与错误分类的得分至少相差某一个确定的δ,<br>简单来说，其计算公式如下：<br><img src="svm_loss.jpg" alt=""></p>
<p>更多细节可以参考<br><a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="external">cs231n spring2017 linear_classify notes</a></p>
<p>其实概括来说就是SVM loss 希望让正确分类的得分大于错误分类的得分至少δ，如果没有 达到要求，那么我们就计算一个loss,如果达到要求，那么loss为0。针对线性分类器，我们有如下的计算SVM loss的公式：<br><img src="linear_svm_loss.jpg" alt=""></p>
<p>其实形如 max(0,-)这样的损失函数叫做 hinge loss,并且指数项不一定是1次，有时为了让错误结果更明显，可能用指数项为2次得到的效果会更好。具体使用哪种可以通过前面提及的交叉验证来确定。确定了损失函数之后，接下来的工作就是找到一种优化的方法，使得loss尽可能小，然后确定W。</p>
<p>上面提及的SVM loss还存在一个问题：假设我们有一个数据集和W使得对于每一个图像i都满足Li=0,那么显然W 不是唯一的。因为这样的话 λW(λ&gt;1) 也能使得Li=0。那这样我们该选择哪个W作为最终结果呢？这样对于正确的分类没有影响，但是对于错误的分类，就会将loss放大λ倍。</p>
<p>为了解决以上的问题，引入了一个 regularization penalty(正则惩罚项) R(W)。通常的做法是利用L2 norm 来限制W中每个元素的大小。<br>如下所示：<br><img src="l2_regularization.jpg" alt=""></p>
<p>注意这里的R(W)只和W有关，而和数据集无关。这样SVM loss就有 data loss和 regularization loss 两部分组成：<br><img src="loss.jpg" alt=""></p>
<p>在线性分类器中，其形式如下：<br><img src="linear_loss.jpg" alt=""></p>
<p>λ作为超参数通常也是要通过交叉验证来确定。</p>
<p>引入正则惩罚项的一个最大的好处是增强模型的泛化能力，让最终的结果尽可能受到更多参数的影响，能够减小过拟合的情况。另外值得注意的是，当引入正则惩罚之后，Loss就不可能为0了，因为如果Loss为0，那么意味着W=0，那将毫无意义。接下来我们将要考虑的就是通过什么方法来使得loss尽可能小。</p>
<p>如何确定超参数δ，实际上我们可以简单设置δ为1。其实δ和λ对于loss的影响是一致的，所以我们其实只需要确定λ就好。</p>
<h6 id="Softmax-loss"><a href="#Softmax-loss" class="headerlink" title="Softmax loss"></a>Softmax loss</h6><p>这是另一种计算损失函数的方法，和SVM 计算每个分类得分的方法不同，Softmax分类器是对属于每个分类的可能性做评估。<br>在这里，将每个分类的得分转化为属于这个分类的概率，并且用 cross-entropy loss(交叉熵损失)代替hinge loss。<br>计算形式如下：<br><img src="softmax.jpg" alt=""></p>
<p>其中softmax function 形如以下：<br><img src="softmax_function.jpg" alt=""></p>
<p>其中的一些理论不再阐述。<br>实践的技巧：由于要计算指数项，除以大数可能造成数值不稳定，所以需要归一化的技巧，可以如下操作：<br><img src="calculate_trick.jpg" alt=""></p>
<p>比较常用的方法是设置<br><img src="c.jpg" alt="">  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">f = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>]) <span class="comment"># example with 3 classes and each having large scores</span></div><div class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># Bad: Numeric problem, potential blowup</span></div><div class="line"></div><div class="line"><span class="comment"># instead: first shift the values of f so that the highest number is 0:</span></div><div class="line">f -= np.max(f) <span class="comment"># f becomes [-666, -333, 0]</span></div><div class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># safe to do, gives the correct answer</span></div></pre></td></tr></table></figure>
<h6 id="SVM-loss-和-Softmax-loss-的比较"><a href="#SVM-loss-和-Softmax-loss-的比较" class="headerlink" title="SVM loss 和 Softmax loss 的比较"></a>SVM loss 和 Softmax loss 的比较</h6><p><img src="compare.jpg" alt=""></p>
<p>具体分析见<br><a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="external">cs231n spring2017 linear_classify notes</a></p>
<h5 id="Optimization-优化"><a href="#Optimization-优化" class="headerlink" title="Optimization(优化)"></a>Optimization(优化)</h5><p>确定了score function和 loss function之后，我们要做的就是通过优化使得 loss function 尽可能小，然后确定 score function的参数。不仅是针对线性分类器，其他分类方法的整个流程也是一样的，只是score function 和 loss function可能有所不同。<br>主要有如下一些策略：</p>
<h6 id="Random-Search-随机搜索"><a href="#Random-Search-随机搜索" class="headerlink" title="Random Search(随机搜索)"></a>Random Search(随机搜索)</h6><p>顾名思义就是随机设置W的数值，每次记录loss,迭代若干次，找出使得loss最小的结果。显然，迭代次数越多，能够尝试的参数就会越多，就越有可能找出更为准确的参数，但是永远不可能找出所有的结果。并且我们是盲目地找结果，效率较低，这显然过于笨拙。<br>但是这种方法也能给我们一些启示：我们能不能找到一种方法，从一个随机的参数W开始，进行优化，每次迭代使得loss降低一些？这给下一个策略提供了思路。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># assume X_train is the data where each column is an example (e.g. 3073 x 50,000)</span></div><div class="line"><span class="comment"># assume Y_train are the labels (e.g. 1D array of 50,000)</span></div><div class="line"><span class="comment"># assume the function L evaluates the loss function</span></div><div class="line"></div><div class="line">bestloss = float(<span class="string">"inf"</span>) <span class="comment"># Python assigns the highest possible float value</span></div><div class="line"><span class="keyword">for</span> num <span class="keyword">in</span> xrange(<span class="number">1000</span>):</div><div class="line">  W = np.random.randn(<span class="number">10</span>, <span class="number">3073</span>) * <span class="number">0.0001</span> <span class="comment"># generate random parameters</span></div><div class="line">  loss = L(X_train, Y_train, W) <span class="comment"># get the loss over the entire training set</span></div><div class="line">  <span class="keyword">if</span> loss &lt; bestloss: <span class="comment"># keep track of the best solution</span></div><div class="line">    bestloss = loss</div><div class="line">    bestW = W</div><div class="line">  <span class="keyword">print</span> <span class="string">'in attempt %d the loss was %f, best %f'</span> % (num, loss, bestloss)</div><div class="line"></div><div class="line"><span class="comment"># prints:</span></div><div class="line"><span class="comment"># in attempt 0 the loss was 9.401632, best 9.401632</span></div><div class="line"><span class="comment"># in attempt 1 the loss was 8.959668, best 8.959668</span></div><div class="line"><span class="comment"># in attempt 2 the loss was 9.044034, best 8.959668</span></div><div class="line"><span class="comment"># in attempt 3 the loss was 9.278948, best 8.959668</span></div><div class="line"><span class="comment"># in attempt 4 the loss was 8.857370, best 8.857370</span></div><div class="line"><span class="comment"># in attempt 5 the loss was 8.943151, best 8.857370</span></div><div class="line"><span class="comment"># in attempt 6 the loss was 8.605604, best 8.605604</span></div><div class="line"><span class="comment"># ... (trunctated: continues for 1000 lines)</span></div></pre></td></tr></table></figure></p>
<h6 id="Random-Local-Search"><a href="#Random-Local-Search" class="headerlink" title="Random Local Search"></a>Random Local Search</h6><p>这种方法的思想就是随机给W设置一个初始值，然后在此基础上给一个增量变为W+δW,比较两处的loss,如果增加后更小，则更新W，否则维持原状。这种方法相比前一种方法少了盲目性，效果会好一些，但是计算量仍旧很大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">W = np.random.randn(<span class="number">10</span>, <span class="number">3073</span>) * <span class="number">0.001</span> <span class="comment"># generate random starting W</span></div><div class="line">bestloss = float(<span class="string">"inf"</span>)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1000</span>):</div><div class="line">  step_size = <span class="number">0.0001</span></div><div class="line">  Wtry = W + np.random.randn(<span class="number">10</span>, <span class="number">3073</span>) * step_size</div><div class="line">  loss = L(Xtr_cols, Ytr, Wtry)</div><div class="line">  <span class="keyword">if</span> loss &lt; bestloss:</div><div class="line">    W = Wtry</div><div class="line">    bestloss = loss</div><div class="line">  <span class="keyword">print</span> <span class="string">'iter %d loss is %f'</span> % (i, bestloss)</div></pre></td></tr></table></figure>
<h6 id="Following-the-Gradient"><a href="#Following-the-Gradient" class="headerlink" title="Following the Gradient"></a>Following the Gradient</h6><p>第二种方法虽然效率比第一种稍高，但是在选择δW的时候还是随机的，效率也较低，而实际上是可以有一定的策略选择δW的。比如可以通过计算梯度，沿着梯度小于0的方向就能使得loss变小。<br><img src="gradient.jpg" alt=""></p>
<h5 id="如何计算梯度"><a href="#如何计算梯度" class="headerlink" title="如何计算梯度"></a>如何计算梯度</h5><p>从以上分析看出，前两种优化策略都显得盲目，效率较低，而根据梯度来进行优化显然更为合理。那么梯度怎么去计算呢？主要有两种方法：1、numerical gradient,通过定义去计算梯度，其优点是思想简单，缺点是速度慢并且只是近似值，精度取决于δ的大小。2、analytic gradient，根据分析得出偏导数的表达式计算，其优点是快速准确，缺点就是容易出错。接下来分别介绍这两种算法。</p>
<h6 id="Numerical-Gradient"><a href="#Numerical-Gradient" class="headerlink" title="Numerical Gradient"></a>Numerical Gradient</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_numerical_gradient</span><span class="params">(f, x)</span>:</span></div><div class="line">  <span class="string">""" </span></div><div class="line"><span class="string">  a naive implementation of numerical gradient of f at x </span></div><div class="line"><span class="string">  - f should be a function that takes a single argument</span></div><div class="line"><span class="string">  - x is the point (numpy array) to evaluate the gradient at</span></div><div class="line"><span class="string">  """</span> </div><div class="line"></div><div class="line">  fx = f(x) <span class="comment"># evaluate function value at original point</span></div><div class="line">  grad = np.zeros(x.shape)</div><div class="line">  h = <span class="number">0.00001</span></div><div class="line"></div><div class="line">  <span class="comment"># iterate over all indexes in x</span></div><div class="line">  it = np.nditer(x, flags=[<span class="string">'multi_index'</span>], op_flags=[<span class="string">'readwrite'</span>])</div><div class="line">  <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</div><div class="line"></div><div class="line">    <span class="comment"># evaluate function at x+h</span></div><div class="line">    ix = it.multi_index</div><div class="line">    old_value = x[ix]</div><div class="line">    x[ix] = old_value + h <span class="comment"># increment by h</span></div><div class="line">    fxh = f(x) <span class="comment"># evalute f(x + h)</span></div><div class="line">    x[ix] = old_value <span class="comment"># restore to previous value (very important!)</span></div><div class="line"></div><div class="line">    <span class="comment"># compute the partial derivative</span></div><div class="line">    grad[ix] = (fxh - fx) / h <span class="comment"># the slope</span></div><div class="line">    it.iternext() <span class="comment"># step to next dimension</span></div><div class="line"></div><div class="line">  <span class="keyword">return</span> grad</div></pre></td></tr></table></figure>
<p>实际使用中常用的公式是 [f(x+h)-f(x-h)]/2h<br>在更新W的时候，是沿着负梯度的方向更新的，这样能够确保每次使得loss在降低。<br>选择合适的step size 很重要，也就是 learning rate(学习率)，这也是机器学习中的一个超参数。learning rate过低，使得更新缓慢，时间效率低，而learning rate如果过高，可能使得overstep(即越过最低点到达一个很糟糕的地方)。<br>更新梯度与参数数量成线性关系，对于30730个参数，我们需要对30731个参数验证梯度，最后只在1个参数上更新，对于参数少的情况着无关紧要，但是当参数特别多时，这就比较麻烦了，所以需要更好的办法。</p>
<h6 id="Computing-the-gradient-analytically-with-Calculus"><a href="#Computing-the-gradient-analytically-with-Calculus" class="headerlink" title="Computing the gradient analytically with Calculus"></a>Computing the gradient analytically with Calculus</h6><p>这种方法因为有确定的公式，所以计算速度很快，但是容易出错。常常会将这两种方法进行比较以验证梯度计算方法的正确性，这叫做 gradient check(梯度检查)。不同的loss function自然有不同的梯度表达式。</p>
<h5 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h5><p>计算出梯度之后，我们就将沿着梯度下降的方向更新参数。这就叫做Gradient Descent(梯度下降)。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Vanilla Gradient Descent</span></div><div class="line"></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">  weights_grad = evaluate_gradient(loss_fun, data, weights)</div><div class="line">  weights += - step_size * weights_grad <span class="comment"># perform parameter update</span></div></pre></td></tr></table></figure></p>
<p>之后可能会有其他方法来优化这一过程，但是其核心思想都是梯度下降。</p>
<h6 id="Mini-batch-gradient-descent"><a href="#Mini-batch-gradient-descent" class="headerlink" title="Mini-batch gradient descent"></a>Mini-batch gradient descent</h6><p>在训练集比较大的情况下，如果每执行一次单个参数的更新就对每个数据的loss进行计算，显得效率太低。常用的解决方法是计算批量数据之间的梯度，如下面所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Vanilla Minibatch Gradient Descent</span></div><div class="line"></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">  data_batch = sample_training_data(data, <span class="number">256</span>) <span class="comment"># sample 256 examples</span></div><div class="line">  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)</div><div class="line">  weights += - step_size * weights_grad <span class="comment"># perform parameter update</span></div></pre></td></tr></table></figure>
<p>实际上，批量数据的梯度是完整数据的梯度的良好近似，用批量数据的梯度代替完整数据的梯度进行快速计算，实现参数的快速更新，在实践中往往能够达到更好的结果。这算是时间效率和精度的一个折中方案。</p>
<h6 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent(SGD)"></a>Stochastic Gradient Descent(SGD)</h6><p>这是当batch size为1时的特例，不过在实践中很少用。batch的大小是一个超参数，但是实践中很少用交叉验证的方法去确定它。这个参数的设置通常是基于内存限制或者确定为某些值，通常为2的幂。</p>
<p>整个优化的流程大概如下所示：<br><img src="liuchen.jpg" alt=""></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1、<a href="http://cs231n.github.io/classification/" target="_blank" rel="external">cs231n spring 2017 classification notes</a><br>2、<a href="http://cs231n.github.io/linear-classify/" target="_blank" rel="external">cs231n spring 2017 linear_classify_1 notes</a><br>3、<a href="http://cs231n.github.io/optimization-1/" target="_blank" rel="external">cs231n spring 2017 linear_classify_2 notes</a><br>3、<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf" target="_blank" rel="external">cs231n spring 2017 lecture2 slides</a><br>4、<a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf" target="_blank" rel="external">cs231n spring 2017 lecture3 slides</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/dl//" class="article-tag-list-link color3">dl</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/09/24/cs231n-lecture-2-and-3/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-cs231n-assignment1" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/23/cs231n-assignment1/">cs231n assignment1</a>
    </h1>
  

        
        <a href="/2017/09/23/cs231n-assignment1/" class="archive-article-date">
  	<time datetime="2017-09-23T09:48:15.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-09-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#k-Nearest-Neighbor-classifier"><span class="toc-text">k-Nearest Neighbor classifier</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#compute-distances"><span class="toc-text">compute distances</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#compute-distances-with-two-loops"><span class="toc-text">compute distances with two loops</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#compute-distances-with-one-loop"><span class="toc-text">compute distances with one loop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#compute-distances-with-no-loop"><span class="toc-text">compute distances with no loop</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cross-validation"><span class="toc-text">Cross-validation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Split-up-the-training-data-into-folds"><span class="toc-text">Split up the training data into folds</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Perform-k-fold-cross-validation"><span class="toc-text">Perform k-fold cross validation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol>
</div>

        <h1 id="k-Nearest-Neighbor-classifier"><a href="#k-Nearest-Neighbor-classifier" class="headerlink" title="k-Nearest Neighbor classifier"></a>k-Nearest Neighbor classifier</h1><h2 id="compute-distances"><a href="#compute-distances" class="headerlink" title="compute distances"></a>compute distances</h2><h3 id="compute-distances-with-two-loops"><a href="#compute-distances-with-two-loops" class="headerlink" title="compute distances with two loops"></a>compute distances with two loops</h3><p>思想很简单，但是耗时较长，代码如下。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_distances_two_loops</span><span class="params">(X,X_train)</span>:</span></div><div class="line">    <span class="keyword">assert</span>(X.shape[<span class="number">1</span>]==X_train.shape[<span class="number">1</span>])</div><div class="line">    num_test=X.shape[<span class="number">0</span>]</div><div class="line">    num_train=X_train.shape[<span class="number">0</span>]</div><div class="line">    dists=np.zeros((num_test,num_train))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_train):</div><div class="line">            dists[i][j]=np.linalg.norm(X[i,:]-X_train[j,:])</div><div class="line">    <span class="keyword">return</span> dists</div></pre></td></tr></table></figure></p>
<h3 id="compute-distances-with-one-loop"><a href="#compute-distances-with-one-loop" class="headerlink" title="compute distances with one loop"></a>compute distances with one loop</h3><p>利用numpy.sum代替一个循环，但是在测试中比第一种方法更耗时。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_distances_one_loop</span><span class="params">(X,X_train)</span>:</span></div><div class="line">    <span class="keyword">assert</span>(X.shape[<span class="number">1</span>]==X_train.shape[<span class="number">1</span>])</div><div class="line">    num_test=X.shape[<span class="number">0</span>]</div><div class="line">    num_train=X_train.shape[<span class="number">0</span>]</div><div class="line">    dists=np.zeros((num_test,num_train))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test):</div><div class="line">        dists[i,:]=np.linalg.norm(X[i,:]-X_train,axis=<span class="number">1</span>)</div><div class="line">    <span class="keyword">return</span> dists</div></pre></td></tr></table></figure></p>
<h3 id="compute-distances-with-no-loop"><a href="#compute-distances-with-no-loop" class="headerlink" title="compute distances with no loop"></a>compute distances with no loop</h3><p>利用矩阵运算代替循环，用时极短但是不容易理解。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_distances_no_loop</span><span class="params">(X,X_train)</span>:</span></div><div class="line">    <span class="keyword">assert</span>(X.shape[<span class="number">1</span>]==X_train.shape[<span class="number">1</span>])</div><div class="line">    num_test=X.shape[<span class="number">0</span>]</div><div class="line">    num_train=X_train.shape[<span class="number">0</span>]</div><div class="line">    dists=np.zeros((num_test,num_train))</div><div class="line">    M=X.dot(X_train.T)</div><div class="line">    te=np.square(X).sum(axis=<span class="number">1</span>)</div><div class="line">    tr=np.square(X_train).sum(axis=<span class="number">1</span>)</div><div class="line">    dists = np.sqrt(<span class="number">-2</span>*M+tr+np.matrix(te).T)</div><div class="line">    <span class="keyword">return</span> dists</div></pre></td></tr></table></figure></p>
<h2 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross-validation"></a>Cross-validation</h2><h3 id="Split-up-the-training-data-into-folds"><a href="#Split-up-the-training-data-into-folds" class="headerlink" title="Split up the training data into folds"></a>Split up the training data into folds</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">y_train_ = y_train.reshape(<span class="number">-1</span>, <span class="number">1</span>)</div><div class="line">X_train_folds , y_train_folds = np.array_split(X_train,num_folds),p.array_split(y_train_,num_folds)</div></pre></td></tr></table></figure>
<h3 id="Perform-k-fold-cross-validation"><a href="#Perform-k-fold-cross-validation" class="headerlink" title="Perform k-fold cross validation"></a>Perform k-fold cross validation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> k_ <span class="keyword">in</span> k_choices:</div><div class="line">    k_to_accuracies.setdefault(k_, [])</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_folds):</div><div class="line">    classifier = KNearestNeighbor()</div><div class="line">    X_val_train = np.vstack(X_train_folds[<span class="number">0</span>:i] + X_train_folds[i+<span class="number">1</span>:])</div><div class="line">    y_val_train = np.vstack(y_train_folds[<span class="number">0</span>:i] + y_train_folds[i+<span class="number">1</span>:])</div><div class="line">    y_val_train = y_val_train[:,<span class="number">0</span>]</div><div class="line">    classifier.train(X_val_train, y_val_train)</div><div class="line">    <span class="keyword">for</span> k_ <span class="keyword">in</span> k_choices:</div><div class="line">        y_val_pred = classifier.predict(X_train_folds[i], k=k_)</div><div class="line">        num_correct = np.sum(y_val_pred == y_train_folds[i][:,<span class="number">0</span>])</div><div class="line">        accuracy = float(num_correct) / len(y_val_pred)</div><div class="line">        k_to_accuracies[k_] = k_to_accuracies[k_] + [accuracy]</div></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="">完整代码</a><br><a href="http://cs231n.github.io/assignments2017/assignment1/" target="_blank" rel="external">Assignment1</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/cs231n//" class="article-tag-list-link color2">cs231n</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/09/23/cs231n-assignment1/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
    <article id="post-how-to-use-git" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/22/how-to-use-git/">How to use git</a>
    </h1>
  

        
        <a href="/2017/09/22/how-to-use-git/" class="archive-article-date">
  	<time datetime="2017-09-22T10:39:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-09-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
<div id="toc">
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#创建本地仓库并上传代码到GitHub"><span class="toc-text">创建本地仓库并上传代码到GitHub</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#IDEA创建项目并push到Github"><span class="toc-text">IDEA创建项目并push到Github</span></a></li></ol>
</div>

        <h1 id="创建本地仓库并上传代码到GitHub"><a href="#创建本地仓库并上传代码到GitHub" class="headerlink" title="创建本地仓库并上传代码到GitHub"></a>创建本地仓库并上传代码到GitHub</h1><p><em>1）新建Text文件夹作为仓库根目录（文件夹名字随意命名）
</em>2）将需要上传的代码文件加入到Text根目录<br><em>3）在根目录下建立仓库<br>    使用命令行或Git Bash，输入下面命令：先进入到Text根目录下，再输入git init（初始化一个仓库）
</em>4）将所有文件添加到仓库<br>    使用命令行或Git Bash，输入下面命令：git add .<br><em>5）提交<br>    使用命令行或Git Bash，输入下面命令：git commit -m “CommitInfo”
</em>6）添加源到GitHub<br>    git remote add origin git@github.com:YourName/YourRepositroy.git<br>*7）上传源到GitHub<br>    git push -u origin master</p>
<h1 id="IDEA创建项目并push到Github"><a href="#IDEA创建项目并push到Github" class="headerlink" title="IDEA创建项目并push到Github"></a>IDEA创建项目并push到Github</h1><p><a href="http://blog.csdn.net/u011853294/article/details/53228720" target="_blank" rel="external">配置方式</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">git</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/git//" class="article-tag-list-link color4">git</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2017/09/22/how-to-use-git/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>







  
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2018 Fengyang
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>

    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),W=r(160),D=r(11),U=r(31),G=D.f,B=U.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",Y="Shared"+K,J="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Wt=!!q&&o(function(){gt.call(new q(1))}),Dt=function(){return gt.apply(Wt?dt.call(Nt(this)):Nt(this),arguments)},Ut={copyWithin:function(t,n){return W.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(U.f=qt,D.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Yt=v({},Ut);v(Yt,Vt),h(Yt,bt,Vt.values),v(Yt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Dt}),Lt(Yt,"buffer","b"),Lt(Yt,"byteOffset","o"),Lt(Yt,"byteLength","l"),Lt(Yt,"length","e"),G(Yt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==Y))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Yt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==Y?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),J in _||h(_,J,n),u(u.P,a,Ut),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Dt}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,W=s("symbol-registry"),D=s("symbols"),U=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=D[t]=_(N[k]);return n._k=t,n},Y=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},J=function(t,n,r){return t===G&&J(U,n,r),m(t),n=w(n,!0),m(r),i(D,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)J(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(D,t)&&!i(U,t))&&(!(n||!i(this,t)||!i(D,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(D,n)||i(U,n)){var r=F(t,n);return!r||!i(D,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(D,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?U:x(t)),o=[],u=0;e.length>u;)!i(D,n=e[u++])||r&&!i(G,n)||o.push(D[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(U,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=J,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(W,t+="")?W[t]:W[t]=N(t)},keyFor:function(t){if(Y(t))return y(W,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:J,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!Y(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!Y(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,W=i?"_o":L,D=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},U=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return D(t,52,8)},K=function(t){return D(t,23,4)},Y=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},J=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[W],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[W],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[W]=i,this[C]=r},i&&(Y(S,k,"_l"),Y(_,I,"_b"),Y(_,k,"_l"),Y(_,L,"_o")),f(_[m],{getInt8:function(t){return J(this,1,t)[0]<<24>>24},getUint8:function(t){return J(this,1,t)[0]},getInt16:function(t){var n=J(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=J(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(J(this,4,t,arguments[1]))},getUint32:function(t){return G(J(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return U(J(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return U(J(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText),window.YiliaChangyanWrap&&window.YiliaChangyanWrap()}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{
toISOString:function(){if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,W=s("symbol-registry"),D=s("symbols"),U=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=D[t]=_(N[k]);return n._k=t,n},Y=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},J=function(t,n,r){return t===G&&J(U,n,r),m(t),n=w(n,!0),m(r),i(D,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)J(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(D,t)&&!i(U,t))&&(!(n||!i(this,t)||!i(D,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(D,n)||i(U,n)){var r=F(t,n);return!r||!i(D,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(D,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?U:x(t)),o=[],u=0;e.length>u;)!i(D,n=e[u++])||r&&!i(G,n)||o.push(D[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(U,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=J,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(W,t+="")?W[t]:W[t]=N(t)},keyFor:function(t){if(Y(t))return y(W,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:J,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!Y(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!Y(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({
getOwnMetadataKeys:function(t){return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.507b3a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">RNN</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">sklearn</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">cs231n</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">sql</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">python</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">algorithm</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">cuda</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">cpp</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">git</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">cv</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">dl</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">paper</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">link</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">rnn</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">pytorch</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">tensorflow</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">pandas</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://wwdguu.github.io/2018/01/17/useful-links/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>常用网站链接</a>
            </li>
          
            <li class="search-li">
              <a href="https://wwdguu.github.io/2018/03/25/paperlist/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>CV论文列表</a>
            </li>
          
            <li class="search-li">
              <a href="https://github.com/wwdguu/ebooks" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>电子书</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接4</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接5</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接6</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>